\documentclass[../main.tex]{subfiles}
\begin{document}

\section{Tổng quan}
Đồ án này ứng dụng và mở rộng HippoRAG 2, một framework Retrieval-Augmented Generation (RAG) tiên tiến lấy cảm hứng từ cơ chế bộ nhớ dài hạn của con người. Được phát triển bởi các nhà nghiên cứu tại OSU-NLP Group, HippoRAG 2 được thiết kế để giúp các Mô hình Ngôn ngữ Lớn (LLM) liên tục tích hợp kiến thức từ các tài liệu bên ngoài. Framework này giải quyết những hạn chế chính trong các hệ thống RAG truyền thống bằng cách kết hợp các thành phần lấy cảm hứng từ thần kinh học, mô phỏng quá trình ghi nhớ của con người. Trong công trình này, tôi nghiên cứu và mở rộng HippoRAG 2, đặc biệt tập trung vào việc áp dụng nó cho dữ liệu tiếng Việt và các tác vụ lập luận đa bước.Ngoài ra nghiên cứu này, tôi bổ sung thêm các modules fine tune Reranking Model để tăng cường khả năng của hệ thống HippoRAG2. 


HippoRAG 2 hoạt động trong hai giai đoạn chính: giai đoạn Offline Indexing để xây dựng bộ nhớ và giai đoạn Online Retrieval \& QA để truy xuất thông tin và tạo phản hồi. Giai đoạn Offline Indexing xây dựng hệ thống bộ nhớ dài hạn cho framework bằng cách tạo ra một Đồ thị Tri thức (Knowledge Graph - KG) từ các tài liệu văn bản, chuyển đổi văn bản thô thành một biểu diễn có cấu trúc, nắm bắt cả thông tin khái niệm và chi tiết ngữ cảnh. Giai đoạn Online Retrieval \& QA sử dụng KG đã xây dựng này để truy xuất thông tin dựa trên truy vấn của người dùng và tạo ra các phản hồi thông minh, sử dụng các thuật toán phức tạp để điều hướng cấu trúc tri thức và trích xuất thông tin liên quan.

Luồng công việc tổng thể được minh họa trong Hình 1, thể hiện hai giai đoạn chính này. HippoRAG 2 được xây dựng dựa trên framework HippoRAG ban đầu nhưng giới thiệu một số cải tiến quan trọng nhằm tăng cường sự phù hợp với cơ chế bộ nhớ của con người. Những cải tiến này bao gồm việc tích hợp liền mạch thông tin khái niệm và ngữ cảnh, truy xuất nhận thức ngữ cảnh tốt hơn, và bộ nhớ nhận diện để cải thiện việc lựa chọn nút hạt giống. Nghiên cứu của tôi xem xét chi tiết các cơ chế này và khám phá hiệu quả của chúng khi áp dụng cho dữ liệu tiếng Việt.

\section{Offline Indexing – Giai đoạn Xây dựng Bộ nhớ}
Trong giai đoạn Offline Indexing, nhiệm vụ chính là xây dựng hệ thống bộ nhớ dài hạn bằng cách tạo ra một Đồ thị Tri thức (KG) từ các tài liệu văn bản. Các module trong giai đoạn này làm việc cùng nhau để trích xuất, xử lý và tổ chức thông tin một cách có cấu trúc nhằm hỗ trợ các bước truy xuất trong tương lai. Giai đoạn này rất quan trọng vì nó quyết định chất lượng và hiệu quả của các hoạt động truy xuất tiếp theo.

% \subsection{Module 1: Phân đoạn Tài liệu}
% Phân đoạn tài liệu là một bước quan trọng nhằm chia nhỏ tài liệu gốc thành các đoạn ngắn hơn, mỗi đoạn mang một ý nghĩa logic riêng biệt. Quá trình này đảm bảo rằng thông tin được tổ chức thành các đơn vị dễ quản lý, có thể được xử lý và truy xuất hiệu quả. HippoRAG 2 sử dụng các Mô hình Ngôn ngữ Lớn (LLM), như Qwen-1.5B-Instruct, để nâng cao khả năng phân đoạn vượt trội so với các phương pháp dựa trên quy tắc truyền thống.

% Quá trình phân đoạn bắt đầu bằng việc tách văn bản thành các câu riêng biệt trong khi vẫn giữ nguyên ý nghĩa của chúng. Không giống như việc chia câu đơn giản, hệ thống sử dụng LLM để đánh giá ngữ cảnh và đưa ra quyết định sáng suốt về việc hợp nhất hay tách câu dựa trên cấu trúc logic của chúng. Phương pháp tiếp cận nhận thức ngữ cảnh này tạo ra các đoạn văn mạch lạc, ngắn gọn và dễ quản lý, được tối ưu hóa cho việc trích xuất triple tiếp theo.

% Quá trình phân đoạn này đặc biệt quan trọng vì nó ảnh hưởng trực tiếp đến chất lượng của việc trích xuất triple và xây dựng đồ thị tri thức sau này. Bằng cách tạo ra các đoạn văn có tính liên kết logic, hệ thống đảm bảo rằng các triple được trích xuất duy trì được ngữ cảnh và mối quan hệ ngữ nghĩa phù hợp. Việc phân đoạn kém có thể dẫn đến thông tin bị phân mảnh hoặc mất các mối quan hệ ngữ cảnh, làm suy yếu hiệu quả của toàn bộ framework.


\subsection{Module 2: OpenIE by LLM (Trích xuất Triple)}
Module OpenIE by LLM trong HippoRAG 2 sử dụng các mô hình mạnh mẽ như Llama-3.3-70B để trích xuất triple từ mỗi đoạn văn. Module này đại diện cho một bước quan trọng trong việc chuyển đổi văn bản phi cấu trúc thành kiến thức có cấu trúc có thể được tích hợp vào đồ thị tri thức. Quá trình trích xuất tập trung vào việc xác định các triple chủ thể-quan hệ-đối tượng nắm bắt các sự kiện và mối quan hệ thiết yếu trong văn bản.

Triple tuân theo định dạng (subject, relation, object), cung cấp một cách tự nhiên để biểu diễn thông tin thực tế. Ví dụ: Từ câu "Elon Musk đã sáng lập SpaceX," hệ thống trích xuất triple ("Elon Musk", "đã sáng lập", "SpaceX"). Mỗi triple được trích xuất tạo ra hai Phrase Node (subject và object) và một Relation Edge (có hướng từ subject đến object) trong đồ thị tri thức. Biểu diễn có cấu trúc này cho phép lưu trữ và truy xuất thông tin hiệu quả.

Một đổi mới quan trọng trong HippoRAG 2 là việc sử dụng phương pháp "schema-less open KG". Không giống như các đồ thị tri thức truyền thống bị giới hạn bởi các ontology được định nghĩa trước, phương pháp này cho phép trích xuất bất kỳ loại quan hệ nào mà không bị giới hạn bởi một schema cố định. Tính linh hoạt này cho phép hệ thống nắm bắt một phạm vi thông tin và mối quan hệ rộng hơn, làm cho nó dễ thích ứng hơn với các miền kiến thức đa dạng.

Phương pháp này mang lại những lợi thế đáng kể so với các hệ thống trích xuất thông tin truyền thống. Không giống như các phương pháp trích xuất dựa trên quy tắc hoặc thống kê, LLM có thể hiểu ngữ cảnh và trích xuất các mối quan hệ phức tạp mà các phương pháp cứng nhắc hơn có thể bỏ sót. Hệ thống không bị giới hạn bởi các tập hợp quan hệ được định nghĩa trước, cho phép biểu diễn thông tin đa dạng nắm bắt tốt hơn các sắc thái của ngôn ngữ tự nhiên. Hơn nữa, phương pháp không có schema giúp KG linh hoạt và dễ dàng mở rộng với kiến thức mới mà không cần thiết kế lại cấu trúc cơ bản.

\subsection{Module 3: Synonym Detection by Embedding}
Sau khi trích xuất triple, module Synonym Detection sử dụng các kỹ thuật embedding (Word2Vec, GloVe, BERT) để phát hiện các từ và cụm từ đồng nghĩa. Module này giải quyết một thách thức phổ biến trong truy xuất thông tin: sự đa dạng trong cách diễn đạt cùng một khái niệm trong ngôn ngữ tự nhiên. Bằng cách xác định và kết nối các thuật ngữ đồng nghĩa, hệ thống có thể bắc cầu qua những biến thể ngôn ngữ này và cải thiện hiệu suất truy xuất.

Quá trình bắt đầu bằng việc tính toán độ tương đồng cosine giữa các embedding của các Phrase Node khác nhau trong đồ thị tri thức. Khi độ tương đồng giữa hai node vượt quá ngưỡng được định nghĩa trước, một Synonym Edge được tạo ra để kết nối chúng. Ví dụ, hệ thống có thể kết nối "NYC" với "New York City" thông qua Synonym Edge, nhận ra rằng các thuật ngữ này đề cập đến cùng một thực thể mặc dù hình thức bề mặt của chúng khác nhau.

Module này mang lại một số lợi ích chính cho toàn bộ framework. Nó giúp hệ thống nhận diện các cách diễn đạt khác nhau của cùng một khái niệm, nâng cao khả năng truy vấn khi người dùng sử dụng từ đồng nghĩa hoặc biến thể của khái niệm. Bằng cách tạo kết nối giữa thông tin tương tự nhau trong các tài liệu khác nhau, nó cho phép truy xuất thông tin toàn diện hơn mà không bị giới hạn bởi các lựa chọn thuật ngữ cụ thể.

Không giống như các phương pháp dựa vào từ điển đồng nghĩa cố định, phương pháp dựa trên embedding này có thể phát hiện các mối quan hệ đồng nghĩa dựa trên sự tương đồng ngữ nghĩa thực tế trong không gian vector. Điều này cho phép nó xác định các mối quan hệ có thể không được nắm bắt trong các tài nguyên từ vựng được định nghĩa trước. Kết quả là một hệ thống linh hoạt và mạnh mẽ hơn, có thể kết nối thông tin giữa các tài liệu sử dụng thuật ngữ khác nhau nhưng truyền tải cùng một ý nghĩa.

\subsection{Module 4: Dense-Sparse Integration}
Module Dense-Sparse Integration kết hợp hai loại node trong đồ thị tri thức: Phrase node (mã hóa thưa thớt - sparse coding) và Passage node (mã hóa dày đặc - dense coding). Sự tích hợp này đại diện cho một đổi mới cơ bản trong HippoRAG 2 nhằm giải quyết sự đánh đổi cố hữu giữa độ chính xác khái niệm và sự phong phú về ngữ cảnh trong biểu diễn kiến thức.

Phrase node lưu trữ các khái niệm cô đọng, cụ thể là các chủ thể và đối tượng được trích xuất từ triple. Các node này biểu diễn thông tin ở định dạng thưa thớt, hiệu quả, tạo điều kiện cho việc suy luận và truy xuất nhanh chóng. Mặt khác, Passage node lưu trữ toàn bộ đoạn văn gốc, bảo toàn ngữ cảnh đầy đủ và thông tin chi tiết. Hai loại node này được liên kết thông qua các Context edge có nhãn "contains," có hướng từ Passage Node đến Phrase Node, cho biết một đoạn văn cụ thể chứa các khái niệm cụ thể.

Thiết kế của module này dựa trên lý thuyết mã hóa dày đặc và thưa thớt trong nhận thức của con người. Mã hóa thưa thớt, được đại diện bởi Phrase Node, hiệu quả về mặt lưu trữ và tạo điều kiện cho việc suy luận bằng cách tập trung vào các khái niệm thiết yếu. Mã hóa dày đặc, được đại diện bởi Passage Node, bảo toàn ngữ cảnh đầy đủ và thông tin chi tiết phong phú có thể bị mất trong các biểu diễn cô đọng hơn. Bằng cách kết hợp cả hai phương pháp, hệ thống đạt được sự cân bằng giữa hiệu quả xử lý và độ chính xác của thông tin.

Sự tích hợp này giải quyết những hạn chế chính của framework HippoRAG ban đầu. Nó khắc phục phương pháp tập trung vào thực thể vốn bỏ qua nhiều tín hiệu ngữ cảnh, cung cấp một biểu diễn kiến thức toàn diện hơn. Sự kết hợp này cải thiện đáng kể khả năng truy xuất thông tin so với các phương pháp chỉ dựa vào vector embedding. Quan trọng nhất, nó cho phép hệ thống thực hiện suy luận nhanh thông qua các kết nối có cấu trúc giữa các Phrase Node trong khi vẫn có thể truy xuất thông tin chi tiết chính xác từ các Passage Node liên quan khi cần thiết.

Sự tích hợp dense-sparse đại diện cho một cải tiến cơ bản trong HippoRAG 2, giải quyết sự đánh đổi giữa khái niệm và ngữ cảnh tồn tại trong nhiều hệ thống biểu diễn kiến thức. Bằng cách kết hợp cả mã hóa thưa thớt (để biểu diễn khái niệm hiệu quả) và mã hóa dày đặc (để cung cấp thông tin ngữ cảnh phong phú), hệ thống đạt được sự cân bằng gần hơn với cách tổ chức bộ nhớ của con người, nơi cả khái niệm trừu tượng và ký ức tình tiết chi tiết cùng tồn tại và bổ sung cho nhau.

\section{Online Retrieval \& QA – Giai đoạn Truy hồi và Phản hồi}
Giai đoạn này sử dụng KG đã xây dựng để trả lời câu hỏi của người dùng thông qua một chuỗi các module xử lý. Giai đoạn Online Retrieval \& QA là nơi kiến thức được lưu trữ trong đồ thị được truy cập, lọc và tổng hợp để tạo ra phản hồi cho các truy vấn của người dùng.

\subsection{Module 1: Retriever passages and triples}

Module Retriever trong HippoRAG 2 đóng vai trò then chốt như cửa ngõ đầu tiên trong quá trình xử lý truy vấn, thực hiện nhiệm vụ truy xuất thông tin ban đầu từ đồ thị tri thức (Knowledge Graph - KG). Đây là bước nền tảng quyết định phạm vi thông tin sẽ được đưa vào các giai đoạn xử lý tiếp theo, từ đó ảnh hưởng trực tiếp đến chất lượng của phản hồi cuối cùng. Hiệu quả của module này phụ thuộc vào khả năng cân bằng giữa hai yếu tố đối lập: phạm vi bao phủ rộng (để đảm bảo không bỏ sót thông tin quan trọng) và độ chính xác cao (để tránh nhiễu thông tin và quá tải các module tiếp theo).

Về mặt kỹ thuật, HippoRAG 2 triển khai một cơ chế truy xuất kép (dual retrieval) sử dụng các mô hình embedding tiên tiến như NV-Embed-v2. Cơ chế này đồng thời truy xuất cả passages (đoạn văn) và triples (bộ ba thông tin) từ đồ thị tri thức. Sự kết hợp này tạo nên một lợi thế đáng kể so với các phương pháp truy xuất đơn lẻ, vì nó cho phép hệ thống tiếp cận song song hai dạng thông tin bổ sung cho nhau: kiến thức có cấu trúc (structured knowledge) thông qua các triple và thông tin ngữ cảnh phong phú (contextual information) thông qua các passage.

\subsubsection{Passage}
Bước đầu tiên là truy xuất các passage liên quan từ kho dữ liệu. Không giống như Phrase Node chỉ được chọn từ các triple đã lọc, tất cả các Passage Node được truy xuất từ kho dữ liệu dựa trên độ tương đồng với truy vấn sẽ được xem xét làm seed node. Hệ thống sử dụng mô hình embedding như NV-Embed-v2 để tính toán độ tương đồng giữa truy vấn \(q\) và mỗi passage \(p\) trong kho dữ liệu:

\begin{equation}
\text{sim}(q, p) = \cos(\text{embed}(q), \text{embed}(p))
\end{equation}

Bước thứ hai là xếp hạng các passage theo độ tương đồng. Các passage được sắp xếp theo thứ tự giảm dần của độ tương đồng với truy vấn, và top-k passage có độ tương đồng cao nhất được chọn:

\begin{equation}
P_{\text{top-k}} = \{p_1, p_2, \ldots, p_k\} \text{ sao cho } \text{sim}(q, p_1) \geq \text{sim}(q, p_2) \geq \ldots \geq \text{sim}(q, p_k)
\end{equation}


Quá trình truy xuất passage sử dụng kỹ thuật dense retrieval tiêu chuẩn, trong đó truy vấn được chuyển đổi thành vector embedding và so sánh với các vector embedding của tất cả các passage trong kho dữ liệu bằng phép đo tương đồng cosine. Các passage có độ tương đồng cao nhất với truy vấn sẽ được chọn để xử lý tiếp theo. Tuy nhiên, điểm đột phá thực sự nằm ở phương pháp truy xuất triple.
\subsubsection{Truy xuất Triple với "Query to Triple"}
Một đổi mới quan trọng trong HippoRAG 2 là việc triển khai phương pháp "Query to Triple" thay vì chỉ dựa vào kỹ thuật Named Entity Recognition (NER) như trong các hệ thống trước đây. Phương pháp NER truyền thống chỉ trích xuất các thực thể được đề cập trong truy vấn (ví dụ: "Elon Musk", "SpaceX") và sử dụng chúng làm điểm khởi đầu cho việc tìm kiếm. Ngược lại, phương pháp "Query to Triple" xem xét toàn bộ truy vấn như một đơn vị ngữ nghĩa hoàn chỉnh và so khớp nó với các triple trong đồ thị tri thức bằng cách sử dụng embedding.

Cơ chế hoạt động của phương pháp "Query to Triple" bao gồm các bước sau:

1. Truy vấn của người dùng được chuyển đổi thành vector embedding sử dụng cùng một mô hình embedding được sử dụng cho các triple.

2. Hệ thống tính toán độ tương đồng cosine giữa vector embedding của truy vấn và vector embedding của mỗi triple trong đồ thị tri thức.

3. Các triple có độ tương đồng cao nhất với truy vấn được chọn làm ứng viên tiềm năng.

4. Hệ thống áp dụng một ngưỡng tương đồng tối thiểu để lọc bỏ các triple không đủ liên quan, đảm bảo chỉ những thông tin thực sự phù hợp mới được đưa vào xử lý tiếp theo.

5. Các triple được chọn sau cùng được sắp xếp theo độ tương đồng giảm dần và chuyển đến module tiếp theo trong pipeline.

Phương pháp này mang lại nhiều lợi thế đáng kể so với các phương pháp truyền thống. Thứ nhất, nó cung cấp ngữ cảnh phong phú hơn so với việc chỉ trích xuất thực thể riêng lẻ. Bằng cách xem xét toàn bộ truy vấn, hệ thống có thể nắm bắt ý định và ngữ cảnh của câu hỏi một cách toàn diện hơn. Ví dụ, với truy vấn "Ai đã sáng lập SpaceX và Tesla?", phương pháp NER chỉ trích xuất "SpaceX" và "Tesla" làm điểm khởi đầu, trong khi "Query to Triple" hiểu rằng truy vấn đang tìm kiếm mối quan hệ "sáng lập" giữa một người và hai công ty này.

Thứ hai, các triple chứa các mối quan hệ cơ bản giữa các khái niệm, giúp hiểu rõ hơn ý định của truy vấn. Triple có định dạng (subject, relation, object), nắm bắt không chỉ các thực thể được đề cập mà còn cả cách chúng liên quan đến nhau. Điều này đặc biệt quan trọng đối với các truy vấn phức tạp đòi hỏi hiểu biết về mối quan hệ giữa các thực thể. Ví dụ, triple ("Elon Musk", "là CEO của", "Tesla") và ("Elon Musk", "đã sáng lập", "SpaceX") cung cấp thông tin về mối quan hệ cụ thể giữa Elon Musk và các công ty, không chỉ đơn thuần là sự hiện diện của các thực thể này trong cùng một ngữ cảnh.

Thứ ba, các đánh giá thực nghiệm đã chứng minh hiệu quả vượt trội của phương pháp này. Cụ thể, "Query to Triple" cải thiện Recall@5 (tỷ lệ truy xuất thành công trong top 5 kết quả) trung bình 12,5% so với phương pháp NER-to-node được sử dụng trong HippoRAG ban đầu. Con số này không chỉ là một cải tiến về mặt số lượng mà còn phản ánh khả năng của hệ thống trong việc nắm bắt và đáp ứng chính xác hơn ý định của người dùng.

Cuối cùng, phương pháp này giải quyết một hạn chế cơ bản của các phương pháp tập trung vào thực thể: việc bỏ qua các tín hiệu ngữ cảnh quan trọng. Các phương pháp truyền thống thường chỉ tập trung vào các thực thể được đề cập rõ ràng, bỏ qua các yếu tố ngữ cảnh như động từ, tính từ, và các mối quan hệ ngữ nghĩa khác có thể chứa thông tin quan trọng về ý định của truy vấn. "Query to Triple" khắc phục điểm yếu này bằng cách xem xét toàn bộ truy vấn và so khớp nó với các triple hoàn chỉnh, dẫn đến việc truy xuất thông tin toàn diện và chính xác hơn.

\subsubsection{Ví dụ thực tiễn từ HippoRAG 2}

Để minh họa rõ hơn sự khác biệt giữa phương pháp "Query to Triple" trong HippoRAG 2 và phương pháp NER truyền thống, chúng ta hãy xem xét một ví dụ cụ thể từ nghiên cứu gốc. Giả sử người dùng đặt câu hỏi: "Những tác dụng phụ của thuốc Metformin là gì?"

\textbf{Cách tiếp cận NER truyền thống (HippoRAG ban đầu):}

Phương pháp này sẽ xử lý truy vấn như sau:
\begin{itemize}
    \item Trích xuất thực thể chính: "Metformin"
    \item Tìm kiếm các node trong đồ thị có chứa thực thể "Metformin"
    \item Không quan tâm đặc biệt đến phần "tác dụng phụ" trong truy vấn
    \item Có thể truy xuất cả thông tin về công dụng chính, liều lượng, chống chỉ định, v.v. của Metformin
\end{itemize}

Kết quả là, hệ thống có thể truy xuất nhiều thông tin không liên quan trực tiếp đến câu hỏi về tác dụng phụ, như:
\begin{itemize}
    \item ("Metformin", "được sử dụng để điều trị", "tiểu đường type 2")
    \item ("Metformin", "có liều lượng thông thường", "500mg-2000mg mỗi ngày")
    \item ("Metformin", "thuộc nhóm thuốc", "biguanide")
\end{itemize}

\textbf{Phương pháp "Query to Triple" (HippoRAG 2):}

Phương pháp này xử lý truy vấn một cách toàn diện hơn:
\begin{itemize}
    \item Chuyển đổi toàn bộ truy vấn "Những tác dụng phụ của thuốc Metformin là gì?" thành vector embedding
    \item So sánh với các triple trong đồ thị tri thức
    \item Ưu tiên các triple có mối quan hệ liên quan đến "tác dụng phụ"
\end{itemize}

Kết quả là, hệ thống ưu tiên truy xuất các triple thực sự liên quan đến tác dụng phụ, như:
\begin{itemize}
    \item ("Metformin", "có tác dụng phụ", "buồn nôn")
    \item ("Metformin", "gây ra tác dụng không mong muốn", "đau bụng")
    \item ("Metformin", "có thể dẫn đến", "thiếu vitamin B12")
    \item ("Metformin", "có tác dụng phụ hiếm gặp", "nhiễm toan lactic")
    \item ("Metformin", "có thể gây", "tiêu chảy")
\end{itemize}

Trong nghiên cứu này, tôi sử dụng sử dụng mô hình embedding NV-Embed-v2 (Nvidia Embed v2) cho việc embedding cả truy vấn và triple. Đây là một mô hình embedding có sẵn được phát triển bởi NVIDIA, được sử dụng để chuyển đổi cả truy vấn và triple thành các vector trong cùng một không gian vector, cho phép tính toán độ tương đồng cosine giữa chúng.



\subsubsection{Tinh chỉnh Mô hình Retriever và Reranking}
Trong phần mở rộng HippoRAG 2 của tôi, tôi đặc biệt tập trung vào việc tinh chỉnh các quy trình truy xuất và xếp hạng lại cho dữ liệu tiếng Việt. Hiệu quả của cả hai thành phần được tăng cường đáng kể thông qua việc tinh chỉnh trên dữ liệu cụ thể của miền. Cách tiếp cận dựa trên dữ liệu này cho phép hệ thống thích ứng với các miền kiến thức và mẫu truy vấn cụ thể, dẫn đến việc truy xuất thông tin chính xác và phù hợp hơn.

Đối với thành phần retriever, phương pháp tinh chỉnh của tôi bao gồm một quy trình nhiều giai đoạn sử dụng dữ liệu huấn luyện được tuyển chọn cẩn thận. Ban đầu, một bộ dữ liệu gồm các cặp truy vấn-đoạn văn được xây dựng, trong đó mỗi truy vấn được liên kết với các đoạn văn liên quan (ví dụ dương tính) và các đoạn văn không liên quan (ví dụ âm tính). Mô hình retriever, thường dựa trên kiến trúc bộ mã hóa kép (dual-encoder), sau đó được tinh chỉnh bằng cách sử dụng các mục tiêu học tương phản như mất mát InfoNCE. Việc huấn luyện này khuyến khích mô hình tạo ra các embedding đặt các truy vấn và đoạn văn có liên quan về mặt ngữ nghĩa gần nhau hơn trong không gian vector trong khi đẩy nội dung không liên quan ra xa hơn.

Dữ liệu huấn luyện để tinh chỉnh retriever thường được tăng cường thông qua các kỹ thuật như khai thác ví dụ âm tính khó (hard negative mining), trong đó các ví dụ âm tính thách thức, bề ngoài tương tự như ví dụ dương tính nhưng khác biệt về mặt ngữ nghĩa, được cố ý đưa vào. Điều này buộc mô hình phải học các phân biệt tinh tế hơn giữa nội dung liên quan và không liên quan. 

Đối với các mô hình reranking, quy trình tinh chỉnh mà tôi triển khai thậm chí còn phức tạp hơn. Các mô hình này thường sử dụng kiến trúc bộ mã hóa chéo (cross-encoder) cho phép tương tác sâu hơn giữa các biểu diễn truy vấn và đoạn văn. Dữ liệu huấn luyện bao gồm các cặp truy vấn-đoạn văn với nhãn mức độ liên quan được phân loại, thường theo thang điểm từ 0 (hoàn toàn không liên quan) đến 3 hoặc 4 (hoàn toàn liên quan). Mô hình reranker được tinh chỉnh bằng cách sử dụng các mục tiêu học theo điểm (pointwise), theo cặp (pairwise) hoặc theo danh sách (listwise).

Trong học theo điểm, mô hình được huấn luyện để dự đoán điểm liên quan tuyệt đối của mỗi cặp truy vấn-đoạn văn. Học theo cặp tập trung vào việc sắp xếp chính xác các cặp đoạn văn cho một truy vấn nhất định, trong khi học theo danh sách tối ưu hóa toàn bộ thứ hạng của các đoạn văn cho mỗi truy vấn. Các kỹ thuật như chưng cất kiến thức (knowledge distillation) cũng có thể được sử dụng, trong đó một mô hình lớn hơn, mạnh hơn (giáo viên) hướng dẫn việc huấn luyện một mô hình nhỏ hơn, hiệu quả hơn (học sinh).

Thích ứng miền là một khía cạnh quan trọng trong phương pháp tinh chỉnh của tôi cho cả retriever và reranker. Đối với các ứng dụng chuyên biệt với dữ liệu tiếng Việt, các mô hình được tiền huấn luyện trên các kho ngữ liệu chung được tinh chỉnh thêm trên dữ liệu cụ thể của miền. Quá trình này thường bao gồm học theo chương trình (curriculum learning), trong đó việc huấn luyện tiến triển từ các ví dụ chung đến các ví dụ ngày càng cụ thể theo miền, cho phép mô hình chuyển giao kiến thức chung trong khi thích ứng với các sắc thái của miền.

Thông qua phương pháp tinh chỉnh toàn diện này, việc triển khai các thành phần retriever và reranker của HippoRAG 2 trong nghiên cứu của tôi đạt được hiệu suất cao hơn đáng kể trong các tác vụ cụ thể của tiếng Việt so với các mô hình mục đích chung, đóng góp đáng kể vào hiệu quả tổng thể của framework.

\subsection{Module 2: Recognition Memory (Triple Filtering)}
Module Recognition Memory phân tích và lọc bỏ các triple không liên quan đến câu hỏi. Thành phần này được lấy cảm hứng từ các quá trình bộ nhớ của con người, đặc biệt là sự phân biệt giữa recall (chủ động truy xuất thông tin) và recognition (xác định thông tin liên quan khi được trình bày với nó). 

Module này sử dụng LLM để phân tích các triple được truy xuất và xác định mức độ liên quan của chúng với truy vấn. Quá trình này giảm nhiễu bằng cách chỉ giữ lại thông tin cần thiết, ngăn chặn các sự kiện không liên quan ảnh hưởng đến câu trả lời cuối cùng. Module sử dụng Llama-3.3-70B-Instruct để tối ưu hóa prompt cho việc lọc triple. Quá trình tối ưu hóa này đảm bảo rằng LLM có thể phân biệt hiệu quả giữa các triple liên quan và không liên quan trên một loạt các loại truy vấn và miền kiến thức. Kỹ thuật prompt rất quan trọng, vì nó hướng dẫn LLM đưa ra các đánh giá về mức độ liên quan một cách nhất quán và chính xác.

Module này mang lại những lợi ích chính cho toàn bộ framework. Nó cải thiện chất lượng của các seed node cho thuật toán PageRank bằng cách đảm bảo rằng chỉ các triple thực sự liên quan mới được xem xét. Bằng cách giảm nhiễu trong quá trình truy vấn, nó tăng độ chính xác của kết quả cuối cùng, ngăn chặn thông tin không liên quan làm loãng hoặc sai lệch câu trả lời. Có lẽ quan trọng nhất, nó mô phỏng quá trình nhận diện trong bộ nhớ con người, giúp xác định thông tin liên quan khi được gợi ý, đây là một khía cạnh quan trọng của quá trình xử lý thông tin giống con người thường thiếu trong các hệ thống RAG truyền thống.

\subsection{Module 3: Gán Trọng số cho Seed Nodes}
Module Gán Trọng số cho Seed Nodes là một thành phần quan trọng quyết định cách ảnh hưởng được phân bổ trên đồ thị tri thức trong thuật toán PageRank tiếp theo. Module này cẩn thận gán trọng số cho các node được chọn làm seed node, thiết lập tầm quan trọng tương đối của chúng đối với truy vấn cụ thể đang được xử lý.

\subsubsection{Đối với các phrase node}

Đối với các phrase node, quá trình lựa chọn và gán trọng số bắt đầu với các triple đã được lọc từ module Recognition Memory. Mỗi phrase node (chủ thể hoặc đối tượng) xuất hiện trong các triple đã lọc này sẽ trở thành một seed node tiềm năng. Sau đó, hệ thống tính toán trọng số cho mỗi node dựa trên điểm xếp hạng trung bình của nó trên tất cả các triple đã lọc mà nó xuất hiện. Cách tiếp cận này đảm bảo rằng các khái niệm được xếp hạng cao một cách nhất quán trên nhiều triple liên quan sẽ nhận được ảnh hưởng lớn hơn trong tìm kiếm đồ thị. Quá trình này được thực hiện một cách có hệ thống thông qua năm bước chính, đảm bảo rằng chỉ những khái niệm thực sự liên quan đến truy vấn mới được chọn làm seed node và nhận được trọng số phù hợp.

Bước đầu tiên là thu thập các triple đã được lọc từ module Recognition Memory (Triple Filtering). Hệ thống lấy tập \(T\) gồm tất cả các triple \((s, r, o)\) đã vượt qua ngưỡng liên quan do module Recognition Memory trả về. Mỗi triple trong tập này được gắn kèm một điểm liên quan \(\sigma\), phản ánh mức độ phù hợp của nó với truy vấn. Về mặt toán học, tập này được biểu diễn như sau:

\begin{equation}
T = \{\,t_1, t_2, \dots, t_N\}
\end{equation}

với mỗi \(t_i = (s_i, r_i, o_i)\) và có điểm số \(\sigma(t_i)\).

Bước thứ hai là xác định tập các phrase node tiềm năng. Từ mỗi triple \((s_i, r_i, o_i)\), hệ thống tách lấy hai thành phần subject \(s_i\) và object \(o_i\). Tất cả các thực thể này được gom lại thành tập \(V\) các phrase node tiềm năng:

\begin{equation}
V = \{\,v : v = s_i \text{ hoặc } v = o_i,\ \forall\,t_i \in T\}
\end{equation}

Bước thứ ba là tính điểm trung bình cho mỗi node. Với mỗi node \(v \in V\), hệ thống tìm ra những triple chứa \(v\), sau đó lấy trung bình các điểm số của những triple đó để làm trọng số ban đầu. Cụ thể, tập các triple chứa node \(v\) được xác định như sau:

\begin{equation}
T(v) = \{\,t_i \in T : v \text{ là } s_i \text{ hoặc } o_i\}
\end{equation}

Và điểm trung bình của node \(v\) được tính bằng:

\begin{equation}
w(v) = \frac{\sum_{t_i \in T(v)} \sigma(t_i)}{|T(v)|}
\end{equation}

Bước thứ tư là chuẩn hóa trọng số về khoảng [0,1]. Để dễ so sánh và thiết lập ngưỡng, điểm \(w(v)\) được đưa về chuẩn \([0,1]\) bằng tỉ lệ so với giá trị nhỏ nhất và lớn nhất của toàn bộ các \(w(u)\):

\begin{equation}
w_{\mathrm{norm}}(v) = \frac{w(v) - \min_{u\in V} w(u)}{\max_{u\in V} w(u) - \min_{u\in V} w(u)}
\end{equation}

Bước thứ năm là chọn seed nodes dựa trên ngưỡng. Hệ thống đặt một ngưỡng \(\tau\) (ví dụ top-k hoặc \(w_{\mathrm{norm}}(v)\ge\tau\)) để chỉ giữ lại những node có trọng số cao nhất, làm seed cho bước mở rộng đồ thị tiếp theo:

\begin{equation}
S = \{\,v\in V : w_{\mathrm{norm}}(v)\ge\tau\}
\end{equation}

Phương pháp gán trọng số cho phrase node trong HippoRAG 2 có ba ý nghĩa quan trọng:

Thứ nhất, một node chỉ được chọn khi nó xuất hiện nhiều lần trong các triple quan trọng, giúp tránh trường hợp "được nhắc" nhưng không thực sự liên quan. Điều này đảm bảo rằng chỉ những khái niệm thực sự quan trọng mới được chọn làm seed node.

Thứ hai, việc sử dụng điểm trung bình giúp giảm nhiễu: một triple có điểm số rất cao cũng không làm trọng số của node đó lệch quá nhiều nếu nó không xuất hiện ở các triple khác. Điều này tăng cường tính ổn định của quá trình lựa chọn seed node.

Thứ ba, ngưỡng \(\tau\) cho phép kiểm soát độ rộng của việc mở rộng đồ thị: \(\tau\) cao dẫn đến việc chọn ít node hơn, tập trung vào những khái niệm có liên quan cao nhất, trong khi \(\tau\) thấp cho phép chọn nhiều node hơn, mở rộng phạm vi tìm kiếm.

Để minh họa quá trình này, chúng ta xét một ví dụ cụ thể. Giả sử module Recognition Memory cho kết quả 4 triple sau với điểm số tương ứng:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Triple} & \textbf{Điểm số \(\sigma\)} \\
\hline
(Metformin, "có tác dụng phụ", buồn nôn) & 0.92 \\
\hline
(Metformin, "có thể dẫn đến", thiếu vitamin B12) & 0.85 \\
\hline
(vitamin B12, "thiếu hụt gây", mệt mỏi) & 0.80 \\
\hline
(Metformin, "gây ra tác dụng không mong muốn", đau bụng) & 0.78 \\
\hline
\end{tabular}
\end{table}

Tập node tiềm năng sẽ là:
\begin{equation}
V=\{\text{Metformin},\ \text{buồn nôn},\ \text{thiếu vitamin B12},\ \text{vitamin B12},\ \text{mệt mỏi},\ \text{đau bụng}\}
\end{equation}

Tính điểm trung bình \(w(v)\) cho mỗi node:
\begin{align}
w(\mathrm{Metformin}) &= (0.92 + 0.85 + 0.78)/3 = 0.85 \\
w(\mathrm{buồn\,nôn}) &= 0.92 \\
w(\mathrm{thiếu\,vitamin\,B12}) &= 0.85 \\
w(\mathrm{vitamin\,B12}) &= 0.80 \\
w(\mathrm{mệt\,mỏi}) &= 0.80 \\
w(\mathrm{đau\,bụng}) &= 0.78
\end{align}

Chuẩn hóa các điểm số (với min = 0.78, max = 0.92):
\begin{align}
w_{\mathrm{norm}}(\mathrm{buồn\,nôn}) &= (0.92-0.78)/(0.92-0.78) = 1.0 \\
w_{\mathrm{norm}}(\mathrm{Metformin}) &= (0.85-0.78)/(0.92-0.78) \approx 0.50 \\
w_{\mathrm{norm}}(\mathrm{thiếu\,vitamin\,B12}) &= (0.85-0.78)/(0.92-0.78) \approx 0.50 \\
w_{\mathrm{norm}}(\mathrm{vitamin\,B12}) &= (0.80-0.78)/(0.92-0.78) \approx 0.14 \\
w_{\mathrm{norm}}(\mathrm{mệt\,mỏi}) &= (0.80-0.78)/(0.92-0.78) \approx 0.14 \\
w_{\mathrm{norm}}(\mathrm{đau\,bụng}) &= (0.78-0.78)/(0.92-0.78) = 0.0
\end{align}

Với ngưỡng \(\tau = 0.5\), seed nodes sẽ là \{"buồn nôn", "Metformin", "thiếu vitamin B12"\}.
\subsubsection{Gán trọng số cho Passage Node}

Trong khi Phrase Node đại diện cho các khái niệm cụ thể, Passage Node lưu trữ thông tin ngữ cảnh đầy đủ, và việc gán trọng số cho chúng đòi hỏi một phương pháp khác biệt nhưng bổ sung.

Quá trình gán trọng số cho Passage Node trong HippoRAG 2 được thực hiện thông qua các bước chính, đảm bảo sự cân bằng giữa thông tin khái niệm (từ Phrase Node) và thông tin ngữ cảnh (từ Passage Node) trong quá trình tìm kiếm đồ thị.

Trọng số ban đầu của mỗi passage \(p_i\) chính là độ tương đồng của nó với truy vấn:

\begin{equation}
w_{\text{initial}}(p_i) = \text{sim}(q, p_i)
\end{equation}

Bước tiếp theo là áp dụng hệ số cân bằng để điều chỉnh ảnh hưởng tương đối của Passage Node so với Phrase Node. Đây là một bước quan trọng trong HippoRAG 2, giúp cân bằng giữa thông tin khái niệm và thông tin ngữ cảnh. Trọng số cuối cùng của mỗi passage được tính bằng cách nhân trọng số ban đầu với một hệ số cân bằng \(\alpha\):

\begin{equation}
w_{\text{final}}(p_i) = \alpha \cdot w_{\text{initial}}(p_i)
\end{equation}

Trong HippoRAG 2, hệ số cân bằng \(\alpha\) mặc định là 0.05, được xác định thông qua thử nghiệm rộng rãi. Giá trị này đại diện cho sự cân bằng tối ưu giữa Phrase Node và Passage Node, đảm bảo rằng cả hai loại thông tin đều đóng góp một cách thích hợp vào quá trình tìm kiếm đồ thị.

Phương pháp gán trọng số cho Passage Node trong HippoRAG 2 có ba ý nghĩa quan trọng:

Thứ nhất, tất cả các passage được truy xuất đều được chọn làm seed node, nhưng với trọng số khác nhau. Điều này đảm bảo rằng thông tin ngữ cảnh từ tất cả các passage liên quan đều được xem xét trong quá trình tìm kiếm đồ thị, mặc dù với mức độ ảnh hưởng khác nhau.

Thứ hai, hệ số cân bằng \(\alpha\) đóng vai trò quan trọng trong việc kiểm soát ảnh hưởng tương đối của Passage Node so với Phrase Node. Nếu \(\alpha\) quá cao, tìm kiếm đồ thị sẽ bị chi phối bởi sự tương đồng passage trực tiếp, về cơ bản giảm xuống thành truy xuất vector tiêu chuẩn. Nếu \(\alpha\) quá thấp, hệ thống sẽ không tận dụng hết thông tin ngữ cảnh phong phú trong các passage.

Thứ ba, phương pháp này cho phép điều chỉnh linh hoạt mức độ ảnh hưởng của thông tin ngữ cảnh (passage) và thông tin cô đọng (phrase) dựa trên loại truy vấn. Đối với các truy vấn tìm kiếm thông tin thực tế cụ thể, trọng số của Phrase Node có thể được tăng lên. Ngược lại, đối với các truy vấn yêu cầu hiểu biết ngữ cảnh nhiều hơn, trọng số của Passage Node có thể được điều chỉnh tăng lên.

Để minh họa quá trình này, chúng ta xét một ví dụ cụ thể. Giả sử hệ thống truy xuất 5 passage liên quan đến truy vấn "Những tác dụng phụ của thuốc Metformin là gì?" với độ tương đồng như sau:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Passage} & \textbf{Độ tương đồng} \\
\hline
Passage 1 (về tác dụng phụ của Metformin) & 0.85 \\
\hline
Passage 2 (về cơ chế hoạt động của Metformin) & 0.78 \\
\hline
Passage 3 (về liều lượng Metformin) & 0.72 \\
\hline
Passage 4 (về chống chỉ định của Metformin) & 0.68 \\
\hline
Passage 5 (về so sánh Metformin với các thuốc khác) & 0.65 \\
\hline
\end{tabular}
\end{table}

Trọng số ban đầu của mỗi passage chính là độ tương đồng của nó với truy vấn:
\begin{align}
w_{\text{initial}}(p_1) &= 0.85 \\
w_{\text{initial}}(p_2) &= 0.78 \\
w_{\text{initial}}(p_3) &= 0.72 \\
w_{\text{initial}}(p_4) &= 0.68 \\
w_{\text{initial}}(p_5) &= 0.65
\end{align}

Áp dụng hệ số cân bằng \(\alpha = 0.05\), trọng số cuối cùng của mỗi passage sẽ là:
\begin{align}
w_{\text{final}}(p_1) &= 0.05 \times 0.85 = 0.0425 \\
w_{\text{final}}(p_2) &= 0.05 \times 0.78 = 0.0390 \\
w_{\text{final}}(p_3) &= 0.05 \times 0.72 = 0.0360 \\
w_{\text{final}}(p_4) &= 0.05 \times 0.68 = 0.0340 \\
w_{\text{final}}(p_5) &= 0.05 \times 0.65 = 0.0325
\end{align}

Trong ví dụ này, tất cả các passage đều được chọn làm seed node, nhưng với trọng số khác nhau dựa trên độ tương đồng với truy vấn. Passage 1, có nội dung trực tiếp về tác dụng phụ của Metformin, nhận được trọng số cao nhất (0.0425), trong khi Passage 5, về so sánh Metformin với các thuốc khác, nhận được trọng số thấp nhất (0.0325).

Tuy nhiên, ngay cả với hệ số cân bằng \(\alpha = 0.05\), trọng số của các Passage Node vẫn thấp hơn đáng kể so với trọng số của các Phrase Node (thường nằm trong khoảng 0.5-1.0 sau khi chuẩn hóa). Điều này phản ánh thiết kế có chủ ý của HippoRAG 2, trong đó thông tin khái niệm từ Phrase Node đóng vai trò chính trong việc hướng dẫn tìm kiếm đồ thị, trong khi thông tin ngữ cảnh từ Passage Node đóng vai trò bổ sung.

Phương pháp gán trọng số cho Passage Node trong HippoRAG 2 đảm bảo rằng cả thông tin khái niệm và thông tin ngữ cảnh đều được xem xét trong quá trình tìm kiếm đồ thị, với mức độ ảnh hưởng phù hợp. Điều này giúp hệ thống đạt được sự cân bằng giữa độ chính xác khái niệm và sự phong phú về ngữ cảnh, dẫn đến kết quả truy xuất toàn diện và chính xác hơn.

Hệ số cân bằng này là một siêu tham số quan trọng đã được tối ưu hóa thực nghiệm thông qua thử nghiệm rộng rãi. Đặt nó quá cao sẽ khiến tìm kiếm đồ thị bị chi phối bởi sự tương đồng passage trực tiếp, về cơ bản giảm xuống thành truy xuất vector tiêu chuẩn. Đặt nó quá thấp sẽ không tận dụng hết thông tin ngữ cảnh phong phú trong các passage. Giá trị mặc định 0,05 đại diện cho sự cân bằng tối ưu tận dụng thế mạnh của cả hai loại node trong khi vẫn duy trì lợi thế cấu trúc của phương pháp dựa trên đồ thị.

% Hệ thống cũng triển khai việc gán trọng số thích ứng dựa trên đặc điểm của truy vấn. Đối với các truy vấn dường như đang tìm kiếm thông tin thực tế cụ thể, trọng số của các phrase node được tăng nhẹ so với các passage node. Ngược lại, đối với các truy vấn dường như yêu cầu hiểu biết ngữ cảnh nhiều hơn hoặc suy luận đa bước, trọng số của passage node được điều chỉnh tăng lên. Cách tiếp cận thích ứng này cho phép hệ thống điều chỉnh chiến lược truy xuất của mình cho phù hợp với nhu cầu thông tin cụ thể được thể hiện trong truy vấn.

Thông qua cơ chế gán trọng số phức tạp này, HippoRAG 2 đạt được một số lợi ích quan trọng. Nó cân bằng ảnh hưởng giữa các phrase node và passage node trong quá trình PageRank, đảm bảo rằng cả độ chính xác khái niệm và sự phong phú về ngữ cảnh đều đóng góp một cách thích hợp vào kết quả cuối cùng. Việc kích hoạt rộng rãi các passage node cải thiện khả năng suy luận đa bước bằng cách cung cấp nhiều con đường thông qua đồ thị tri thức. Hệ thống cho phép điều chỉnh linh hoạt mức độ ảnh hưởng của thông tin ngữ cảnh (passage) và thông tin cô đọng (phrase), có thể được điều chỉnh cho các miền hoặc loại truy vấn khác nhau. Có lẽ quan trọng nhất, cách tiếp cận này cải thiện hiệu suất trên các loại truy vấn khác nhau, từ các câu hỏi thực tế đơn giản đến các tác vụ suy luận phức tạp, làm cho hệ thống trở nên linh hoạt và mạnh mẽ hơn.

\subsection{Module 4: Tìm kiếm Đồ thị PPR (Personalized PageRank)}
Module Tìm kiếm Đồ thị PPR (Personalized PageRank) là thành phần thuật toán cốt lõi cho phép HippoRAG 2 thực hiện suy luận đa bước, phức tạp trên đồ thị tri thức. Module này triển khai một phiên bản sửa đổi của thuật toán PageRank đã được cá nhân hóa để tập trung vào các phần liên quan đến truy vấn của đồ thị, cho phép duyệt qua cấu trúc tri thức một cách nhận biết ngữ cảnh để xác định thông tin phù hợp nhất.

Thuật toán PPR hoạt động dựa trên nguyên tắc cơ bản rằng tầm quan trọng lan truyền qua đồ thị dọc theo các cạnh của nó. Không giống như PageRank tiêu chuẩn, vốn coi tất cả các node như nhau ở trạng thái ban đầu, Personalized PageRank bắt đầu với sự phân bổ tầm quan trọng không đồng đều tập trung vào các seed node đã được xác định và gán trọng số ở module trước. Việc cá nhân hóa này đảm bảo rằng việc khám phá đồ thị của thuật toán được hướng dẫn bởi mức độ liên quan của truy vấn ngay từ đầu.

Công thức toán học của PPR có thể được biểu diễn dưới dạng một quá trình lặp. Gọi $r$ là một vector biểu thị điểm tầm quan trọng của tất cả các node trong đồ thị, được khởi tạo bằng trọng số của seed node. Gọi $M$ là ma trận chuyển tiếp được suy ra từ cấu trúc đồ thị, trong đó $M_{ij}$ biểu thị xác suất chuyển từ node $i$ sang node $j$. Phương trình cập nhật PPR là:

$r_{t+1} = (1-\alpha) \cdot M \cdot r_t + \alpha \cdot p$

Trong đó $\alpha$ là xác suất dịch chuyển tức thời (teleport probability) (thường được đặt trong khoảng từ 0,1 đến 0,2 trong HippoRAG 2), và $p$ là vector cá nhân hóa được suy ra từ trọng số của seed node. Phương trình này nắm bắt hai hành vi chính: với xác suất $(1-\alpha)$, thuật toán tuân theo cấu trúc đồ thị bằng cách chuyển tiếp theo $M$; với xác suất $\alpha$, nó "dịch chuyển tức thời" trở lại các seed node theo trọng số của chúng trong $p$.

Việc triển khai trong HippoRAG 2 bao gồm một số cải tiến phức tạp cho công thức cơ bản này. Đầu tiên, ma trận chuyển tiếp $M$ được xây dựng để phản ánh các loại cạnh khác nhau trong đồ thị tri thức. Các Relation edge, synonym edge và context edge được gán các xác suất chuyển tiếp khác nhau dựa trên ý nghĩa ngữ nghĩa của chúng. Ví dụ, các synonym edge thường nhận được xác suất chuyển tiếp cao hơn các relation edge, phản ánh sự tương đương ngữ nghĩa mạnh mẽ mà chúng đại diện.

Thứ hai, thuật toán sử dụng các hệ số giảm chấn cụ thể theo cạnh (edge-specific damping factors) thay đổi dựa trên loại cạnh và khoảng cách ngữ nghĩa mà chúng đại diện. Điều này cho phép kiểm soát tinh tế hơn cách tầm quan trọng lan truyền qua các loại kết nối khác nhau. Ví dụ, các chuyển tiếp dọc theo context edge (từ passage đến phrase) có thể sử dụng một hệ số giảm chấn khác với các chuyển tiếp dọc theo relation edge (giữa các phrase).

Thứ ba, HippoRAG 2 triển khai một cơ chế phát hiện hội tụ sớm theo dõi tốc độ thay đổi trong thứ hạng của các node thay vì chỉ là điểm thô. Điều này cho phép thuật toán kết thúc khi thứ tự tương đối của các node ổn định, ngay cả khi điểm tuyệt đối vẫn đang thay đổi một chút, cải thiện hiệu quả tính toán mà không làm giảm chất lượng xếp hạng.

Quá trình PPR tiếp tục lặp đi lặp lại cho đến khi hội tụ, thường yêu cầu 30-50 lần lặp đối với hầu hết các truy vấn. Sau khi đạt được sự hội tụ, các node được xếp hạng theo điểm tầm quan trọng cuối cùng của chúng. Các passage node có điểm PageRank cao nhất được coi là phù hợp nhất với truy vấn và được chọn cho giai đoạn tạo câu trả lời cuối cùng.

Cách tiếp cận này mang lại những lợi thế đáng kể so với các phương pháp truy xuất đơn giản hơn. Bằng cách mô phỏng khả năng liên kết trong bộ nhớ con người, PPR có thể xác định các kết nối không rõ ràng từ các thước đo tương đồng trực tiếp. Nó cho phép tìm kiếm thông tin liên quan thông qua suy luận đa bước, theo các chuỗi mối quan hệ kết nối các khái niệm được đề cập trong truy vấn với các khái niệm liên quan khác và cuối cùng là các passage chứa thông tin hữu ích. 

Khả năng duyệt qua cấu trúc đồ thị của thuật toán PPR làm cho nó đặc biệt hiệu quả đối với các truy vấn phức tạp trong đó thông tin liên quan được phân bổ trên nhiều passage hoặc yêu cầu kết nối các mảnh kiến thức khác nhau. Khả năng này rất cần thiết để trả lời các câu hỏi vượt ra ngoài việc truy xuất sự kiện đơn giản và yêu cầu tổng hợp hoặc suy luận trên nhiều nguồn thông tin.



\subsection{Module 4: Tìm kiếm Đồ thị PPR (Personalized PageRank)}
Module Tìm kiếm Đồ thị PPR (Personalized PageRank) là thành phần thuật toán cốt lõi cho phép HippoRAG 2 thực hiện suy luận đa bước, phức tạp trên đồ thị tri thức. Module này triển khai một phiên bản sửa đổi của thuật toán PageRank đã được cá nhân hóa để tập trung vào các phần liên quan đến truy vấn của đồ thị, cho phép duyệt qua cấu trúc tri thức một cách nhận biết ngữ cảnh để xác định thông tin phù hợp nhất.

Thuật toán PPR hoạt động dựa trên nguyên tắc cơ bản rằng tầm quan trọng lan truyền qua đồ thị dọc theo các cạnh của nó. Không giống như PageRank tiêu chuẩn, vốn coi tất cả các node như nhau ở trạng thái ban đầu, Personalized PageRank bắt đầu với sự phân bổ tầm quan trọng không đồng đều tập trung vào các seed node đã được xác định và gán trọng số ở module trước. Việc cá nhân hóa này đảm bảo rằng việc khám phá đồ thị của thuật toán được hướng dẫn bởi mức độ liên quan của truy vấn ngay từ đầu.

Công thức toán học của PPR có thể được biểu diễn dưới dạng một quá trình lặp. Gọi $r$ là một vector biểu thị điểm tầm quan trọng của tất cả các node trong đồ thị, được khởi tạo bằng trọng số của seed node. Gọi $M$ là ma trận chuyển tiếp được suy ra từ cấu trúc đồ thị, trong đó $M_{ij}$ biểu thị xác suất chuyển từ node $i$ sang node $j$. Phương trình cập nhật PPR là:

\begin{equation}
r_{t+1} = (1-\alpha) \cdot M^T \cdot r_t + \alpha \cdot p \label{eq:ppr_update}
\end{equation}

Trong đó $\alpha$ là xác suất dịch chuyển tức thời (teleport probability) (thường được đặt trong khoảng từ 0,1 đến 0,2 trong HippoRAG 2), $p$ là vector cá nhân hóa (đã chuẩn hóa) được suy ra từ trọng số của seed node, và $M^T$ là ma trận chuyển tiếp chuyển vị (transpose), thể hiện cách điểm số được *thu thập* từ các node lân cận. Phương trình này nắm bắt hai hành vi chính: với xác suất $(1-\alpha)$, điểm số của một node ở bước $t+1$ được tính dựa trên điểm số của các node *trỏ đến nó* ở bước $t$; với xác suất $\alpha$, điểm số được "dịch chuyển tức thời" từ vector cá nhân hóa $p$.

Việc triển khai trong HippoRAG 2 bao gồm một số cải tiến phức tạp cho công thức cơ bản này. Đầu tiên, ma trận chuyển tiếp $M$ được xây dựng để phản ánh các loại cạnh khác nhau trong đồ thị tri thức. Các Relation edge, synonym edge và context edge được gán các xác suất chuyển tiếp khác nhau dựa trên ý nghĩa ngữ nghĩa của chúng. Ví dụ, các synonym edge thường nhận được xác suất chuyển tiếp cao hơn các relation edge, phản ánh sự tương đương ngữ nghĩa mạnh mẽ mà chúng đại diện.

Thứ hai, thuật toán sử dụng các hệ số giảm chấn cụ thể theo cạnh (edge-specific damping factors) thay đổi dựa trên loại cạnh và khoảng cách ngữ nghĩa mà chúng đại diện. Điều này cho phép kiểm soát tinh tế hơn cách tầm quan trọng lan truyền qua các loại kết nối khác nhau. Ví dụ, các chuyển tiếp dọc theo context edge (từ passage đến phrase) có thể sử dụng một hệ số giảm chấn khác với các chuyển tiếp dọc theo relation edge (giữa các phrase).

Thứ ba, HippoRAG 2 triển khai một cơ chế phát hiện hội tụ sớm theo dõi tốc độ thay đổi trong thứ hạng của các node thay vì chỉ là điểm thô. Điều này cho phép thuật toán kết thúc khi thứ tự tương đối của các node ổn định, ngay cả khi điểm tuyệt đối vẫn đang thay đổi một chút, cải thiện hiệu quả tính toán mà không làm giảm chất lượng xếp hạng.

Quá trình PPR tiếp tục lặp đi lặp lại cho đến khi hội tụ, thường yêu cầu 30-50 lần lặp đối với hầu hết các truy vấn. Sau khi đạt được sự hội tụ, các node được xếp hạng theo điểm tầm quan trọng cuối cùng của chúng. Các passage node có điểm PageRank cao nhất được coi là phù hợp nhất với truy vấn và được chọn cho giai đoạn tạo câu trả lời cuối cùng.

Cách tiếp cận này mang lại những lợi thế đáng kể so với các phương pháp truy xuất đơn giản hơn. Bằng cách mô phỏng khả năng liên kết trong bộ nhớ con người, PPR có thể xác định các kết nối không rõ ràng từ các thước đo tương đồng trực tiếp. Nó cho phép tìm kiếm thông tin liên quan thông qua suy luận đa bước, theo các chuỗi mối quan hệ kết nối các khái niệm được đề cập trong truy vấn với các khái niệm liên quan khác và cuối cùng là các passage chứa thông tin hữu ích. 

Khả năng duyệt qua cấu trúc đồ thị của thuật toán PPR làm cho nó đặc biệt hiệu quả đối với các truy vấn phức tạp trong đó thông tin liên quan được phân bổ trên nhiều passage hoặc yêu cầu kết nối các mảnh kiến thức khác nhau. Khả năng này rất cần thiết để trả lời các câu hỏi vượt ra ngoài việc truy xuất sự kiện đơn giản và yêu cầu tổng hợp hoặc suy luận trên nhiều nguồn thông tin.

\subsubsection{Ví dụ minh họa Personalized PageRank (Chi tiết hơn)}

Để hiểu rõ hơn cách thuật toán Personalized PageRank (PPR) hoạt động trong HippoRAG 2, chúng ta hãy tiếp tục với ví dụ từ Module 3, nơi chúng ta đã xác định các seed node và trọng số của chúng cho truy vấn "Những tác dụng phụ của thuốc Metformin là gì?".

\textbf{1. Xác định Seed Nodes và Vector Cá nhân hóa (p):}

Như đã tính toán ở Module 3 và ví dụ trước, chúng ta có vector cá nhân hóa \(p\) (đã chuẩn hóa, tổng bằng 1) cho các seed node:
\begin{itemize}
    \item \(p(\text{"buồn nôn"}) \approx 0.458\)
    \item \(p(\text{"Metformin"}) \approx 0.229\)
    \item \(p(\text{"thiếu vitamin B12"}) \approx 0.229\)
    \item \(p(\text{Passage 1}) \approx 0.019\)
    \item \(p(\text{Passage 2}) \approx 0.018\)
    \item \(p(\text{Passage 3}) \approx 0.016\)
    \item \(p(\text{Passage 4}) \approx 0.016\)
    \item \(p(\text{Passage 5}) \approx 0.015\)
    \item \(p(\text{các node khác}) = 0\)
\end{itemize}
Vector \(p\) này đại diện cho nơi mà "người lướt web ngẫu nhiên" có khả năng "dịch chuyển tức thời" (teleport) đến trong mỗi bước, tập trung vào các node liên quan đến truy vấn ban đầu.

\textbf{2. Xây dựng Đồ thị con và Ma trận Chuyển tiếp (M):}

Chúng ta tiếp tục với đồ thị con giả định:

\textit{Nodes:} Metformin (M), buồn nôn (BN), thiếu vitamin B12 (TVB12), vitamin B12 (VB12), mệt mỏi (MM), đau bụng (DB), P1, P2, P3, P4, P5. (Tổng cộng 11 node).

\textit{Edges (ví dụ, giả sử là vô hướng để đơn giản hóa việc tính toán lan truyền):}
\begin{itemize}
    \item (M, BN), (M, TVB12), (M, DB)
    \item (VB12, MM)
    \item (P1, M), (P1, BN)
    \item (P2, M), (P3, M), (P4, M), (P5, M)
    \item (TVB12, VB12)
\end{itemize}

Ma trận chuyển tiếp \(M\) (kích thước 11x11) mô tả xác suất đi từ node \(i\) đến node \(j\). \(M_{ij} = 1 / \text{deg}(i)\) nếu có cạnh giữa \(i\) và \(j\), và bằng 0 nếu không. \(\text{deg}(i)\) là bậc của node \(i\) (số cạnh nối với nó).

Ví dụ tính bậc:
\begin{itemize}
    \item deg(M) = 8 (nối với BN, TVB12, DB, P1, P2, P3, P4, P5)
    \item deg(BN) = 2 (nối với M, P1)
    \item deg(TVB12) = 2 (nối với M, VB12)
    \item deg(VB12) = 2 (nối với TVB12, MM)
    \item deg(MM) = 1 (nối với VB12)
    \item deg(DB) = 1 (nối với M)
    \item deg(P1) = 2 (nối với M, BN)
    \item deg(P2) = 1 (nối với M)
    \item deg(P3) = 1 (nối với M)
    \item deg(P4) = 1 (nối với M)
    \item deg(P5) = 1 (nối với M)
\end{itemize}

Ma trận chuyển tiếp chuyển vị \(M^T\) sẽ được sử dụng trong công thức cập nhật. \(M^T_{ij}\) là xác suất chuyển từ node \(j\) đến node \(i\). Ví dụ, hàng của node DB trong \(M^T\) sẽ chỉ có một giá trị khác 0 tại cột M, là \(M^T_{DB, M} = 1 / \text{deg}(M) = 1/8\).

\textbf{3. Khởi tạo Vector Xếp hạng (r_0):}

Vector xếp hạng \(r\) (kích thước 11x1) lưu trữ điểm số PageRank của mỗi node. Khởi tạo \(r_0 = p\):

\(r_0 = [r_0(M), r_0(BN), r_0(TVB12), r_0(VB12), r_0(MM), r_0(DB), r_0(P1), r_0(P2), r_0(P3), r_0(P4), r_0(P5)]^T\)
\(r_0 \approx [0.229, 0.458, 0.229, 0, 0, 0, 0.019, 0.018, 0.016, 0.016, 0.015]^T\)

\textbf{4. Thực hiện Lặp PPR (Chi tiết Lần lặp 1):}

Sử dụng công thức \ref{eq:ppr_update} với \(\alpha = 0.15\):

\(r_{1} = (1-0.15) \cdot M^T \cdot r_0 + 0.15 \cdot p = 0.85 \cdot M^T \cdot r_0 + 0.15 \cdot p\)

Hãy tính điểm mới cho một vài node ví dụ:

*   **Tính \(r_1(DB)\) (điểm của node "đau bụng"):**
    Node DB chỉ kết nối với node M. Do đó, điểm số lan truyền đến DB chỉ đến từ M.
    \(r_1(DB) = 0.85 \times (M^T_{DB, M} \times r_0(M)) + 0.15 \times p(DB)\)
    \(r_1(DB) = 0.85 \times ( (1 / \text{deg}(M)) \times r_0(M) ) + 0.15 \times 0\) (vì DB không phải seed node nên p(DB)=0)
    \(r_1(DB) = 0.85 \times ( (1/8) \times 0.229 ) \approx 0.85 \times 0.0286 \approx 0.0243\)
    *Giải thích:* Node DB nhận được điểm từ node M (vì có cạnh nối) tỷ lệ với điểm của M (0.229) và nghịch đảo bậc của M (1/8), nhân với hệ số lan truyền (0.85).

*   **Tính \(r_1(M)\) (điểm của node "Metformin"):**
    Node M kết nối với BN, TVB12, DB, P1, P2, P3, P4, P5. Điểm số sẽ lan truyền từ tất cả các node này đến M.
    \(r_1(M) = 0.85 \times ( M^T_{M,BN}r_0(BN) + M^T_{M,TVB12}r_0(TVB12) + M^T_{M,DB}r_0(DB) + M^T_{M,P1}r_0(P1) + ... + M^T_{M,P5}r_0(P5) ) + 0.15 \times p(M)\)
    \(r_1(M) = 0.85 \times ( (1/\text{deg}(BN))r_0(BN) + (1/\text{deg}(TVB12))r_0(TVB12) + (1/\text{deg}(DB))r_0(DB) + (1/\text{deg}(P1))r_0(P1) + ... ) + 0.15 \times 0.229\)
    \(r_1(M) = 0.85 \times ( (1/2)0.458 + (1/2)0.229 + (1/1)0 + (1/2)0.019 + (1/1)0.018 + (1/1)0.016 + (1/1)0.016 + (1/1)0.015 ) + 0.03435\)
    \(r_1(M) = 0.85 \times ( 0.229 + 0.1145 + 0 + 0.0095 + 0.018 + 0.016 + 0.016 + 0.015 ) + 0.03435\)
    \(r_1(M) = 0.85 \times ( 0.418 ) + 0.03435 \approx 0.3553 + 0.03435 \approx 0.3897\)
    *Giải thích:* Node M nhận điểm từ tất cả các hàng xóm của nó (BN, TVB12, P1, P2, P3, P4, P5 - lưu ý r0(DB)=0 nên không đóng góp). Mỗi hàng xóm đóng góp một phần điểm của nó (ví dụ BN đóng góp r0(BN)/deg(BN) = 0.458/2). Tổng các đóng góp này được nhân với hệ số lan truyền (0.85), sau đó cộng thêm phần điểm từ teleport (0.15 * p(M)).

*   **Tính \(r_1(BN)\) (điểm của node "buồn nôn"):**
    Node BN kết nối với M và P1.
    \(r_1(BN) = 0.85 \times ( M^T_{BN, M}r_0(M) + M^T_{BN, P1}r_0(P1) ) + 0.15 \times p(BN)\)
    \(r_1(BN) = 0.85 \times ( (1/\text{deg}(M))r_0(M) + (1/\text{deg}(P1))r_0(P1) ) + 0.15 \times 0.458\)
    \(r_1(BN) = 0.85 \times ( (1/8)0.229 + (1/2)0.019 ) + 0.0687\)
    \(r_1(BN) = 0.85 \times ( 0.0286 + 0.0095 ) + 0.0687\)
    \(r_1(BN) = 0.85 \times 0.0381 + 0.0687 \approx 0.0324 + 0.0687 \approx 0.1011\)
    *Giải thích:* Node BN nhận điểm từ M và P1, cộng thêm phần lớn điểm từ teleport vì nó là seed node quan trọng nhất (p(BN) cao nhất).

Sau lần lặp 1, vector \(r_1\) sẽ có các giá trị mới. Chúng ta thấy điểm của M tăng lên đáng kể do nhận được nhiều đóng góp từ các hàng xóm, trong khi điểm của BN giảm đi vì nó "cho đi" nhiều điểm hơn là nhận lại từ hàng xóm (nhưng vẫn được bù đắp bởi teleport). Các node ban đầu có điểm 0 như DB đã bắt đầu nhận được điểm.

\textit{Lần lặp 2 (Tính r_2):}

\(r_2 = 0.85 \cdot M^T \cdot r_1 + 0.15 \cdot p\)

Quá trình tính toán tương tự như lần lặp 1, nhưng bây giờ sử dụng vector \(r_1\) làm đầu vào. Ví dụ, node MM ("mệt mỏi") bây giờ sẽ nhận được điểm từ VB12, và VB12 sẽ nhận được điểm từ TVB12 (vốn đã nhận điểm từ M ở lần lặp 1). Điểm số tiếp tục lan truyền xa hơn.

\textbf{5. Hội tụ và Kết quả:}

Quá trình lặp (tính \(r_3, r_4, ...\)) tiếp tục cho đến khi vector \(r\) hội tụ, nghĩa là sự thay đổi giữa \(r_{t+1}\) và \(r_t\) rất nhỏ. Kết quả cuối cùng là vector điểm PPR ổn định.

Các node có điểm PPR cao nhất được coi là quan trọng nhất. Đặc biệt, chúng ta sẽ xem xét điểm của các **Passage Nodes** (P1 đến P5). Passage nào có điểm PPR cuối cùng cao nhất sẽ được ưu tiên đưa vào Module 5 để tạo câu trả lời.

Trong ví dụ này, chúng ta có thể dự đoán:
- Passage P1 có khả năng cao sẽ có điểm PPR cao vì nó kết nối với cả M và BN (hai node có điểm khởi tạo và/hoặc nhận được điểm cao sớm).
- Các passage P2-P5 chỉ kết nối với M, nên điểm của chúng sẽ phụ thuộc vào điểm của M và điểm teleport ban đầu của chúng.
- Các phrase node như DB, VB12, MM sẽ nhận được điểm thông qua các bước nhảy, thể hiện khả năng suy luận đa bước của PPR.

Ví dụ chi tiết này cho thấy cách PPR kết hợp cả sự lan truyền điểm số dựa trên cấu trúc đồ thị (thông qua \(M^T\)) và sự ưu tiên dựa trên truy vấn (thông qua \(p\)) để xác định tầm quan trọng của từng node.

\subsection{Module 5: QA Reading}
Module QA Reading đại diện cho giai đoạn cuối cùng trong quy trình của HippoRAG 2, nơi thông tin được truy xuất được tổng hợp thành một phản hồi mạch lạc và chính xác cho truy vấn của người dùng. Module này tận dụng sức mạnh của các Mô hình Ngôn ngữ Lớn để đọc, diễn giải và tích hợp thông tin từ các đoạn văn được xác định là phù hợp nhất bởi Tìm kiếm Đồ thị PPR.

Quá trình bắt đầu với việc LLM đọc các đoạn văn được xếp hạng cao nhất từ thuật toán PPR. Không giống như các phương pháp trích xuất đơn giản hơn, LLM không chỉ sao chép thông tin từ các đoạn văn này mà còn tham gia vào một quá trình hiểu và tổng hợp phức tạp. Nó phân tích nội dung của mỗi đoạn văn, xác định thông tin liên quan, giải quyết các mâu thuẫn hoặc dư thừa tiềm ẩn và tích hợp những hiểu biết này thành một phản hồi mạch lạc.

Phương pháp này mang lại một số lợi ích chính góp phần vào hiệu quả tổng thể của HippoRAG 2. Bằng cách tận dụng khả năng tổng hợp và suy luận của LLM, hệ thống có thể tạo ra các câu trả lời chất lượng cao vượt ra ngoài việc trích xuất thông tin đơn giản. LLM có thể suy ra các kết nối giữa các sự kiện, khái quát hóa từ các ví dụ cụ thể và trình bày thông tin một cách rõ ràng và phù hợp với ngữ cảnh. Bằng cách cung cấp ngữ cảnh đầy đủ cho LLM thông qua các đoạn văn được chọn lọc cẩn thận, hệ thống đảm bảo rằng mô hình có quyền truy cập vào tất cả thông tin cần thiết để tạo ra một phản hồi chính xác và toàn diện.

% Hiệu quả của phương pháp này được chứng minh bằng các kết quả thực nghiệm, với HippoRAG 2 đạt điểm F1 cao hơn 2,8% so với phương pháp dense retrieval tốt nhất (NV-Embed-v2) trên các bộ dữ liệu benchmark. Có lẽ quan trọng nhất, module này hiệu quả trên các loại nhiệm vụ khác nhau, bao gồm factual memory (truy xuất sự kiện đơn giản), sense-making (hiểu các câu chuyện phức tạp) và associativity (kết nối thông tin liên quan), làm cho nó trở thành một giải pháp linh hoạt cho một loạt các tình huống trả lời câu hỏi.

% \section{Các đóng góp chính của đồ án}
% \subsection{Đổi mới Kỹ thuật}
% Trong luận văn này, tôi khám phá và mở rộng HippoRAG 2, một framework giới thiệu một số đổi mới kỹ thuật quan trọng cho lĩnh vực hệ thống retrieval-augmented generation. Công việc của tôi đặc biệt tập trung vào việc điều chỉnh và đánh giá những đổi mới này cho dữ liệu tiếng Việt, nhấn mạnh vào các tác vụ lập luận đa bước.

% Phương pháp Dense-Sparse Integration đại diện cho một giải pháp mới cho thách thức biểu diễn kiến thức. Bằng cách kết hợp mã hóa thưa thớt (phrase node) và mã hóa dày đặc (passage node), HippoRAG 2 giải quyết sự đánh đổi giữa khái niệm và ngữ cảnh tồn tại trong nhiều hệ thống kiến thức. Sự tích hợp này cho phép hệ thống cân bằng giữa suy luận hiệu quả và truy xuất thông tin chi tiết, mô phỏng khả năng của não người làm việc với cả khái niệm trừu tượng và ký ức tình tiết chi tiết. Biểu diễn thưa thớt tạo điều kiện cho việc lưu trữ hiệu quả và suy luận nhanh chóng về các khái niệm, trong khi biểu diễn dày đặc bảo toàn sự phong phú về ngữ cảnh có thể bị mất trong các định dạng cô đọng hơn.

% Phương pháp Query to Triple đánh dấu một sự khác biệt đáng kể so với các phương pháp truy xuất tập trung vào thực thể truyền thống. Thay vì chỉ tập trung vào các thực thể được đề cập trong truy vấn, phương pháp này so khớp toàn bộ truy vấn với các triple trong đồ thị tri thức. Điều này cung cấp ngữ cảnh phong phú hơn để hiểu ý định của truy vấn và cải thiện hiệu suất truy xuất trung bình 12,5% so với các phương pháp dựa trên thực thể. Bằng cách xem xét các mối quan hệ được thể hiện trong truy vấn, không chỉ các thực thể, hệ thống có thể điều chỉnh việc truy xuất tốt hơn với nhu cầu thông tin của người dùng.

% Thành phần Recognition Memory lấy cảm hứng từ các quá trình bộ nhớ của con người để tăng cường việc lọc thông tin. Bằng cách triển khai một cơ chế mô phỏng cách con người nhận ra thông tin liên quan khi được trình bày với nó, HippoRAG 2 có thể phân biệt hiệu quả hơn giữa các triple liên quan và không liên quan. Điều này giảm nhiễu trong quá trình truy xuất và cải thiện chất lượng của các seed node cho thuật toán PageRank, dẫn đến kết quả tập trung và chính xác hơn.

% Phương pháp Balanced Reset Probabilities giới thiệu một phương pháp phức tạp để kiểm soát ảnh hưởng của các loại node khác nhau trong thuật toán Personalized PageRank. Bằng cách sử dụng hệ số trọng số để cân bằng giữa phrase node và passage node, hệ thống có thể tối ưu hóa hiệu suất trên các loại truy vấn khác nhau. Cách tiếp cận tinh tế này đối với việc duyệt đồ thị cho phép HippoRAG 2 tận dụng cả các mối quan hệ có cấu trúc giữa các khái niệm và thông tin ngữ cảnh phong phú trong các đoạn văn, dẫn đến việc truy xuất toàn diện và chính xác hơn.

% Đóng góp của tôi tập trung vào việc điều chỉnh những đổi mới này cho dữ liệu tiếng Việt, đặc biệt thông qua việc tinh chỉnh các mô hình truy xuất và xếp hạng lại cho các tác vụ trả lời câu hỏi đa bước tiếng Việt. Việc điều chỉnh này bao gồm giải quyết các thách thức cụ thể của ngôn ngữ và đánh giá hiệu quả của framework HippoRAG 2 trong một bối cảnh ngôn ngữ mới.

% \subsection{Cải thiện Hiệu suất}
% Nghiên cứu của tôi xem xét những cải thiện hiệu suất đạt được bởi HippoRAG 2 trên một loạt các tác vụ benchmark, đặc biệt tập trung vào việc áp dụng nó cho dữ liệu tiếng Việt và các tác vụ lập luận đa bước.

% Hiệu suất toàn diện của hệ thống trên các loại benchmark khác nhau làm cho nó nổi bật so với các phương pháp trước đây. Trong khi các phương pháp RAG tăng cường cấu trúc trước đây thường xuất sắc trong một lĩnh vực nhưng suy giảm ở các lĩnh vực khác, HippoRAG 2 duy trì hiệu suất mạnh mẽ trên các tác vụ factual memory, sense-making và associativity. Tính linh hoạt này làm cho nó phù hợp với một loạt các ứng dụng mà không yêu cầu tối ưu hóa cụ thể cho từng tác vụ.

% Trong các tác vụ bộ nhớ liên kết, kiểm tra khả năng kết nối thông tin liên quan trên các tài liệu của hệ thống, HippoRAG 2 đạt được cải thiện 7% so với mô hình embedding tiên tiến nhất. Điều này chứng tỏ khả năng vượt trội của nó trong suy luận đa bước, nơi thông tin liên quan phải được xác định thông qua các chuỗi mối quan hệ thay vì khớp trực tiếp.

% Hệ thống cũng cho thấy những cải thiện ấn tượng về chất lượng truy xuất, với Recall@5 tăng 5,0% và 13,9% trên các bộ dữ liệu MuSiQue và 2Wiki so với dense retriever mạnh nhất. Những cải thiện này đặc biệt đáng chú ý trong các tác vụ suy luận đa bước, nơi hệ thống phải điều hướng các mối quan hệ phức tạp để tìm thông tin liên quan.

% Một thế mạnh quan trọng khác của HippoRAG 2 là tính linh hoạt của nó trên các retriever và mô hình ngôn ngữ khác nhau. Hệ thống thể hiện sự mạnh mẽ khi được sử dụng với các dense retriever khác nhau và tương thích với cả LLM mã nguồn mở và độc quyền. Tính linh hoạt này cho phép sử dụng rộng rãi trên các môi trường tính toán và yêu cầu ứng dụng khác nhau, làm cho phương pháp này dễ tiếp cận và dễ thích ứng hơn.

% Công việc của tôi mở rộng những đánh giá này sang dữ liệu tiếng Việt, cụ thể là sử dụng bộ dữ liệu VIMQA, để đánh giá mức độ chuyển đổi của những cải thiện hiệu suất này sang một bối cảnh ngôn ngữ khác. Đánh giá này cung cấp những hiểu biết có giá trị về khả năng áp dụng xuyên ngôn ngữ của framework HippoRAG 2 và hiệu quả của nó đối với các tác vụ lập luận đa bước trong tiếng Việt.

% \subsection{Đóng góp Lý thuyết}
% Ngoài những đổi mới kỹ thuật và cải thiện hiệu suất, HippoRAG 2 còn có một số đóng góp lý thuyết quan trọng cho lĩnh vực trí tuệ nhân tạo và điện toán nhận thức. Nghiên cứu của tôi xem xét những đóng góp này và khám phá ý nghĩa của chúng đối với xử lý ngôn ngữ tiếng Việt và lập luận đa bước.

% Thiết kế lấy cảm hứng từ thần kinh học của HippoRAG 2 thúc đẩy lĩnh vực bằng cách triển khai các thành phần mô phỏng chặt chẽ hơn các quá trình bộ nhớ của con người. Bằng cách kết hợp các yếu tố như mã hóa thưa thớt và dày đặc, bộ nhớ nhận diện và truy xuất liên kết, hệ thống đại diện cho một bước tiến hướng tới các kiến trúc AI hợp lý hơn về mặt nhận thức. Sự phù hợp này với các quá trình nhận thức của con người không chỉ cải thiện hiệu suất mà còn đóng góp vào hiểu biết của chúng ta về cách các hệ thống tính toán có thể triển khai các chức năng bộ nhớ giống con người.

% HippoRAG 2 cung cấp một phương pháp tiếp cận đầy hứa hẹn cho continual learning không tham số cho LLM, giải quyết một thách thức cơ bản trong phát triển AI. Bằng cách cho phép các mô hình liên tục thu thập, tổ chức và tận dụng kiến thức mà không cần sửa đổi tham số của chúng, framework cung cấp một giải pháp có thể mở rộng cho vấn đề tích hợp thông tin mới vào các hệ thống AI. Cách tiếp cận này tránh được các vấn đề quên lãng thảm khốc gây khó khăn cho nhiều phương pháp continual learning tham số trong khi vẫn duy trì tính linh hoạt và khả năng thích ứng.

% Có lẽ quan trọng nhất, HippoRAG 2 đại diện cho một bước tiến hướng tới việc tạo ra các hệ thống AI với khả năng bộ nhớ giống con người hơn. Bằng cách giải quyết cả khả năng ghi nhớ sự kiện và khả năng suy luận phức tạp trong một framework thống nhất, hệ thống chứng minh cách AI có thể vượt ra ngoài việc truy xuất thông tin đơn giản để hướng tới việc sử dụng kiến thức phức tạp hơn. Cách tiếp cận toàn diện này đối với bộ nhớ và suy luận đưa các hệ thống AI đến gần hơn với các khả năng nhận thức tích hợp đặc trưng cho trí thông minh của con người.

% Nghiên cứu của tôi đóng góp vào sự hiểu biết lý thuyết này bằng cách xem xét cách các nguyên tắc nhận thức này áp dụng trên các ngôn ngữ, đặc biệt là trong bối cảnh các tác vụ lập luận đa bước tiếng Việt. Góc nhìn xuyên ngôn ngữ này cung cấp những hiểu biết có giá trị về tính phổ quát của các nguyên tắc nhận thức này và khả năng áp dụng của chúng cho các tác vụ xử lý ngôn ngữ đa dạng.

% \section{Phân tích So sánh với Các Phương pháp Khác}
% \subsection{So sánh với RAG Truyền thống}
% Các hệ thống RAG truyền thống chủ yếu dựa vào vector embedding để truy xuất, điều này hạn chế khả năng nắm bắt bản chất kết nối của bộ nhớ con người. Mặc dù hiệu quả đối với việc truy xuất thông tin đơn giản, các hệ thống này gặp khó khăn với các tác vụ suy luận phức tạp hơn đòi hỏi kết nối nhiều mảnh thông tin hoặc hiểu các ngữ cảnh rộng hơn.

% HippoRAG 2 giải quyết những hạn chế này thông qua một số cải tiến chính. Khả năng liên kết tăng cường của nó cho phép nó xuất sắc trong các tác vụ đòi hỏi kết nối giữa nhiều mảnh thông tin. Trong khi RAG truyền thống gặp khó khăn với suy luận đa bước, HippoRAG 2 đạt được cải thiện trung bình 7 điểm so với RAG tiêu chuẩn trong các tác vụ liên kết. Sự cải thiện này xuất phát từ phương pháp dựa trên đồ thị có thể theo các chuỗi mối quan hệ để xác định thông tin liên quan có thể không được khớp trực tiếp bằng sự tương đồng vector.

% Hệ thống cũng thể hiện khả năng hiểu được cải thiện, hiểu và xử lý tốt hơn các ngữ cảnh phức tạp, dài so với các hệ thống RAG truyền thống. Điều này đặc biệt có giá trị đối với các ứng dụng liên quan đến hiểu câu chuyện hoặc phân tích tài liệu phức tạp, nơi thông tin phải được diễn giải trong ngữ cảnh rộng hơn của nó.

% Một lợi thế khác của HippoRAG 2 là tính linh hoạt của nó trên các backend truy xuất khác nhau. Framework có thể được sử dụng với nhiều dense retriever khác nhau, liên tục cải thiện hiệu suất so với dense retrieval thuần túy bất kể mô hình embedding cụ thể nào được sử dụng. Khả năng thích ứng này làm cho nó trở thành một cải tiến thiết thực cho các hệ thống RAG hiện có, cho phép các tổ chức tận dụng các khoản đầu tư hiện tại của họ vào công nghệ embedding trong khi vẫn thu được lợi ích của phương pháp truy xuất phức tạp hơn.

% Trong nghiên cứu của mình, tôi xem xét cách những lợi thế này chuyển đổi sang xử lý ngôn ngữ tiếng Việt, so sánh hiệu suất của HippoRAG 2 với các phương pháp RAG truyền thống trên các tác vụ lập luận đa bước tiếng Việt. So sánh này cung cấp những hiểu biết có giá trị về hiệu quả của các chiến lược truy xuất khác nhau cho dữ liệu tiếng Việt và những thách thức và cơ hội cụ thể do bối cảnh ngôn ngữ này đặt ra.

% \subsection{So sánh với Các Phương pháp RAG Tăng cường Cấu trúc}
% Một số phương pháp RAG tăng cường cấu trúc đã được đề xuất để giải quyết hạn chế trong RAG truyền thống, mỗi phương pháp có cách tiếp cận riêng để tăng cường khả năng truy xuất. HippoRAG 2 mang lại những lợi thế khác biệt so với các phương pháp thay thế này, mà tôi đánh giá trong bối cảnh xử lý ngôn ngữ tiếng Việt.

% RAPTOR và GraphRAG đều sử dụng LLM để tạo tóm tắt tích hợp thông tin từ các kho ngữ liệu truy xuất của chúng. Mặc dù phương pháp này có thể hiệu quả đối với một số tác vụ nhất định, hiệu suất của chúng giảm đáng kể trong các tác vụ QA đơn giản và đa bước do nhiễu được đưa vào kho ngữ liệu truy xuất. Quá trình tóm tắt có thể gây ra sự không chính xác hoặc thiếu sót lan truyền qua hệ thống, ảnh hưởng đến chất lượng của câu trả lời cuối cùng. HippoRAG 2 tránh vấn đề này bằng cách làm việc trực tiếp với các đoạn văn và triple gốc, duy trì tính trung thực của thông tin trong suốt quá trình.

% LightRAG có một cách tiếp cận khác, sử dụng đồ thị tri thức để mở rộng kho ngữ liệu truy xuất. Mặc dù điều này có thể giúp xác định thêm thông tin liên quan, nó cũng làm tăng nguy cơ bao gồm nội dung không liên quan. Ngược lại, HippoRAG 2 sử dụng KG để hỗ trợ chính quá trình truy xuất, hướng dẫn tìm kiếm đến thông tin liên quan thay vì chỉ đơn giản là mở rộng không gian tìm kiếm. Cách tiếp cận tập trung này làm giảm nhiễu do LLM tạo ra và dẫn đến kết quả truy xuất chính xác hơn.

% So với framework HippoRAG ban đầu, HippoRAG 2 giải quyết một số hạn chế chính. Nó giải quyết các vấn đề liên quan đến mất ngữ cảnh trong quá trình indexing và inference bằng cách tích hợp các passage node trực tiếp vào đồ thị tri thức. Nó cũng cải thiện việc khớp ngữ nghĩa thông qua phương pháp Query to Triple và lọc bộ nhớ nhận diện. Những cải tiến này cho phép HippoRAG 2 duy trì thế mạnh suy luận liên kết của framework ban đầu trong khi mở rộng khả năng của nó sang các loại tác vụ khác.

% Nghiên cứu của tôi đánh giá những lợi thế so sánh này đặc biệt trong bối cảnh xử lý ngôn ngữ tiếng Việt, xem xét cách các phương pháp RAG tăng cường cấu trúc khác nhau hoạt động trên các tác vụ lập luận đa bước tiếng Việt. Đánh giá này cung cấp những hiểu biết về phương pháp nào hiệu quả nhất cho dữ liệu tiếng Việt và những thách thức cụ thể phát sinh khi áp dụng các phương pháp này vào một bối cảnh ngôn ngữ mới.

% \subsection{Kết quả Thực nghiệm}
% Các thí nghiệm của tôi chứng minh hiệu suất của HippoRAG 2 trên một loạt các tác vụ benchmark, đặc biệt tập trung vào dữ liệu tiếng Việt từ bộ dữ liệu VIMQA. Những kết quả này cung cấp xác nhận thực nghiệm về hiệu quả và tính linh hoạt của framework trong một bối cảnh ngôn ngữ mới.

% Trên tất cả các loại benchmark, HippoRAG 2 đạt điểm F1 cao, cho thấy khả năng tạo ra các câu trả lời chính xác và phù hợp trên các loại câu hỏi khác nhau. Hiệu suất nhất quán này đặc biệt đáng chú ý vì nhiều phương pháp cạnh tranh cho thấy sự thay đổi đáng kể về hiệu quả trên các tác vụ khác nhau.

% Trên các bộ dữ liệu thách thức cụ thể, HippoRAG 2 cho thấy những cải thiện ấn tượng so với các phương pháp tiên tiến nhất. Nó vượt trội NV-Embed-v2 9,5% F1 trên 2Wiki và 3,1% trên bộ dữ liệu thách thức LV-Eval, chứng minh hiệu quả của nó trong các tác vụ suy luận phức tạp và khả năng chống rò rỉ kiến thức.

% Hệ thống cho thấy những cải thiện nhất quán so với tất cả các phương pháp khác trên gần như tất cả các cài đặt, xác nhận phương pháp tiếp cận lấy cảm hứng từ tâm lý thần kinh học của nó. Sự nhất quán này là một thế mạnh quan trọng, vì nó cho thấy rằng những lợi thế của framework là cơ bản chứ không phải cụ thể cho từng tác vụ hoặc phụ thuộc vào bộ dữ liệu.

% Một phát hiện quan trọng khác là HippoRAG 2 duy trì hiệu suất mạnh mẽ bất kể dense retriever cụ thể nào được sử dụng. Điều này cho thấy rằng những cải tiến của framework đến từ những đổi mới kiến trúc của nó chứ không chỉ đơn giản là tận dụng một retriever cơ sở mạnh hơn, và những lợi ích này có thể được thực hiện trên các backend truy xuất khác nhau.

% Nghiên cứu của tôi mở rộng những đánh giá này sang dữ liệu tiếng Việt, xem xét mức độ chuyển đổi của những lợi thế hiệu suất này sang một bối cảnh ngôn ngữ mới. Đánh giá này cung cấp những hiểu biết có giá trị về khả năng áp dụng xuyên ngôn ngữ của framework HippoRAG 2 và hiệu quả của nó đối với các tác vụ lập luận đa bước trong tiếng Việt.

% \section{Hướng Phát triển Tương lai}
% Mặc dù nghiên cứu của tôi chứng minh hiệu quả của HippoRAG 2 đối với xử lý ngôn ngữ tiếng Việt và các tác vụ lập luận đa bước, một số hướng nghiên cứu tương lai đầy hứa hẹn có thể nâng cao hơn nữa khả năng và ứng dụng của nó.

% Khả năng Bộ nhớ Episodic tăng cường có thể được phát triển bằng cách khám phá các phương pháp truy xuất dựa trên đồ thị được thiết kế đặc biệt cho các cuộc hội thoại dài. Điều này sẽ cho phép hệ thống duy trì ngữ cảnh qua các tương tác kéo dài, tham chiếu đến các phần trước của cuộc hội thoại khi có liên quan và xây dựng sự hiểu biết mạch lạc hơn về nhu cầu thông tin của người dùng theo thời gian.

% Tích hợp Đa phương tiện đại diện cho một biên giới thú vị khác, mở rộng framework để kết hợp thông tin từ các phương thức khác nhau như văn bản, hình ảnh, âm thanh và video vào một đồ thị tri thức thống nhất. Điều này sẽ cho phép truy xuất và tổng hợp thông tin toàn diện hơn trên các loại nội dung khác nhau, phù hợp hơn với bản chất đa phương tiện của kiến thức con người.

% Cập nhật Kiến thức Động sẽ giải quyết thách thức cập nhật hiệu quả đồ thị tri thức khi có thông tin mới. Phát triển cơ chế cập nhật tăng dần mà không yêu cầu xây dựng lại hoàn toàn đồ thị sẽ làm cho hệ thống trở nên thiết thực hơn cho các ứng dụng thực tế nơi kiến thức phát triển liên tục.

% Khả năng Cá nhân hóa có thể điều chỉnh framework để kết hợp kiến thức và sở thích cụ thể của người dùng, dẫn đến các phản hồi phù hợp hơn. Điều này có thể liên quan đến việc duy trì các thành phần được cá nhân hóa riêng biệt của đồ thị tri thức cho những người dùng khác nhau hoặc điều chỉnh các quy trình truy xuất và xếp hạng dựa trên lịch sử và sở thích của người dùng.

% Cải thiện Hiệu quả Tính toán sẽ làm cho framework dễ tiếp cận hơn cho các môi trường hạn chế tài nguyên. Tối ưu hóa các thuật toán xây dựng, lưu trữ và duyệt đồ thị có thể giảm yêu cầu tính toán trong khi vẫn duy trì hiệu suất, cho phép hệ thống được triển khai trong một phạm vi cài đặt rộng hơn.

% Đối với xử lý ngôn ngữ tiếng Việt cụ thể, công việc trong tương lai có thể tập trung vào việc phát triển các mô hình embedding chuyên biệt hơn, cải thiện việc trích xuất triple cho cú pháp tiếng Việt và mở rộng phạm vi các bộ dữ liệu benchmark để đánh giá. Những cải tiến này sẽ nâng cao hơn nữa hiệu quả của framework cho các ứng dụng tiếng Việt và cung cấp một nền tảng vững chắc hơn cho lập luận đa bước trong bối cảnh ngôn ngữ này.

% \section{Kết luận}
% Luận văn này đã khám phá việc ứng dụng và mở rộng HippoRAG 2 cho các tác vụ xử lý ngôn ngữ tiếng Việt và lập luận đa bước. HippoRAG 2 đại diện cho một bước tiến đáng kể trong việc phát triển các hệ thống RAG gần hơn với bộ nhớ dài hạn của con người. Bằng cách kết hợp thuật toán Personalized PageRank với tích hợp passage sâu hơn và sử dụng LLM hiệu quả hơn trong quá trình online, framework đạt được những cải thiện toàn diện so với các phương pháp RAG tiêu chuẩn trên các tác vụ factual, sense-making, và associative memory.

% Thiết kế lấy cảm hứng từ thần kinh học của framework, kết hợp các yếu tố như dense-sparse integration, recognition memory, và balanced reset probabilities, cho phép nó vượt qua những hạn chế trong các phương pháp trước đây và đạt được hiệu suất tốt nhất trên các benchmark đa dạng. Triết lý thiết kế này, dựa trên những hiểu biết sâu sắc từ các quá trình bộ nhớ của con người, cung cấp một nền tảng vững chắc để phát triển các hệ thống AI với khả năng nhận thức giống con người hơn.

% Nghiên cứu của tôi đã chứng minh hiệu quả của phương pháp này đối với dữ liệu tiếng Việt, đặc biệt là đối với các tác vụ lập luận đa bước sử dụng bộ dữ liệu VIMQA. Bằng cách tinh chỉnh các thành phần truy xuất và xếp hạng lại cho xử lý ngôn ngữ tiếng Việt, tôi đã chỉ ra rằng những lợi ích của framework HippoRAG 2 có thể được mở rộng sang các bối cảnh ngôn ngữ mới, cung cấp những hiểu biết có giá trị về khả năng áp dụng xuyên ngôn ngữ của nó.

% Công trình này không chỉ thúc đẩy lĩnh vực retrieval-augmented generation mà còn mở đường cho continual learning không tham số cho LLM, đưa các hệ thống AI đến gần hơn với khả năng bộ nhớ giống con người. Bằng cách cung cấp một cơ chế để liên tục tích hợp kiến thức mới mà không cần sửa đổi tham số mô hình, HippoRAG 2 giải quyết một trong những thách thức cơ bản trong việc phát triển các hệ thống AI thích ứng.

% Khi nghiên cứu trong lĩnh vực này tiếp tục phát triển, những hiểu biết thu được từ việc áp dụng HippoRAG 2 vào xử lý ngôn ngữ tiếng Việt sẽ đóng góp vào việc phát triển các hệ thống bộ nhớ ngày càng tinh vi cho AI, cuối cùng nâng cao khả năng liên tục thu thập, tổ chức và tận dụng kiến thức theo cách gần hơn với trí thông minh của con người. Cách tiếp cận toàn diện của framework đối với việc biểu diễn, truy xuất và sử dụng kiến thức mở ra những khả năng mới cho các ứng dụng AI trên các lĩnh vực và ngôn ngữ đòi hỏi xử lý thông tin phức tạp.




\end{document}
