\documentclass[../main.tex]{subfiles}
\begin{document}

\section{Tổng quan}
Luận văn này khám phá việc ứng dụng và mở rộng HippoRAG 2, một framework Retrieval-Augmented Generation (RAG) tiên tiến lấy cảm hứng từ cơ chế bộ nhớ dài hạn của con người. Được phát triển bởi các nhà nghiên cứu tại OSU-NLP Group, HippoRAG 2 được thiết kế để giúp các Mô hình Ngôn ngữ Lớn (LLM) liên tục tích hợp kiến thức từ các tài liệu bên ngoài. Framework này giải quyết những hạn chế chính trong các hệ thống RAG truyền thống bằng cách kết hợp các thành phần lấy cảm hứng từ thần kinh học, mô phỏng quá trình ghi nhớ của con người. Trong công trình này, tôi nghiên cứu và mở rộng HippoRAG 2, đặc biệt tập trung vào việc áp dụng nó cho dữ liệu tiếng Việt và các tác vụ lập luận đa bước.

HippoRAG 2 hoạt động trong hai giai đoạn chính: giai đoạn Offline Indexing để xây dựng bộ nhớ và giai đoạn Online Retrieval \& QA để truy xuất thông tin và tạo phản hồi. Giai đoạn Offline Indexing xây dựng hệ thống bộ nhớ dài hạn cho framework bằng cách tạo ra một Đồ thị Tri thức (Knowledge Graph - KG) từ các tài liệu văn bản, chuyển đổi văn bản thô thành một biểu diễn có cấu trúc, nắm bắt cả thông tin khái niệm và chi tiết ngữ cảnh. Giai đoạn Online Retrieval \& QA sử dụng KG đã xây dựng này để truy xuất thông tin dựa trên truy vấn của người dùng và tạo ra các phản hồi thông minh, sử dụng các thuật toán phức tạp để điều hướng cấu trúc tri thức và trích xuất thông tin liên quan.

Luồng công việc tổng thể được minh họa trong Hình 1, thể hiện hai giai đoạn chính này. HippoRAG 2 được xây dựng dựa trên framework HippoRAG ban đầu nhưng giới thiệu một số cải tiến quan trọng nhằm tăng cường sự phù hợp với cơ chế bộ nhớ của con người. Những cải tiến này bao gồm việc tích hợp liền mạch thông tin khái niệm và ngữ cảnh, truy xuất nhận thức ngữ cảnh tốt hơn, và bộ nhớ nhận diện để cải thiện việc lựa chọn nút hạt giống. Nghiên cứu của tôi xem xét chi tiết các cơ chế này và khám phá hiệu quả của chúng khi áp dụng cho dữ liệu tiếng Việt.

\section{Offline Indexing – Giai đoạn Xây dựng Bộ nhớ}
Trong giai đoạn Offline Indexing, nhiệm vụ chính là xây dựng hệ thống bộ nhớ dài hạn bằng cách tạo ra một Đồ thị Tri thức (KG) từ các tài liệu văn bản. Các module trong giai đoạn này làm việc cùng nhau để trích xuất, xử lý và tổ chức thông tin một cách có cấu trúc nhằm hỗ trợ các bước truy xuất trong tương lai. Giai đoạn này rất quan trọng vì nó quyết định chất lượng và hiệu quả của các hoạt động truy xuất tiếp theo.

\subsection{Module 1: Phân đoạn Tài liệu}
Phân đoạn tài liệu là một bước quan trọng nhằm chia nhỏ tài liệu gốc thành các đoạn ngắn hơn, mỗi đoạn mang một ý nghĩa logic riêng biệt. Quá trình này đảm bảo rằng thông tin được tổ chức thành các đơn vị dễ quản lý, có thể được xử lý và truy xuất hiệu quả. HippoRAG 2 sử dụng các Mô hình Ngôn ngữ Lớn (LLM), như Qwen-1.5B-Instruct, để nâng cao khả năng phân đoạn vượt trội so với các phương pháp dựa trên quy tắc truyền thống.

Quá trình phân đoạn bắt đầu bằng việc tách văn bản thành các câu riêng biệt trong khi vẫn giữ nguyên ý nghĩa của chúng. Không giống như việc chia câu đơn giản, hệ thống sử dụng LLM để đánh giá ngữ cảnh và đưa ra quyết định sáng suốt về việc hợp nhất hay tách câu dựa trên cấu trúc logic của chúng. Phương pháp tiếp cận nhận thức ngữ cảnh này tạo ra các đoạn văn mạch lạc, ngắn gọn và dễ quản lý, được tối ưu hóa cho việc trích xuất triple tiếp theo.

Quá trình phân đoạn này đặc biệt quan trọng vì nó ảnh hưởng trực tiếp đến chất lượng của việc trích xuất triple và xây dựng đồ thị tri thức sau này. Bằng cách tạo ra các đoạn văn có tính liên kết logic, hệ thống đảm bảo rằng các triple được trích xuất duy trì được ngữ cảnh và mối quan hệ ngữ nghĩa phù hợp. Việc phân đoạn kém có thể dẫn đến thông tin bị phân mảnh hoặc mất các mối quan hệ ngữ cảnh, làm suy yếu hiệu quả của toàn bộ framework.

\subsubsection{Tinh chỉnh Mô hình Retriever và Reranking}
Trong phần mở rộng HippoRAG 2 của tôi, tôi đặc biệt tập trung vào việc tinh chỉnh các quy trình truy xuất và xếp hạng lại cho dữ liệu tiếng Việt. Hiệu quả của cả hai thành phần được tăng cường đáng kể thông qua việc tinh chỉnh trên dữ liệu cụ thể của miền. Cách tiếp cận dựa trên dữ liệu này cho phép hệ thống thích ứng với các miền kiến thức và mẫu truy vấn cụ thể, dẫn đến việc truy xuất thông tin chính xác và phù hợp hơn.

Đối với thành phần retriever, phương pháp tinh chỉnh của tôi bao gồm một quy trình nhiều giai đoạn sử dụng dữ liệu huấn luyện được tuyển chọn cẩn thận. Ban đầu, một bộ dữ liệu gồm các cặp truy vấn-đoạn văn được xây dựng, trong đó mỗi truy vấn được liên kết với các đoạn văn liên quan (ví dụ dương tính) và các đoạn văn không liên quan (ví dụ âm tính). Mô hình retriever, thường dựa trên kiến trúc bộ mã hóa kép (dual-encoder), sau đó được tinh chỉnh bằng cách sử dụng các mục tiêu học tương phản như mất mát InfoNCE. Việc huấn luyện này khuyến khích mô hình tạo ra các embedding đặt các truy vấn và đoạn văn có liên quan về mặt ngữ nghĩa gần nhau hơn trong không gian vector trong khi đẩy nội dung không liên quan ra xa hơn.

Dữ liệu huấn luyện để tinh chỉnh retriever thường được tăng cường thông qua các kỹ thuật như khai thác ví dụ âm tính khó (hard negative mining), trong đó các ví dụ âm tính thách thức, bề ngoài tương tự như ví dụ dương tính nhưng khác biệt về mặt ngữ nghĩa, được cố ý đưa vào. Điều này buộc mô hình phải học các phân biệt tinh tế hơn giữa nội dung liên quan và không liên quan. Ngoài ra, các kỹ thuật tạo truy vấn có thể được sử dụng để mở rộng dữ liệu huấn luyện, trong đó LLM tạo ra các truy vấn tiềm năng cho các đoạn văn để tạo thêm các cặp huấn luyện.

Đối với các mô hình reranking, quy trình tinh chỉnh mà tôi triển khai thậm chí còn phức tạp hơn. Các mô hình này thường sử dụng kiến trúc bộ mã hóa chéo (cross-encoder) cho phép tương tác sâu hơn giữa các biểu diễn truy vấn và đoạn văn. Dữ liệu huấn luyện bao gồm các cặp truy vấn-đoạn văn với nhãn mức độ liên quan được phân loại, thường theo thang điểm từ 0 (hoàn toàn không liên quan) đến 3 hoặc 4 (hoàn toàn liên quan). Mô hình reranker được tinh chỉnh bằng cách sử dụng các mục tiêu học theo điểm (pointwise), theo cặp (pairwise) hoặc theo danh sách (listwise).

Trong học theo điểm, mô hình được huấn luyện để dự đoán điểm liên quan tuyệt đối của mỗi cặp truy vấn-đoạn văn. Học theo cặp tập trung vào việc sắp xếp chính xác các cặp đoạn văn cho một truy vấn nhất định, trong khi học theo danh sách tối ưu hóa toàn bộ thứ hạng của các đoạn văn cho mỗi truy vấn. Các kỹ thuật như chưng cất kiến thức (knowledge distillation) cũng có thể được sử dụng, trong đó một mô hình lớn hơn, mạnh hơn (giáo viên) hướng dẫn việc huấn luyện một mô hình nhỏ hơn, hiệu quả hơn (học sinh).

Thích ứng miền là một khía cạnh quan trọng trong phương pháp tinh chỉnh của tôi cho cả retriever và reranker. Đối với các ứng dụng chuyên biệt với dữ liệu tiếng Việt, các mô hình được tiền huấn luyện trên các kho ngữ liệu chung được tinh chỉnh thêm trên dữ liệu cụ thể của miền. Quá trình này thường bao gồm học theo chương trình (curriculum learning), trong đó việc huấn luyện tiến triển từ các ví dụ chung đến các ví dụ ngày càng cụ thể theo miền, cho phép mô hình chuyển giao kiến thức chung trong khi thích ứng với các sắc thái của miền.

Quá trình tinh chỉnh kết hợp các kỹ thuật điều chuẩn khác nhau để ngăn chặn việc quá khớp (overfitting), bao gồm dropout, suy giảm trọng số (weight decay) và dừng sớm dựa trên hiệu suất xác thực. Các chiến lược tăng cường dữ liệu như cải cách truy vấn, diễn giải đoạn văn và tạo dữ liệu tổng hợp giúp cải thiện độ mạnh mẽ và khả năng khái quát hóa của mô hình.

Việc theo dõi hiệu suất trong quá trình tinh chỉnh theo dõi các chỉ số như Mean Reciprocal Rank (MRR), Normalized Discounted Cumulative Gain (NDCG) và Recall@k. Tối ưu hóa siêu tham số thông qua các kỹ thuật như tối ưu hóa Bayes hoặc tìm kiếm lưới giúp xác định tốc độ học, kích thước lô và thời gian huấn luyện tối ưu cho từng ứng dụng cụ thể.

Thông qua phương pháp tinh chỉnh toàn diện này, việc triển khai các thành phần retriever và reranker của HippoRAG 2 trong nghiên cứu của tôi đạt được hiệu suất cao hơn đáng kể trong các tác vụ cụ thể của tiếng Việt so với các mô hình mục đích chung, đóng góp đáng kể vào hiệu quả tổng thể của framework.

\subsection{Module 2: OpenIE by LLM (Trích xuất Triple)}
Module OpenIE by LLM trong HippoRAG 2 sử dụng các mô hình mạnh mẽ như Llama-3.3-70B để trích xuất triple từ mỗi đoạn văn. Module này đại diện cho một bước quan trọng trong việc chuyển đổi văn bản phi cấu trúc thành kiến thức có cấu trúc có thể được tích hợp vào đồ thị tri thức. Quá trình trích xuất tập trung vào việc xác định các triple chủ thể-quan hệ-đối tượng nắm bắt các sự kiện và mối quan hệ thiết yếu trong văn bản.

Triple tuân theo định dạng (subject, relation, object), cung cấp một cách tự nhiên để biểu diễn thông tin thực tế. Ví dụ: Từ câu "Elon Musk đã sáng lập SpaceX," hệ thống trích xuất triple ("Elon Musk", "đã sáng lập", "SpaceX"). Mỗi triple được trích xuất tạo ra hai Phrase Node (subject và object) và một Relation Edge (có hướng từ subject đến object) trong đồ thị tri thức. Biểu diễn có cấu trúc này cho phép lưu trữ và truy xuất thông tin hiệu quả.

Một đổi mới quan trọng trong HippoRAG 2 là việc sử dụng phương pháp "schema-less open KG". Không giống như các đồ thị tri thức truyền thống bị giới hạn bởi các ontology được định nghĩa trước, phương pháp này cho phép trích xuất bất kỳ loại quan hệ nào mà không bị giới hạn bởi một schema cố định. Tính linh hoạt này cho phép hệ thống nắm bắt một phạm vi thông tin và mối quan hệ rộng hơn, làm cho nó dễ thích ứng hơn với các miền kiến thức đa dạng.

Phương pháp này mang lại những lợi thế đáng kể so với các hệ thống trích xuất thông tin truyền thống. Không giống như các phương pháp trích xuất dựa trên quy tắc hoặc thống kê, LLM có thể hiểu ngữ cảnh và trích xuất các mối quan hệ phức tạp mà các phương pháp cứng nhắc hơn có thể bỏ sót. Hệ thống không bị giới hạn bởi các tập hợp quan hệ được định nghĩa trước, cho phép biểu diễn thông tin đa dạng nắm bắt tốt hơn các sắc thái của ngôn ngữ tự nhiên. Hơn nữa, phương pháp không có schema giúp KG linh hoạt và dễ dàng mở rộng với kiến thức mới mà không cần thiết kế lại cấu trúc cơ bản.

\subsection{Module 3: Synonym Detection by Embedding}
Sau khi trích xuất triple, module Synonym Detection sử dụng các kỹ thuật embedding (Word2Vec, GloVe, BERT) để phát hiện các từ và cụm từ đồng nghĩa. Module này giải quyết một thách thức phổ biến trong truy xuất thông tin: sự đa dạng trong cách diễn đạt cùng một khái niệm trong ngôn ngữ tự nhiên. Bằng cách xác định và kết nối các thuật ngữ đồng nghĩa, hệ thống có thể bắc cầu qua những biến thể ngôn ngữ này và cải thiện hiệu suất truy xuất.

Quá trình bắt đầu bằng việc tính toán độ tương đồng cosine giữa các embedding của các Phrase Node khác nhau trong đồ thị tri thức. Khi độ tương đồng giữa hai node vượt quá ngưỡng được định nghĩa trước, một Synonym Edge được tạo ra để kết nối chúng. Ví dụ, hệ thống có thể kết nối "NYC" với "New York City" thông qua Synonym Edge, nhận ra rằng các thuật ngữ này đề cập đến cùng một thực thể mặc dù hình thức bề mặt của chúng khác nhau.

Module này mang lại một số lợi ích chính cho toàn bộ framework. Nó giúp hệ thống nhận diện các cách diễn đạt khác nhau của cùng một khái niệm, nâng cao khả năng truy vấn khi người dùng sử dụng từ đồng nghĩa hoặc biến thể của khái niệm. Bằng cách tạo kết nối giữa thông tin tương tự nhau trong các tài liệu khác nhau, nó cho phép truy xuất thông tin toàn diện hơn mà không bị giới hạn bởi các lựa chọn thuật ngữ cụ thể.

Không giống như các phương pháp dựa vào từ điển đồng nghĩa cố định, phương pháp dựa trên embedding này có thể phát hiện các mối quan hệ đồng nghĩa dựa trên sự tương đồng ngữ nghĩa thực tế trong không gian vector. Điều này cho phép nó xác định các mối quan hệ có thể không được nắm bắt trong các tài nguyên từ vựng được định nghĩa trước. Kết quả là một hệ thống linh hoạt và mạnh mẽ hơn, có thể kết nối thông tin giữa các tài liệu sử dụng thuật ngữ khác nhau nhưng truyền tải cùng một ý nghĩa.

\subsection{Module 4: Dense-Sparse Integration}
Module Dense-Sparse Integration kết hợp hai loại node trong đồ thị tri thức: Phrase node (mã hóa thưa thớt - sparse coding) và Passage node (mã hóa dày đặc - dense coding). Sự tích hợp này đại diện cho một đổi mới cơ bản trong HippoRAG 2 nhằm giải quyết sự đánh đổi cố hữu giữa độ chính xác khái niệm và sự phong phú về ngữ cảnh trong biểu diễn kiến thức.

Phrase node lưu trữ các khái niệm cô đọng, cụ thể là các chủ thể và đối tượng được trích xuất từ triple. Các node này biểu diễn thông tin ở định dạng thưa thớt, hiệu quả, tạo điều kiện cho việc suy luận và truy xuất nhanh chóng. Mặt khác, Passage node lưu trữ toàn bộ đoạn văn gốc, bảo toàn ngữ cảnh đầy đủ và thông tin chi tiết. Hai loại node này được liên kết thông qua các Context edge có nhãn "contains," có hướng từ Passage Node đến Phrase Node, cho biết một đoạn văn cụ thể chứa các khái niệm cụ thể.

Thiết kế của module này dựa trên lý thuyết mã hóa dày đặc và thưa thớt trong nhận thức của con người. Mã hóa thưa thớt, được đại diện bởi Phrase Node, hiệu quả về mặt lưu trữ và tạo điều kiện cho việc suy luận bằng cách tập trung vào các khái niệm thiết yếu. Mã hóa dày đặc, được đại diện bởi Passage Node, bảo toàn ngữ cảnh đầy đủ và thông tin chi tiết phong phú có thể bị mất trong các biểu diễn cô đọng hơn. Bằng cách kết hợp cả hai phương pháp, hệ thống đạt được sự cân bằng giữa hiệu quả xử lý và độ chính xác của thông tin.

Sự tích hợp này giải quyết những hạn chế chính của framework HippoRAG ban đầu. Nó khắc phục phương pháp tập trung vào thực thể vốn bỏ qua nhiều tín hiệu ngữ cảnh, cung cấp một biểu diễn kiến thức toàn diện hơn. Sự kết hợp này cải thiện đáng kể khả năng truy xuất thông tin so với các phương pháp chỉ dựa vào vector embedding. Có lẽ quan trọng nhất, nó cho phép hệ thống thực hiện suy luận nhanh thông qua các kết nối có cấu trúc giữa các Phrase Node trong khi vẫn có thể truy xuất thông tin chi tiết chính xác từ các Passage Node liên quan khi cần thiết.

Sự tích hợp dense-sparse đại diện cho một cải tiến cơ bản trong HippoRAG 2, giải quyết sự đánh đổi giữa khái niệm và ngữ cảnh tồn tại trong nhiều hệ thống biểu diễn kiến thức. Bằng cách kết hợp cả mã hóa thưa thớt (để biểu diễn khái niệm hiệu quả) và mã hóa dày đặc (để cung cấp thông tin ngữ cảnh phong phú), hệ thống đạt được sự cân bằng gần hơn với cách tổ chức bộ nhớ của con người, nơi cả khái niệm trừu tượng và ký ức tình tiết chi tiết cùng tồn tại và bổ sung cho nhau.

\section{Online Retrieval \& QA – Giai đoạn Truy hồi và Phản hồi}
Giai đoạn này sử dụng KG đã xây dựng để trả lời câu hỏi của người dùng thông qua một chuỗi các module xử lý. Giai đoạn Online Retrieval \& QA là nơi kiến thức được lưu trữ trong đồ thị được truy cập, lọc và tổng hợp để tạo ra phản hồi cho các truy vấn của người dùng.

\subsection{Module 1: Retriever}
Module Retriever thực hiện việc truy xuất thông tin ban đầu dựa trên truy vấn của người dùng. Bước đầu tiên quan trọng này xác định phần nào của đồ thị tri thức sẽ được xem xét để xử lý thêm và cuối cùng ảnh hưởng đến chất lượng của phản hồi cuối cùng. Retriever phải cân bằng giữa phạm vi bao phủ (để đảm bảo thông tin liên quan không bị bỏ sót) và độ chính xác (để tránh làm quá tải các bước xử lý tiếp theo với nội dung không liên quan).

HippoRAG 2 sử dụng các mô hình embedding như NV-Embed-v2 để truy xuất cả passages và triples từ KG. Phương pháp truy xuất kép này cho phép hệ thống truy cập cả kiến thức có cấu trúc (triple) và thông tin ngữ cảnh (passage) ngay từ đầu. Một đổi mới quan trọng là việc triển khai phương pháp "Query to Triple" thay vì chỉ sử dụng Named Entity Recognition (NER). Thay vì chỉ trích xuất các thực thể từ truy vấn, hệ thống so khớp toàn bộ truy vấn với các triple trong KG bằng cách sử dụng embedding, nắm bắt ý định của truy vấn một cách toàn diện hơn.

Phương pháp này mang lại những lợi thế đáng kể so với các phương pháp truyền thống hơn. Phương pháp "Query to Triple" cung cấp ngữ cảnh phong phú hơn so với việc chỉ trích xuất thực thể, cho phép hiểu sâu hơn về các yêu cầu của truy vấn. Triple chứa các mối quan hệ cơ bản giữa các khái niệm, giúp hiểu rõ hơn ý định của truy vấn bằng cách nắm bắt không chỉ các thực thể được đề cập mà còn cả cách chúng liên quan đến nhau. Các đánh giá thực nghiệm cho thấy phương pháp này cải thiện Recall@5 trung bình 12,5\% so với phương pháp NER-to-node được sử dụng trong HippoRAG ban đầu. Hơn nữa, nó giải quyết những hạn chế của các phương pháp tập trung vào thực thể vốn bỏ qua các tín hiệu ngữ cảnh quan trọng, dẫn đến việc truy xuất toàn diện và chính xác hơn.

\subsection{Module 2: Recognition Memory (Triple Filtering)}
Module Recognition Memory phân tích và lọc bỏ các triple không liên quan đến câu hỏi. Thành phần này được lấy cảm hứng từ các quá trình bộ nhớ của con người, đặc biệt là sự phân biệt giữa recall (chủ động truy xuất thông tin) và recognition (xác định thông tin liên quan khi được trình bày với nó). Bằng cách triển khai bước lọc này, HippoRAG 2 có thể tập trung xử lý tiếp theo vào thông tin phù hợp nhất, cải thiện cả hiệu quả và độ chính xác.

Module này sử dụng LLM như GPT-3 hoặc T5 để phân tích các triple được truy xuất và xác định mức độ liên quan của chúng với truy vấn. Quá trình này giảm nhiễu bằng cách chỉ giữ lại thông tin cần thiết, ngăn chặn các sự kiện không liên quan ảnh hưởng đến câu trả lời cuối cùng. Việc triển khai dựa trên các quá trình bổ sung trong bộ nhớ con người: recall (chủ động ghi nhớ mà không có gợi ý bên ngoài) và recognition (xác định thông tin khi được gợi ý bằng các tín hiệu bên ngoài).

Về mặt kỹ thuật, module sử dụng DSPy MIPROv2 optimizer và Llama-3.3-70B-Instruct để tối ưu hóa prompt cho việc lọc triple. Quá trình tối ưu hóa này đảm bảo rằng LLM có thể phân biệt hiệu quả giữa các triple liên quan và không liên quan trên một loạt các loại truy vấn và miền kiến thức. Kỹ thuật prompt rất quan trọng, vì nó hướng dẫn LLM đưa ra các đánh giá về mức độ liên quan một cách nhất quán và chính xác.

Module này mang lại những lợi ích chính cho toàn bộ framework. Nó cải thiện chất lượng của các seed node cho thuật toán PageRank bằng cách đảm bảo rằng chỉ các triple thực sự liên quan mới được xem xét. Bằng cách giảm nhiễu trong quá trình truy vấn, nó tăng độ chính xác của kết quả cuối cùng, ngăn chặn thông tin không liên quan làm loãng hoặc sai lệch câu trả lời. Có lẽ quan trọng nhất, nó mô phỏng quá trình nhận diện trong bộ nhớ con người, giúp xác định thông tin liên quan khi được gợi ý, đây là một khía cạnh quan trọng của quá trình xử lý thông tin giống con người thường thiếu trong các hệ thống RAG truyền thống.

\subsection{Module 3: Gán Trọng số cho Seed Nodes}
Module Gán Trọng số cho Seed Nodes là một thành phần quan trọng quyết định cách ảnh hưởng được phân bổ trên đồ thị tri thức trong thuật toán PageRank tiếp theo. Module này cẩn thận gán trọng số cho các node được chọn làm seed node, thiết lập tầm quan trọng tương đối của chúng đối với truy vấn cụ thể đang được xử lý. Cơ chế gán trọng số rất phức tạp và xem xét nhiều yếu tố để đảm bảo hiệu suất tối ưu trên các loại truy vấn khác nhau.

Đối với các phrase node, quá trình lựa chọn và gán trọng số bắt đầu với các triple đã được lọc từ module Recognition Memory. Mỗi phrase node (chủ thể hoặc đối tượng) xuất hiện trong các triple đã lọc này sẽ trở thành một seed node tiềm năng. Sau đó, hệ thống tính toán trọng số cho mỗi node dựa trên điểm xếp hạng trung bình của nó trên tất cả các triple đã lọc mà nó xuất hiện. Cách tiếp cận này đảm bảo rằng các khái niệm được xếp hạng cao một cách nhất quán trên nhiều triple liên quan sẽ nhận được ảnh hưởng lớn hơn trong tìm kiếm đồ thị.

Công thức gán trọng số cho các phrase node kết hợp một số yếu tố. Đầu tiên, điểm truy xuất ban đầu từ mô hình embedding cung cấp một thước đo mức độ liên quan cơ bản. Sau đó, điểm này được điều chỉnh dựa trên tần suất xuất hiện của node trên các triple đã lọc, với hàm lợi ích giảm dần để ngăn các khái niệm cực kỳ phổ biến chiếm ưu thế. Ngoài ra, hệ thống xem xét vị trí của node trong các triple của nó (chủ thể so với đối tượng) và điểm tin cậy từ quá trình lọc triple. Trọng số cuối cùng được chuẩn hóa để đảm bảo tỷ lệ nhất quán trên các truy vấn khác nhau.

Đối với các passage node, cách tiếp cận khác biệt nhưng bổ sung. Tất cả các passage node đều được chọn làm seed node để đảm bảo kích hoạt rộng rãi trên đồ thị tri thức, điều này rất quan trọng đối với suy luận đa bước hiệu quả. Trọng số được gán cho mỗi passage node tỷ lệ thuận với độ tương đồng embedding của nó với truy vấn, phản ánh mức độ liên quan trực tiếp của nó. Tuy nhiên, điểm tương đồng thô này sau đó được điều chỉnh bởi một hệ số cân bằng (mặc định là 0,05) kiểm soát ảnh hưởng tương đối của các passage node so với các phrase node trong tìm kiếm đồ thị tổng thể.

Hệ số cân bằng này là một siêu tham số quan trọng đã được tối ưu hóa thực nghiệm thông qua thử nghiệm rộng rãi. Đặt nó quá cao sẽ khiến tìm kiếm đồ thị bị chi phối bởi sự tương đồng passage trực tiếp, về cơ bản giảm xuống thành truy xuất vector tiêu chuẩn. Đặt nó quá thấp sẽ không tận dụng hết thông tin ngữ cảnh phong phú trong các passage. Giá trị mặc định 0,05 đại diện cho sự cân bằng tối ưu tận dụng thế mạnh của cả hai loại node trong khi vẫn duy trì lợi thế cấu trúc của phương pháp dựa trên đồ thị.

Hệ thống cũng triển khai việc gán trọng số thích ứng dựa trên đặc điểm của truy vấn. Đối với các truy vấn dường như đang tìm kiếm thông tin thực tế cụ thể, trọng số của các phrase node được tăng nhẹ so với các passage node. Ngược lại, đối với các truy vấn dường như yêu cầu hiểu biết ngữ cảnh nhiều hơn hoặc suy luận đa bước, trọng số của passage node được điều chỉnh tăng lên. Cách tiếp cận thích ứng này cho phép hệ thống điều chỉnh chiến lược truy xuất của mình cho phù hợp với nhu cầu thông tin cụ thể được thể hiện trong truy vấn.

Thông qua cơ chế gán trọng số phức tạp này, HippoRAG 2 đạt được một số lợi ích quan trọng. Nó cân bằng ảnh hưởng giữa các phrase node và passage node trong quá trình PageRank, đảm bảo rằng cả độ chính xác khái niệm và sự phong phú về ngữ cảnh đều đóng góp một cách thích hợp vào kết quả cuối cùng. Việc kích hoạt rộng rãi các passage node cải thiện khả năng suy luận đa bước bằng cách cung cấp nhiều con đường thông qua đồ thị tri thức. Hệ thống cho phép điều chỉnh linh hoạt mức độ ảnh hưởng của thông tin ngữ cảnh (passage) và thông tin cô đọng (phrase), có thể được điều chỉnh cho các miền hoặc loại truy vấn khác nhau. Có lẽ quan trọng nhất, cách tiếp cận này cải thiện hiệu suất trên các loại truy vấn khác nhau, từ các câu hỏi thực tế đơn giản đến các tác vụ suy luận phức tạp, làm cho hệ thống trở nên linh hoạt và mạnh mẽ hơn.

\subsection{Module 4: Tìm kiếm Đồ thị PPR (Personalized PageRank)}
Module Tìm kiếm Đồ thị PPR (Personalized PageRank) là thành phần thuật toán cốt lõi cho phép HippoRAG 2 thực hiện suy luận đa bước, phức tạp trên đồ thị tri thức. Module này triển khai một phiên bản sửa đổi của thuật toán PageRank đã được cá nhân hóa để tập trung vào các phần liên quan đến truy vấn của đồ thị, cho phép duyệt qua cấu trúc tri thức một cách nhận biết ngữ cảnh để xác định thông tin phù hợp nhất.

Thuật toán PPR hoạt động dựa trên nguyên tắc cơ bản rằng tầm quan trọng lan truyền qua đồ thị dọc theo các cạnh của nó. Không giống như PageRank tiêu chuẩn, vốn coi tất cả các node như nhau ở trạng thái ban đầu, Personalized PageRank bắt đầu với sự phân bổ tầm quan trọng không đồng đều tập trung vào các seed node đã được xác định và gán trọng số ở module trước. Việc cá nhân hóa này đảm bảo rằng việc khám phá đồ thị của thuật toán được hướng dẫn bởi mức độ liên quan của truy vấn ngay từ đầu.

Công thức toán học của PPR có thể được biểu diễn dưới dạng một quá trình lặp. Gọi $r$ là một vector biểu thị điểm tầm quan trọng của tất cả các node trong đồ thị, được khởi tạo bằng trọng số của seed node. Gọi $M$ là ma trận chuyển tiếp được suy ra từ cấu trúc đồ thị, trong đó $M_{ij}$ biểu thị xác suất chuyển từ node $i$ sang node $j$. Phương trình cập nhật PPR là:

$r_{t+1} = (1-\alpha) \cdot M \cdot r_t + \alpha \cdot p$

Trong đó $\alpha$ là xác suất dịch chuyển tức thời (teleport probability) (thường được đặt trong khoảng từ 0,1 đến 0,2 trong HippoRAG 2), và $p$ là vector cá nhân hóa được suy ra từ trọng số của seed node. Phương trình này nắm bắt hai hành vi chính: với xác suất $(1-\alpha)$, thuật toán tuân theo cấu trúc đồ thị bằng cách chuyển tiếp theo $M$; với xác suất $\alpha$, nó "dịch chuyển tức thời" trở lại các seed node theo trọng số của chúng trong $p$.

Việc triển khai trong HippoRAG 2 bao gồm một số cải tiến phức tạp cho công thức cơ bản này. Đầu tiên, ma trận chuyển tiếp $M$ được xây dựng để phản ánh các loại cạnh khác nhau trong đồ thị tri thức. Các Relation edge, synonym edge và context edge được gán các xác suất chuyển tiếp khác nhau dựa trên ý nghĩa ngữ nghĩa của chúng. Ví dụ, các synonym edge thường nhận được xác suất chuyển tiếp cao hơn các relation edge, phản ánh sự tương đương ngữ nghĩa mạnh mẽ mà chúng đại diện.

Thứ hai, thuật toán sử dụng các hệ số giảm chấn cụ thể theo cạnh (edge-specific damping factors) thay đổi dựa trên loại cạnh và khoảng cách ngữ nghĩa mà chúng đại diện. Điều này cho phép kiểm soát tinh tế hơn cách tầm quan trọng lan truyền qua các loại kết nối khác nhau. Ví dụ, các chuyển tiếp dọc theo context edge (từ passage đến phrase) có thể sử dụng một hệ số giảm chấn khác với các chuyển tiếp dọc theo relation edge (giữa các phrase).

Thứ ba, HippoRAG 2 triển khai một cơ chế phát hiện hội tụ sớm theo dõi tốc độ thay đổi trong thứ hạng của các node thay vì chỉ là điểm thô. Điều này cho phép thuật toán kết thúc khi thứ tự tương đối của các node ổn định, ngay cả khi điểm tuyệt đối vẫn đang thay đổi một chút, cải thiện hiệu quả tính toán mà không làm giảm chất lượng xếp hạng.

Quá trình PPR tiếp tục lặp đi lặp lại cho đến khi hội tụ, thường yêu cầu 30-50 lần lặp đối với hầu hết các truy vấn. Sau khi đạt được sự hội tụ, các node được xếp hạng theo điểm tầm quan trọng cuối cùng của chúng. Các passage node có điểm PageRank cao nhất được coi là phù hợp nhất với truy vấn và được chọn cho giai đoạn tạo câu trả lời cuối cùng.

Cách tiếp cận này mang lại những lợi thế đáng kể so với các phương pháp truy xuất đơn giản hơn. Bằng cách mô phỏng khả năng liên kết trong bộ nhớ con người, PPR có thể xác định các kết nối không rõ ràng từ các thước đo tương đồng trực tiếp. Nó cho phép tìm kiếm thông tin liên quan thông qua suy luận đa bước, theo các chuỗi mối quan hệ kết nối các khái niệm được đề cập trong truy vấn với các khái niệm liên quan khác và cuối cùng là các passage chứa thông tin hữu ích. Các đánh giá thực nghiệm cho thấy cách tiếp cận này vượt trội hơn so với truy xuất vector đơn giản trong các tác vụ đòi hỏi suy luận đa bước, với sự cải thiện về Recall@5 là 5,0% và 13,9% trên các bộ dữ liệu MuSiQue và 2Wiki so với dense retriever mạnh nhất (NV-Embed-v2).

Khả năng duyệt qua cấu trúc đồ thị của thuật toán PPR làm cho nó đặc biệt hiệu quả đối với các truy vấn phức tạp trong đó thông tin liên quan được phân bổ trên nhiều passage hoặc yêu cầu kết nối các mảnh kiến thức khác nhau. Khả năng này rất cần thiết để trả lời các câu hỏi vượt ra ngoài việc truy xuất sự kiện đơn giản và yêu cầu tổng hợp hoặc suy luận trên nhiều nguồn thông tin.

\subsection{Module 5: QA Reading}
Module QA Reading đại diện cho giai đoạn cuối cùng trong quy trình của HippoRAG 2, nơi thông tin được truy xuất được tổng hợp thành một phản hồi mạch lạc và chính xác cho truy vấn của người dùng. Module này tận dụng sức mạnh của các Mô hình Ngôn ngữ Lớn để đọc, diễn giải và tích hợp thông tin từ các đoạn văn được xác định là phù hợp nhất bởi Tìm kiếm Đồ thị PPR.

Quá trình bắt đầu với việc LLM đọc các đoạn văn được xếp hạng cao nhất từ thuật toán PPR. Không giống như các phương pháp trích xuất đơn giản hơn, LLM không chỉ sao chép thông tin từ các đoạn văn này mà còn tham gia vào một quá trình hiểu và tổng hợp phức tạp. Nó phân tích nội dung của mỗi đoạn văn, xác định thông tin liên quan, giải quyết các mâu thuẫn hoặc dư thừa tiềm ẩn và tích hợp những hiểu biết này thành một phản hồi mạch lạc.

Phương pháp này mang lại một số lợi ích chính góp phần vào hiệu quả tổng thể của HippoRAG 2. Bằng cách tận dụng khả năng tổng hợp và suy luận của LLM, hệ thống có thể tạo ra các câu trả lời chất lượng cao vượt ra ngoài việc trích xuất thông tin đơn giản. LLM có thể suy ra các kết nối giữa các sự kiện, khái quát hóa từ các ví dụ cụ thể và trình bày thông tin một cách rõ ràng và phù hợp với ngữ cảnh. Bằng cách cung cấp ngữ cảnh đầy đủ cho LLM thông qua các đoạn văn được chọn lọc cẩn thận, hệ thống đảm bảo rằng mô hình có quyền truy cập vào tất cả thông tin cần thiết để tạo ra một phản hồi chính xác và toàn diện.

Hiệu quả của phương pháp này được chứng minh bằng các kết quả thực nghiệm, với HippoRAG 2 đạt điểm F1 cao hơn 2,8% so với phương pháp dense retrieval tốt nhất (NV-Embed-v2) trên các bộ dữ liệu benchmark. Có lẽ quan trọng nhất, module này hiệu quả trên các loại nhiệm vụ khác nhau, bao gồm factual memory (truy xuất sự kiện đơn giản), sense-making (hiểu các câu chuyện phức tạp) và associativity (kết nối thông tin liên quan), làm cho nó trở thành một giải pháp linh hoạt cho một loạt các tình huống trả lời câu hỏi.

\section{Các đóng góp chính của đồ án}
\subsection{Đổi mới Kỹ thuật}
Trong luận văn này, tôi khám phá và mở rộng HippoRAG 2, một framework giới thiệu một số đổi mới kỹ thuật quan trọng cho lĩnh vực hệ thống retrieval-augmented generation. Công việc của tôi đặc biệt tập trung vào việc điều chỉnh và đánh giá những đổi mới này cho dữ liệu tiếng Việt, nhấn mạnh vào các tác vụ lập luận đa bước.

Phương pháp Dense-Sparse Integration đại diện cho một giải pháp mới cho thách thức biểu diễn kiến thức. Bằng cách kết hợp mã hóa thưa thớt (phrase node) và mã hóa dày đặc (passage node), HippoRAG 2 giải quyết sự đánh đổi giữa khái niệm và ngữ cảnh tồn tại trong nhiều hệ thống kiến thức. Sự tích hợp này cho phép hệ thống cân bằng giữa suy luận hiệu quả và truy xuất thông tin chi tiết, mô phỏng khả năng của não người làm việc với cả khái niệm trừu tượng và ký ức tình tiết chi tiết. Biểu diễn thưa thớt tạo điều kiện cho việc lưu trữ hiệu quả và suy luận nhanh chóng về các khái niệm, trong khi biểu diễn dày đặc bảo toàn sự phong phú về ngữ cảnh có thể bị mất trong các định dạng cô đọng hơn.

Phương pháp Query to Triple đánh dấu một sự khác biệt đáng kể so với các phương pháp truy xuất tập trung vào thực thể truyền thống. Thay vì chỉ tập trung vào các thực thể được đề cập trong truy vấn, phương pháp này so khớp toàn bộ truy vấn với các triple trong đồ thị tri thức. Điều này cung cấp ngữ cảnh phong phú hơn để hiểu ý định của truy vấn và cải thiện hiệu suất truy xuất trung bình 12,5% so với các phương pháp dựa trên thực thể. Bằng cách xem xét các mối quan hệ được thể hiện trong truy vấn, không chỉ các thực thể, hệ thống có thể điều chỉnh việc truy xuất tốt hơn với nhu cầu thông tin của người dùng.

Thành phần Recognition Memory lấy cảm hứng từ các quá trình bộ nhớ của con người để tăng cường việc lọc thông tin. Bằng cách triển khai một cơ chế mô phỏng cách con người nhận ra thông tin liên quan khi được trình bày với nó, HippoRAG 2 có thể phân biệt hiệu quả hơn giữa các triple liên quan và không liên quan. Điều này giảm nhiễu trong quá trình truy xuất và cải thiện chất lượng của các seed node cho thuật toán PageRank, dẫn đến kết quả tập trung và chính xác hơn.

Phương pháp Balanced Reset Probabilities giới thiệu một phương pháp phức tạp để kiểm soát ảnh hưởng của các loại node khác nhau trong thuật toán Personalized PageRank. Bằng cách sử dụng hệ số trọng số để cân bằng giữa phrase node và passage node, hệ thống có thể tối ưu hóa hiệu suất trên các loại truy vấn khác nhau. Cách tiếp cận tinh tế này đối với việc duyệt đồ thị cho phép HippoRAG 2 tận dụng cả các mối quan hệ có cấu trúc giữa các khái niệm và thông tin ngữ cảnh phong phú trong các đoạn văn, dẫn đến việc truy xuất toàn diện và chính xác hơn.

Đóng góp của tôi tập trung vào việc điều chỉnh những đổi mới này cho dữ liệu tiếng Việt, đặc biệt thông qua việc tinh chỉnh các mô hình truy xuất và xếp hạng lại cho các tác vụ trả lời câu hỏi đa bước tiếng Việt. Việc điều chỉnh này bao gồm giải quyết các thách thức cụ thể của ngôn ngữ và đánh giá hiệu quả của framework HippoRAG 2 trong một bối cảnh ngôn ngữ mới.

\subsection{Cải thiện Hiệu suất}
Nghiên cứu của tôi xem xét những cải thiện hiệu suất đạt được bởi HippoRAG 2 trên một loạt các tác vụ benchmark, đặc biệt tập trung vào việc áp dụng nó cho dữ liệu tiếng Việt và các tác vụ lập luận đa bước.

Hiệu suất toàn diện của hệ thống trên các loại benchmark khác nhau làm cho nó nổi bật so với các phương pháp trước đây. Trong khi các phương pháp RAG tăng cường cấu trúc trước đây thường xuất sắc trong một lĩnh vực nhưng suy giảm ở các lĩnh vực khác, HippoRAG 2 duy trì hiệu suất mạnh mẽ trên các tác vụ factual memory, sense-making và associativity. Tính linh hoạt này làm cho nó phù hợp với một loạt các ứng dụng mà không yêu cầu tối ưu hóa cụ thể cho từng tác vụ.

Trong các tác vụ bộ nhớ liên kết, kiểm tra khả năng kết nối thông tin liên quan trên các tài liệu của hệ thống, HippoRAG 2 đạt được cải thiện 7% so với mô hình embedding tiên tiến nhất. Điều này chứng tỏ khả năng vượt trội của nó trong suy luận đa bước, nơi thông tin liên quan phải được xác định thông qua các chuỗi mối quan hệ thay vì khớp trực tiếp.

Hệ thống cũng cho thấy những cải thiện ấn tượng về chất lượng truy xuất, với Recall@5 tăng 5,0% và 13,9% trên các bộ dữ liệu MuSiQue và 2Wiki so với dense retriever mạnh nhất. Những cải thiện này đặc biệt đáng chú ý trong các tác vụ suy luận đa bước, nơi hệ thống phải điều hướng các mối quan hệ phức tạp để tìm thông tin liên quan.

Một thế mạnh quan trọng khác của HippoRAG 2 là tính linh hoạt của nó trên các retriever và mô hình ngôn ngữ khác nhau. Hệ thống thể hiện sự mạnh mẽ khi được sử dụng với các dense retriever khác nhau và tương thích với cả LLM mã nguồn mở và độc quyền. Tính linh hoạt này cho phép sử dụng rộng rãi trên các môi trường tính toán và yêu cầu ứng dụng khác nhau, làm cho phương pháp này dễ tiếp cận và dễ thích ứng hơn.

Công việc của tôi mở rộng những đánh giá này sang dữ liệu tiếng Việt, cụ thể là sử dụng bộ dữ liệu VIMQA, để đánh giá mức độ chuyển đổi của những cải thiện hiệu suất này sang một bối cảnh ngôn ngữ khác. Đánh giá này cung cấp những hiểu biết có giá trị về khả năng áp dụng xuyên ngôn ngữ của framework HippoRAG 2 và hiệu quả của nó đối với các tác vụ lập luận đa bước trong tiếng Việt.

\subsection{Đóng góp Lý thuyết}
Ngoài những đổi mới kỹ thuật và cải thiện hiệu suất, HippoRAG 2 còn có một số đóng góp lý thuyết quan trọng cho lĩnh vực trí tuệ nhân tạo và điện toán nhận thức. Nghiên cứu của tôi xem xét những đóng góp này và khám phá ý nghĩa của chúng đối với xử lý ngôn ngữ tiếng Việt và lập luận đa bước.

Thiết kế lấy cảm hứng từ thần kinh học của HippoRAG 2 thúc đẩy lĩnh vực bằng cách triển khai các thành phần mô phỏng chặt chẽ hơn các quá trình bộ nhớ của con người. Bằng cách kết hợp các yếu tố như mã hóa thưa thớt và dày đặc, bộ nhớ nhận diện và truy xuất liên kết, hệ thống đại diện cho một bước tiến hướng tới các kiến trúc AI hợp lý hơn về mặt nhận thức. Sự phù hợp này với các quá trình nhận thức của con người không chỉ cải thiện hiệu suất mà còn đóng góp vào hiểu biết của chúng ta về cách các hệ thống tính toán có thể triển khai các chức năng bộ nhớ giống con người.

HippoRAG 2 cung cấp một phương pháp tiếp cận đầy hứa hẹn cho continual learning không tham số cho LLM, giải quyết một thách thức cơ bản trong phát triển AI. Bằng cách cho phép các mô hình liên tục thu thập, tổ chức và tận dụng kiến thức mà không cần sửa đổi tham số của chúng, framework cung cấp một giải pháp có thể mở rộng cho vấn đề tích hợp thông tin mới vào các hệ thống AI. Cách tiếp cận này tránh được các vấn đề quên lãng thảm khốc gây khó khăn cho nhiều phương pháp continual learning tham số trong khi vẫn duy trì tính linh hoạt và khả năng thích ứng.

Có lẽ quan trọng nhất, HippoRAG 2 đại diện cho một bước tiến hướng tới việc tạo ra các hệ thống AI với khả năng bộ nhớ giống con người hơn. Bằng cách giải quyết cả khả năng ghi nhớ sự kiện và khả năng suy luận phức tạp trong một framework thống nhất, hệ thống chứng minh cách AI có thể vượt ra ngoài việc truy xuất thông tin đơn giản để hướng tới việc sử dụng kiến thức phức tạp hơn. Cách tiếp cận toàn diện này đối với bộ nhớ và suy luận đưa các hệ thống AI đến gần hơn với các khả năng nhận thức tích hợp đặc trưng cho trí thông minh của con người.

Nghiên cứu của tôi đóng góp vào sự hiểu biết lý thuyết này bằng cách xem xét cách các nguyên tắc nhận thức này áp dụng trên các ngôn ngữ, đặc biệt là trong bối cảnh các tác vụ lập luận đa bước tiếng Việt. Góc nhìn xuyên ngôn ngữ này cung cấp những hiểu biết có giá trị về tính phổ quát của các nguyên tắc nhận thức này và khả năng áp dụng của chúng cho các tác vụ xử lý ngôn ngữ đa dạng.

\section{Phân tích So sánh với Các Phương pháp Khác}
\subsection{So sánh với RAG Truyền thống}
Các hệ thống RAG truyền thống chủ yếu dựa vào vector embedding để truy xuất, điều này hạn chế khả năng nắm bắt bản chất kết nối của bộ nhớ con người. Mặc dù hiệu quả đối với việc truy xuất thông tin đơn giản, các hệ thống này gặp khó khăn với các tác vụ suy luận phức tạp hơn đòi hỏi kết nối nhiều mảnh thông tin hoặc hiểu các ngữ cảnh rộng hơn.

HippoRAG 2 giải quyết những hạn chế này thông qua một số cải tiến chính. Khả năng liên kết tăng cường của nó cho phép nó xuất sắc trong các tác vụ đòi hỏi kết nối giữa nhiều mảnh thông tin. Trong khi RAG truyền thống gặp khó khăn với suy luận đa bước, HippoRAG 2 đạt được cải thiện trung bình 7 điểm so với RAG tiêu chuẩn trong các tác vụ liên kết. Sự cải thiện này xuất phát từ phương pháp dựa trên đồ thị có thể theo các chuỗi mối quan hệ để xác định thông tin liên quan có thể không được khớp trực tiếp bằng sự tương đồng vector.

Hệ thống cũng thể hiện khả năng hiểu được cải thiện, hiểu và xử lý tốt hơn các ngữ cảnh phức tạp, dài so với các hệ thống RAG truyền thống. Điều này đặc biệt có giá trị đối với các ứng dụng liên quan đến hiểu câu chuyện hoặc phân tích tài liệu phức tạp, nơi thông tin phải được diễn giải trong ngữ cảnh rộng hơn của nó.

Một lợi thế khác của HippoRAG 2 là tính linh hoạt của nó trên các backend truy xuất khác nhau. Framework có thể được sử dụng với nhiều dense retriever khác nhau, liên tục cải thiện hiệu suất so với dense retrieval thuần túy bất kể mô hình embedding cụ thể nào được sử dụng. Khả năng thích ứng này làm cho nó trở thành một cải tiến thiết thực cho các hệ thống RAG hiện có, cho phép các tổ chức tận dụng các khoản đầu tư hiện tại của họ vào công nghệ embedding trong khi vẫn thu được lợi ích của phương pháp truy xuất phức tạp hơn.

Trong nghiên cứu của mình, tôi xem xét cách những lợi thế này chuyển đổi sang xử lý ngôn ngữ tiếng Việt, so sánh hiệu suất của HippoRAG 2 với các phương pháp RAG truyền thống trên các tác vụ lập luận đa bước tiếng Việt. So sánh này cung cấp những hiểu biết có giá trị về hiệu quả của các chiến lược truy xuất khác nhau cho dữ liệu tiếng Việt và những thách thức và cơ hội cụ thể do bối cảnh ngôn ngữ này đặt ra.

\subsection{So sánh với Các Phương pháp RAG Tăng cường Cấu trúc}
Một số phương pháp RAG tăng cường cấu trúc đã được đề xuất để giải quyết hạn chế trong RAG truyền thống, mỗi phương pháp có cách tiếp cận riêng để tăng cường khả năng truy xuất. HippoRAG 2 mang lại những lợi thế khác biệt so với các phương pháp thay thế này, mà tôi đánh giá trong bối cảnh xử lý ngôn ngữ tiếng Việt.

RAPTOR và GraphRAG đều sử dụng LLM để tạo tóm tắt tích hợp thông tin từ các kho ngữ liệu truy xuất của chúng. Mặc dù phương pháp này có thể hiệu quả đối với một số tác vụ nhất định, hiệu suất của chúng giảm đáng kể trong các tác vụ QA đơn giản và đa bước do nhiễu được đưa vào kho ngữ liệu truy xuất. Quá trình tóm tắt có thể gây ra sự không chính xác hoặc thiếu sót lan truyền qua hệ thống, ảnh hưởng đến chất lượng của câu trả lời cuối cùng. HippoRAG 2 tránh vấn đề này bằng cách làm việc trực tiếp với các đoạn văn và triple gốc, duy trì tính trung thực của thông tin trong suốt quá trình.

LightRAG có một cách tiếp cận khác, sử dụng đồ thị tri thức để mở rộng kho ngữ liệu truy xuất. Mặc dù điều này có thể giúp xác định thêm thông tin liên quan, nó cũng làm tăng nguy cơ bao gồm nội dung không liên quan. Ngược lại, HippoRAG 2 sử dụng KG để hỗ trợ chính quá trình truy xuất, hướng dẫn tìm kiếm đến thông tin liên quan thay vì chỉ đơn giản là mở rộng không gian tìm kiếm. Cách tiếp cận tập trung này làm giảm nhiễu do LLM tạo ra và dẫn đến kết quả truy xuất chính xác hơn.

So với framework HippoRAG ban đầu, HippoRAG 2 giải quyết một số hạn chế chính. Nó giải quyết các vấn đề liên quan đến mất ngữ cảnh trong quá trình indexing và inference bằng cách tích hợp các passage node trực tiếp vào đồ thị tri thức. Nó cũng cải thiện việc khớp ngữ nghĩa thông qua phương pháp Query to Triple và lọc bộ nhớ nhận diện. Những cải tiến này cho phép HippoRAG 2 duy trì thế mạnh suy luận liên kết của framework ban đầu trong khi mở rộng khả năng của nó sang các loại tác vụ khác.

Nghiên cứu của tôi đánh giá những lợi thế so sánh này đặc biệt trong bối cảnh xử lý ngôn ngữ tiếng Việt, xem xét cách các phương pháp RAG tăng cường cấu trúc khác nhau hoạt động trên các tác vụ lập luận đa bước tiếng Việt. Đánh giá này cung cấp những hiểu biết về phương pháp nào hiệu quả nhất cho dữ liệu tiếng Việt và những thách thức cụ thể phát sinh khi áp dụng các phương pháp này vào một bối cảnh ngôn ngữ mới.

\subsection{Kết quả Thực nghiệm}
Các thí nghiệm của tôi chứng minh hiệu suất của HippoRAG 2 trên một loạt các tác vụ benchmark, đặc biệt tập trung vào dữ liệu tiếng Việt từ bộ dữ liệu VIMQA. Những kết quả này cung cấp xác nhận thực nghiệm về hiệu quả và tính linh hoạt của framework trong một bối cảnh ngôn ngữ mới.

Trên tất cả các loại benchmark, HippoRAG 2 đạt điểm F1 cao, cho thấy khả năng tạo ra các câu trả lời chính xác và phù hợp trên các loại câu hỏi khác nhau. Hiệu suất nhất quán này đặc biệt đáng chú ý vì nhiều phương pháp cạnh tranh cho thấy sự thay đổi đáng kể về hiệu quả trên các tác vụ khác nhau.

Trên các bộ dữ liệu thách thức cụ thể, HippoRAG 2 cho thấy những cải thiện ấn tượng so với các phương pháp tiên tiến nhất. Nó vượt trội NV-Embed-v2 9,5% F1 trên 2Wiki và 3,1% trên bộ dữ liệu thách thức LV-Eval, chứng minh hiệu quả của nó trong các tác vụ suy luận phức tạp và khả năng chống rò rỉ kiến thức.

Hệ thống cho thấy những cải thiện nhất quán so với tất cả các phương pháp khác trên gần như tất cả các cài đặt, xác nhận phương pháp tiếp cận lấy cảm hứng từ tâm lý thần kinh học của nó. Sự nhất quán này là một thế mạnh quan trọng, vì nó cho thấy rằng những lợi thế của framework là cơ bản chứ không phải cụ thể cho từng tác vụ hoặc phụ thuộc vào bộ dữ liệu.

Một phát hiện quan trọng khác là HippoRAG 2 duy trì hiệu suất mạnh mẽ bất kể dense retriever cụ thể nào được sử dụng. Điều này cho thấy rằng những cải tiến của framework đến từ những đổi mới kiến trúc của nó chứ không chỉ đơn giản là tận dụng một retriever cơ sở mạnh hơn, và những lợi ích này có thể được thực hiện trên các backend truy xuất khác nhau.

Nghiên cứu của tôi mở rộng những đánh giá này sang dữ liệu tiếng Việt, xem xét mức độ chuyển đổi của những lợi thế hiệu suất này sang một bối cảnh ngôn ngữ mới. Đánh giá này cung cấp những hiểu biết có giá trị về khả năng áp dụng xuyên ngôn ngữ của framework HippoRAG 2 và hiệu quả của nó đối với các tác vụ lập luận đa bước trong tiếng Việt.

\section{Hướng Phát triển Tương lai}
Mặc dù nghiên cứu của tôi chứng minh hiệu quả của HippoRAG 2 đối với xử lý ngôn ngữ tiếng Việt và các tác vụ lập luận đa bước, một số hướng nghiên cứu tương lai đầy hứa hẹn có thể nâng cao hơn nữa khả năng và ứng dụng của nó.

Khả năng Bộ nhớ Episodic tăng cường có thể được phát triển bằng cách khám phá các phương pháp truy xuất dựa trên đồ thị được thiết kế đặc biệt cho các cuộc hội thoại dài. Điều này sẽ cho phép hệ thống duy trì ngữ cảnh qua các tương tác kéo dài, tham chiếu đến các phần trước của cuộc hội thoại khi có liên quan và xây dựng sự hiểu biết mạch lạc hơn về nhu cầu thông tin của người dùng theo thời gian.

Tích hợp Đa phương tiện đại diện cho một biên giới thú vị khác, mở rộng framework để kết hợp thông tin từ các phương thức khác nhau như văn bản, hình ảnh, âm thanh và video vào một đồ thị tri thức thống nhất. Điều này sẽ cho phép truy xuất và tổng hợp thông tin toàn diện hơn trên các loại nội dung khác nhau, phù hợp hơn với bản chất đa phương tiện của kiến thức con người.

Cập nhật Kiến thức Động sẽ giải quyết thách thức cập nhật hiệu quả đồ thị tri thức khi có thông tin mới. Phát triển cơ chế cập nhật tăng dần mà không yêu cầu xây dựng lại hoàn toàn đồ thị sẽ làm cho hệ thống trở nên thiết thực hơn cho các ứng dụng thực tế nơi kiến thức phát triển liên tục.

Khả năng Cá nhân hóa có thể điều chỉnh framework để kết hợp kiến thức và sở thích cụ thể của người dùng, dẫn đến các phản hồi phù hợp hơn. Điều này có thể liên quan đến việc duy trì các thành phần được cá nhân hóa riêng biệt của đồ thị tri thức cho những người dùng khác nhau hoặc điều chỉnh các quy trình truy xuất và xếp hạng dựa trên lịch sử và sở thích của người dùng.

Cải thiện Hiệu quả Tính toán sẽ làm cho framework dễ tiếp cận hơn cho các môi trường hạn chế tài nguyên. Tối ưu hóa các thuật toán xây dựng, lưu trữ và duyệt đồ thị có thể giảm yêu cầu tính toán trong khi vẫn duy trì hiệu suất, cho phép hệ thống được triển khai trong một phạm vi cài đặt rộng hơn.

Đối với xử lý ngôn ngữ tiếng Việt cụ thể, công việc trong tương lai có thể tập trung vào việc phát triển các mô hình embedding chuyên biệt hơn, cải thiện việc trích xuất triple cho cú pháp tiếng Việt và mở rộng phạm vi các bộ dữ liệu benchmark để đánh giá. Những cải tiến này sẽ nâng cao hơn nữa hiệu quả của framework cho các ứng dụng tiếng Việt và cung cấp một nền tảng vững chắc hơn cho lập luận đa bước trong bối cảnh ngôn ngữ này.

\section{Kết luận}
Luận văn này đã khám phá việc ứng dụng và mở rộng HippoRAG 2 cho các tác vụ xử lý ngôn ngữ tiếng Việt và lập luận đa bước. HippoRAG 2 đại diện cho một bước tiến đáng kể trong việc phát triển các hệ thống RAG gần hơn với bộ nhớ dài hạn của con người. Bằng cách kết hợp thuật toán Personalized PageRank với tích hợp passage sâu hơn và sử dụng LLM hiệu quả hơn trong quá trình online, framework đạt được những cải thiện toàn diện so với các phương pháp RAG tiêu chuẩn trên các tác vụ factual, sense-making, và associative memory.

Thiết kế lấy cảm hứng từ thần kinh học của framework, kết hợp các yếu tố như dense-sparse integration, recognition memory, và balanced reset probabilities, cho phép nó vượt qua những hạn chế trong các phương pháp trước đây và đạt được hiệu suất tốt nhất trên các benchmark đa dạng. Triết lý thiết kế này, dựa trên những hiểu biết sâu sắc từ các quá trình bộ nhớ của con người, cung cấp một nền tảng vững chắc để phát triển các hệ thống AI với khả năng nhận thức giống con người hơn.

Nghiên cứu của tôi đã chứng minh hiệu quả của phương pháp này đối với dữ liệu tiếng Việt, đặc biệt là đối với các tác vụ lập luận đa bước sử dụng bộ dữ liệu VIMQA. Bằng cách tinh chỉnh các thành phần truy xuất và xếp hạng lại cho xử lý ngôn ngữ tiếng Việt, tôi đã chỉ ra rằng những lợi ích của framework HippoRAG 2 có thể được mở rộng sang các bối cảnh ngôn ngữ mới, cung cấp những hiểu biết có giá trị về khả năng áp dụng xuyên ngôn ngữ của nó.

Công trình này không chỉ thúc đẩy lĩnh vực retrieval-augmented generation mà còn mở đường cho continual learning không tham số cho LLM, đưa các hệ thống AI đến gần hơn với khả năng bộ nhớ giống con người. Bằng cách cung cấp một cơ chế để liên tục tích hợp kiến thức mới mà không cần sửa đổi tham số mô hình, HippoRAG 2 giải quyết một trong những thách thức cơ bản trong việc phát triển các hệ thống AI thích ứng.

Khi nghiên cứu trong lĩnh vực này tiếp tục phát triển, những hiểu biết thu được từ việc áp dụng HippoRAG 2 vào xử lý ngôn ngữ tiếng Việt sẽ đóng góp vào việc phát triển các hệ thống bộ nhớ ngày càng tinh vi cho AI, cuối cùng nâng cao khả năng liên tục thu thập, tổ chức và tận dụng kiến thức theo cách gần hơn với trí thông minh của con người. Cách tiếp cận toàn diện của framework đối với việc biểu diễn, truy xuất và sử dụng kiến thức mở ra những khả năng mới cho các ứng dụng AI trên các lĩnh vực và ngôn ngữ đòi hỏi xử lý thông tin phức tạp.

\end{document}
