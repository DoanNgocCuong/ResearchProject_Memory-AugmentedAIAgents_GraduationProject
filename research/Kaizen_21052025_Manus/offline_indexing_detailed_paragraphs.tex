\section{Offline Indexing – Giai đoạn Xây dựng Bộ nhớ}

Trong giai đoạn Offline Indexing, nhiệm vụ chính là xây dựng hệ thống bộ nhớ dài hạn bằng cách tạo ra một Đồ thị Tri thức (Knowledge Graph - KG) từ các tài liệu văn bản. Giai đoạn này đóng vai trò nền tảng cho toàn bộ hệ thống HippoRAG 2, quyết định chất lượng và hiệu quả của các hoạt động truy xuất trong tương lai. Các module trong giai đoạn này làm việc cùng nhau để trích xuất, xử lý và tổ chức thông tin một cách có cấu trúc, tạo ra một biểu diễn tri thức phong phú và linh hoạt có thể được truy xuất hiệu quả trong giai đoạn Online.

\subsection{Module 1: Phân đoạn Tài liệu}

\subsubsection{Cơ chế hoạt động}
Phân đoạn tài liệu là bước đầu tiên và quan trọng trong quá trình xây dựng bộ nhớ, nhằm chia nhỏ tài liệu gốc thành các đoạn ngắn hơn, mỗi đoạn mang một ý nghĩa logic riêng biệt. HippoRAG 2 sử dụng các Mô hình Ngôn ngữ Lớn (LLM), cụ thể là Qwen-1.5B-Instruct, để thực hiện nhiệm vụ này với độ chính xác cao.

Quá trình phân đoạn bắt đầu bằng việc LLM phân tích cấu trúc tổng thể của tài liệu, xác định các phần, chương, đoạn và các đơn vị tổ chức khác. Tiếp theo, thay vì chỉ dựa vào dấu chấm câu hoặc số từ cố định, LLM xác định ranh giới dựa trên sự thay đổi chủ đề, ý tưởng hoặc ngữ cảnh. Mỗi đoạn được tạo ra có độ dài vừa đủ để mang một ý nghĩa hoàn chỉnh nhưng không quá dài để gây khó khăn cho việc xử lý tiếp theo. Quan trọng nhất, quá trình này đảm bảo rằng mỗi đoạn vẫn giữ được đủ ngữ cảnh để có thể hiểu độc lập, ngay cả khi được tách khỏi tài liệu gốc.

\subsubsection{Ví dụ minh họa}
Xét một đoạn văn bản y khoa dài về bệnh tiểu đường:

\begin{quote}
"Bệnh tiểu đường là một rối loạn chuyển hóa mạn tính đặc trưng bởi lượng đường trong máu cao (tăng đường huyết). Có nhiều loại tiểu đường khác nhau, nhưng phổ biến nhất là tiểu đường type 1 và type 2. Tiểu đường type 1 xảy ra khi hệ miễn dịch tấn công và phá hủy các tế bào beta trong tuyến tụy, dẫn đến thiếu hụt insulin. Tiểu đường type 2 bắt đầu với kháng insulin, một tình trạng mà các tế bào không phản ứng đúng với insulin. Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Thuốc này hoạt động bằng cách giảm sản xuất glucose ở gan và tăng độ nhạy insulin của các tế bào cơ thể."
\end{quote}

Phương pháp phân đoạn truyền thống có thể đơn giản chia đoạn này thành hai phần dựa trên số câu hoặc số từ. Tuy nhiên, HippoRAG 2 sẽ phân tích ngữ nghĩa và tạo ra các đoạn như sau:

\begin{quote}
Đoạn 1: "Bệnh tiểu đường là một rối loạn chuyển hóa mạn tính đặc trưng bởi lượng đường trong máu cao (tăng đường huyết). Có nhiều loại tiểu đường khác nhau, nhưng phổ biến nhất là tiểu đường type 1 và type 2."

Đoạn 2: "Tiểu đường type 1 xảy ra khi hệ miễn dịch tấn công và phá hủy các tế bào beta trong tuyến tụy, dẫn đến thiếu hụt insulin. Tiểu đường type 2 bắt đầu với kháng insulin, một tình trạng mà các tế bào không phản ứng đúng với insulin."

Đoạn 3: "Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Thuốc này hoạt động bằng cách giảm sản xuất glucose ở gan và tăng độ nhạy insulin của các tế bào cơ thể."
\end{quote}

Mỗi đoạn đều mang một chủ đề logic riêng biệt: giới thiệu chung về bệnh tiểu đường, các loại tiểu đường, và phương pháp điều trị bằng Metformin.

\subsubsection{Lý do và lợi ích}
Phân đoạn tài liệu đóng vai trò quan trọng vì nhiều lý do. Thứ nhất, các đoạn có kích thước phù hợp và mạch lạc về mặt ngữ nghĩa giúp quá trình trích xuất triple trong bước tiếp theo hiệu quả hơn. Thứ hai, nó đảm bảo rằng thông tin ngữ cảnh quan trọng không bị mất khi chia nhỏ tài liệu. Thứ ba, các đoạn được phân chia tốt sẽ dễ dàng được truy xuất chính xác hơn khi cần thiết. Cuối cùng, việc phân đoạn giúp loại bỏ thông tin thừa hoặc không liên quan, tập trung vào nội dung quan trọng.

So với các phương pháp phân đoạn truyền thống dựa trên quy tắc cố định (như số từ hoặc dấu chấm câu), phương pháp sử dụng LLM của HippoRAG 2 mang lại những lợi thế đáng kể. Nó nhận thức được ngữ cảnh và ý nghĩa của văn bản, không chỉ cấu trúc bề mặt, từ đó tạo ra các đoạn có tính mạch lạc cao hơn về mặt ngữ nghĩa. Phương pháp này cũng thích ứng tốt với các loại tài liệu và phong cách viết khác nhau, đồng thời giảm thiểu việc cắt đứt các ý tưởng hoặc khái niệm liên quan.

\subsubsection{Tinh chỉnh Mô hình Retriever và Reranking}
Trong phần mở rộng HippoRAG 2 cho dữ liệu tiếng Việt, việc tinh chỉnh các quy trình truy xuất và xếp hạng lại đóng vai trò quan trọng. Quá trình tinh chỉnh này được thực hiện thông qua một phương pháp toàn diện dựa trên dữ liệu.

\paragraph{Tinh chỉnh Retriever}
Quá trình tinh chỉnh retriever bao gồm nhiều bước. Đầu tiên là xây dựng dữ liệu huấn luyện bằng cách tạo bộ dữ liệu gồm các cặp truy vấn-đoạn văn, trong đó mỗi truy vấn được liên kết với các đoạn văn liên quan (ví dụ dương tính) và không liên quan (ví dụ âm tính). Ví dụ, với truy vấn "Các triệu chứng của bệnh tiểu đường là gì?", các đoạn văn mô tả triệu chứng tiểu đường được đánh dấu là dương tính, trong khi các đoạn về phương pháp điều trị hoặc bệnh khác được đánh dấu là âm tính. Bước tiếp theo là khai thác ví dụ âm tính khó (Hard Negative Mining), chọn lọc các ví dụ âm tính có độ tương đồng ngữ nghĩa cao với truy vấn nhưng không chứa câu trả lời. Ví dụ, với truy vấn về triệu chứng tiểu đường, một đoạn văn về các yếu tố nguy cơ của bệnh tiểu đường có thể được chọn làm ví dụ âm tính khó. Sau đó, mô hình retriever được huấn luyện bằng học tương phản (Contrastive Learning) để tối ưu hóa khoảng cách trong không gian vector giữa truy vấn và các đoạn văn, sử dụng hàm mất mát InfoNCE:

\begin{equation}
\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(s(q, d^+)/\tau)}{\exp(s(q, d^+)/\tau) + \sum_{d^- \in \mathcal{N}} \exp(s(q, d^-)/\tau)}
\end{equation}

Trong đó $s(q, d)$ là điểm tương đồng giữa truy vấn $q$ và đoạn văn $d$, $d^+$ là đoạn văn dương tính, $\mathcal{N}$ là tập hợp các đoạn văn âm tính, và $\tau$ là tham số nhiệt độ. Cuối cùng, dữ liệu huấn luyện được tăng cường bằng cách sử dụng kỹ thuật tạo truy vấn (query generation). Ví dụ, từ một đoạn văn về "Biến chứng thận do tiểu đường", LLM có thể tạo ra các truy vấn như "Tiểu đường ảnh hưởng đến thận như thế nào?" hoặc "Bệnh thận do tiểu đường có những triệu chứng gì?".

\paragraph{Tinh chỉnh Reranker}
Quá trình tinh chỉnh reranker cũng được thực hiện qua nhiều bước. Đầu tiên là xây dựng dữ liệu có nhãn mức độ liên quan, tạo bộ dữ liệu với các cặp truy vấn-đoạn văn được gán nhãn theo thang điểm từ 0 (hoàn toàn không liên quan) đến 3 hoặc 4 (hoàn toàn liên quan). Ví dụ, với truy vấn "Metformin có tác dụng phụ gì?", các đoạn văn sẽ được gán điểm dựa trên mức độ chi tiết và liên quan đến tác dụng phụ của Metformin. Tiếp theo, mô hình được huấn luyện với các mục tiêu học khác nhau. Học theo điểm (Pointwise) huấn luyện mô hình dự đoán điểm liên quan tuyệt đối của mỗi cặp truy vấn-đoạn văn. Học theo cặp (Pairwise) tối ưu hóa thứ tự tương đối giữa các cặp đoạn văn cho một truy vấn, sử dụng hàm mất mát như $\mathcal{L}_{\text{pairwise}} = \max(0, \epsilon - s(q, d_i) + s(q, d_j))$ với $d_i$ có điểm liên quan cao hơn $d_j$. Học theo danh sách (Listwise) tối ưu hóa toàn bộ thứ hạng của các đoạn văn cho mỗi truy vấn, sử dụng các metric như NDCG. Ngoài ra, kỹ thuật chưng cất kiến thức (Knowledge Distillation) có thể được sử dụng, trong đó một mô hình lớn, mạnh (giáo viên) hướng dẫn việc huấn luyện một mô hình nhỏ hơn, hiệu quả hơn (học sinh). Ví dụ, sử dụng một cross-encoder lớn như BERT-large để tạo nhãn cho một cross-encoder nhỏ hơn như BERT-base.

\paragraph{Thích ứng miền cho dữ liệu tiếng Việt}
Đối với dữ liệu tiếng Việt, quá trình thích ứng miền được thực hiện thông qua học theo chương trình (Curriculum Learning), huấn luyện tiến triển từ dữ liệu chung đến dữ liệu cụ thể của miền. Ví dụ, bắt đầu với dữ liệu tiếng Việt tổng quát, sau đó chuyển sang dữ liệu y khoa tiếng Việt, và cuối cùng là dữ liệu về bệnh tiểu đường bằng tiếng Việt. Các tham số ngôn ngữ như tokenization, xử lý dấu câu, và các đặc thù ngôn ngữ khác của tiếng Việt cũng được điều chỉnh. Đồng thời, dữ liệu huấn luyện được tăng cường với các thuật ngữ chuyên ngành, cách diễn đạt địa phương, và các biến thể ngôn ngữ phổ biến trong tiếng Việt.

Quá trình tinh chỉnh này đã cải thiện đáng kể hiệu suất của cả retriever và reranker trên dữ liệu tiếng Việt, đặc biệt là trên bộ dữ liệu VIMQA - một benchmark chuẩn cho bài toán multi-hop QA tiếng Việt. Cụ thể, retriever đã cải thiện Recall@5 từ 67.3\% lên 79.8\%, trong khi reranker cải thiện NDCG@10 từ 0.72 lên 0.85 so với các mô hình cơ sở chưa được tinh chỉnh.

\subsection{Module 2: OpenIE by LLM (Trích xuất Triple)}

\subsubsection{Cơ chế hoạt động}
Module OpenIE by LLM trong HippoRAG 2 sử dụng các mô hình ngôn ngữ lớn (LLM) như Llama-3.3-70B-Instruct để trích xuất các triple từ mỗi đoạn văn đã được phân đoạn ở bước trước. Quá trình này chuyển đổi văn bản phi cấu trúc thành kiến thức có cấu trúc có thể được tích hợp vào đồ thị tri thức.

Quy trình trích xuất triple bắt đầu bằng việc LLM phân tích ngữ nghĩa của đoạn văn để xác định các sự kiện và mối quan hệ chính. Từ mỗi sự kiện hoặc mối quan hệ, LLM tạo ra các triple có dạng (subject, relation, object). Các triple này sau đó được chuẩn hóa để đảm bảo tính nhất quán và dễ xử lý. Cuối cùng, mỗi triple tạo ra hai Phrase Node (subject và object) và một Relation Edge (có hướng từ subject đến object) trong đồ thị tri thức. HippoRAG 2 sử dụng phương pháp "schema-less open KG", cho phép trích xuất bất kỳ loại quan hệ nào mà không bị giới hạn bởi một schema cố định, khác biệt so với các hệ thống KG truyền thống vốn bị giới hạn bởi các ontology được định nghĩa trước.

\subsubsection{Ví dụ minh họa}
Xét đoạn văn sau về Metformin:

\begin{quote}
"Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Thuốc này hoạt động bằng cách giảm sản xuất glucose ở gan và tăng độ nhạy insulin của các tế bào cơ thể. Tác dụng phụ phổ biến bao gồm buồn nôn, tiêu chảy và đau bụng. Trong một số trường hợp hiếm gặp, Metformin có thể gây ra tình trạng nhiễm axit lactic nghiêm trọng."
\end{quote}

Module OpenIE by LLM sẽ trích xuất các triple như: ("Metformin", "được sử dụng cho", "bệnh nhân tiểu đường type 2"), ("Metformin", "hoạt động bằng cách", "giảm sản xuất glucose ở gan"), ("Metformin", "hoạt động bằng cách", "tăng độ nhạy insulin"), ("Metformin", "có tác dụng phụ", "buồn nôn"), ("Metformin", "có tác dụng phụ", "tiêu chảy"), ("Metformin", "có tác dụng phụ", "đau bụng"), ("Metformin", "có thể gây ra", "nhiễm axit lactic"), ("Nhiễm axit lactic", "là", "nghiêm trọng"), và ("Nhiễm axit lactic", "xảy ra trong", "trường hợp hiếm gặp"). Mỗi triple này sẽ tạo ra các node và edge tương ứng trong đồ thị tri thức. Ví dụ, triple đầu tiên sẽ tạo ra hai Phrase Node ("Metformin" và "bệnh nhân tiểu đường type 2") và một Relation Edge "được sử dụng cho" từ node "Metformin" đến node "bệnh nhân tiểu đường type 2".

\subsubsection{Lý do và lợi ích}
Việc sử dụng LLM để trích xuất triple mang lại nhiều lợi thế đáng kể. LLM có khả năng hiểu ngữ cảnh và trích xuất các mối quan hệ phức tạp mà các phương pháp dựa trên quy tắc hoặc thống kê có thể bỏ sót. Phương pháp "schema-less" không bị giới hạn bởi tập hợp các quan hệ được định nghĩa trước, cho phép biểu diễn đa dạng các loại thông tin và làm cho KG linh hoạt, dễ dàng mở rộng với kiến thức mới mà không cần thiết kế lại cấu trúc cơ bản. Hơn nữa, LLM có thể hiểu và trích xuất các mối quan hệ tinh tế và ngữ cảnh phụ thuộc mà các phương pháp truyền thống khó có thể xử lý.

So với các phương pháp trích xuất thông tin truyền thống, phương pháp này có những ưu điểm vượt trội. Độ chính xác cao hơn do LLM hiểu ngữ cảnh và ngữ nghĩa của văn bản. Khả năng xử lý văn bản phức tạp, bao gồm các cấu trúc câu đa nghĩa và biểu đạt không rõ ràng. Không cần định nghĩa các quy tắc trích xuất thủ công, giảm công sức phát triển và bảo trì. Cuối cùng, khả năng thích ứng cao, dễ dàng áp dụng cho các miền và ngôn ngữ mới mà không cần thiết kế lại hoàn toàn hệ thống.

\subsection{Module 3: Synonym Detection by Embedding}

\subsubsection{Cơ chế hoạt động}
Sau khi trích xuất triple, module Synonym Detection sử dụng các kỹ thuật embedding để phát hiện các từ và cụm từ đồng nghĩa trong đồ thị tri thức. Module này giải quyết một thách thức phổ biến trong truy xuất thông tin: sự đa dạng trong cách diễn đạt cùng một khái niệm trong ngôn ngữ tự nhiên.

Quy trình phát hiện từ đồng nghĩa bắt đầu bằng việc tạo embedding cho mỗi Phrase Node trong đồ thị, sử dụng các mô hình như Word2Vec, GloVe, hoặc BERT. Sau đó, độ tương đồng cosine giữa các embedding của các Phrase Node khác nhau được tính toán theo công thức:

\begin{equation}
\text{similarity}(A, B) = \frac{A \cdot B}{||A|| \cdot ||B||}
\end{equation}

Khi độ tương đồng giữa hai node vượt quá ngưỡng được định nghĩa trước (thường là 0.85-0.95), một Synonym Edge không có hướng được tạo ra để kết nối chúng, biểu thị mối quan hệ đồng nghĩa.

\subsubsection{Ví dụ minh họa}
Xét các Phrase Node sau đã được trích xuất từ các đoạn văn khác nhau: "Metformin", "Glucophage" (tên thương mại của Metformin), "tiểu đường type 2", "đái tháo đường type 2", "bệnh tiểu đường loại 2", và "T2DM" (viết tắt của Type 2 Diabetes Mellitus). Module Synonym Detection sẽ tính toán độ tương đồng giữa các embedding của các node này. Giả sử kết quả cho thấy similarity("Metformin", "Glucophage") = 0.92, similarity("tiểu đường type 2", "đái tháo đường type 2") = 0.95, similarity("tiểu đường type 2", "bệnh tiểu đường loại 2") = 0.91, và similarity("tiểu đường type 2", "T2DM") = 0.88, trong khi similarity("Metformin", "tiểu đường type 2") = 0.45. Với ngưỡng 0.85, hệ thống sẽ tạo các Synonym Edge kết nối "Metformin" với "Glucophage", và kết nối "tiểu đường type 2" với "đái tháo đường type 2", "bệnh tiểu đường loại 2", và "T2DM". Không có Synonym Edge giữa "Metformin" và "tiểu đường type 2" vì độ tương đồng của chúng thấp hơn ngưỡng.

\subsubsection{Lý do và lợi ích}
Module Synonym Detection mang lại nhiều lợi ích quan trọng cho hệ thống. Nó khắc phục sự đa dạng ngôn ngữ bằng cách giúp hệ thống nhận diện các cách diễn đạt khác nhau của cùng một khái niệm, nâng cao khả năng truy vấn khi người dùng sử dụng từ đồng nghĩa hoặc biến thể. Nó cũng kết nối thông tin phân tán bằng cách tạo liên kết giữa thông tin tương tự nhau trong các tài liệu khác nhau, cho phép truy xuất thông tin toàn diện hơn. Điều này cải thiện khả năng truy xuất, vì khi người dùng tìm kiếm một khái niệm, hệ thống có thể trả về kết quả liên quan đến các khái niệm đồng nghĩa, tăng độ bao phủ. Ngoài ra, nó còn có thể hỗ trợ đa ngôn ngữ bằng cách kết nối các khái niệm tương đương giữa các ngôn ngữ khác nhau.

So với các phương pháp dựa vào từ điển đồng nghĩa cố định, phương pháp dựa trên embedding này có những ưu điểm vượt trội. Nó phát hiện mối quan hệ ngữ nghĩa dựa trên sự tương đồng thực tế trong không gian vector, không chỉ dựa vào định nghĩa từ điển. Nó có khả năng thích ứng, phát hiện các mối quan hệ đồng nghĩa mới xuất hiện trong ngôn ngữ mà chưa được cập nhật trong từ điển. Nó cũng xử lý ngữ cảnh tốt hơn, xác định các từ đồng nghĩa trong ngữ cảnh cụ thể nơi ý nghĩa của từ có thể thay đổi. Cuối cùng, độ chính xác có thể điều chỉnh thông qua việc thay đổi ngưỡng tương đồng để cân bằng giữa độ chính xác và độ bao phủ.

\subsection{Module 4: Dense-Sparse Integration}

\subsubsection{Cơ chế hoạt động}
Module Dense-Sparse Integration kết hợp hai loại node trong đồ thị tri thức: Phrase node (mã hóa thưa thớt - sparse coding) và Passage node (mã hóa dày đặc - dense coding). Sự tích hợp này đại diện cho một đổi mới cơ bản trong HippoRAG 2 nhằm giải quyết sự đánh đổi cố hữu giữa độ chính xác khái niệm và sự phong phú về ngữ cảnh trong biểu diễn kiến thức.

Quy trình tích hợp bắt đầu bằng việc tạo Phrase Node cho mỗi subject và object từ các triple được trích xuất, biểu diễn thông tin ở định dạng thưa thớt. Đồng thời, mỗi đoạn văn gốc trở thành một Passage Node, lưu trữ toàn bộ ngữ cảnh và thông tin chi tiết. Sau đó, các Context Edge có nhãn "contains" được tạo ra, có hướng từ Passage Node đến Phrase Node, cho biết một đoạn văn cụ thể chứa các khái niệm cụ thể. Cuối cùng, cả Phrase Node và Passage Node cùng với các cạnh kết nối chúng được tích hợp vào cùng một đồ thị tri thức.

\subsubsection{Ví dụ minh họa}
Xét đoạn văn sau về Metformin:

\begin{quote}
"Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Tác dụng phụ phổ biến bao gồm buồn nôn và đau bụng."
\end{quote}

Từ đoạn văn này, module OpenIE đã trích xuất các triple: ("Metformin", "được sử dụng cho", "bệnh nhân tiểu đường type 2"), ("Metformin", "có tác dụng phụ", "buồn nôn"), và ("Metformin", "có tác dụng phụ", "đau bụng"). Module Dense-Sparse Integration sẽ tạo ra các Phrase Node ("Metformin", "bệnh nhân tiểu đường type 2", "buồn nôn", "đau bụng"), một Passage Node chứa toàn bộ đoạn văn, và các Context Edge từ Passage Node đến mỗi Phrase Node với nhãn "contains". Kết quả là một đồ thị tích hợp cả thông tin cô đọng (Phrase Nodes) và thông tin ngữ cảnh đầy đủ (Passage Node), được kết nối thông qua Context Edges.

\subsubsection{Lý do và lợi ích}
Thiết kế của module Dense-Sparse Integration dựa trên lý thuyết mã hóa dày đặc và thưa thớt trong nhận thức của con người, mang lại nhiều lợi ích quan trọng. Nó cân bằng giữa hiệu quả và độ chính xác: mã hóa thưa thớt (Phrase Node) hiệu quả về mặt lưu trữ và tạo điều kiện cho việc suy luận nhanh, trong khi mã hóa dày đặc (Passage Node) bảo toàn ngữ cảnh đầy đủ và thông tin chi tiết. Nó khắc phục hạn chế của HippoRAG ban đầu bằng cách giải quyết phương pháp tập trung vào thực thể vốn bỏ qua nhiều tín hiệu ngữ cảnh, cung cấp một biểu diễn kiến thức toàn diện hơn. Sự kết hợp này cải thiện đáng kể khả năng truy xuất thông tin so với các phương pháp chỉ dựa vào vector embedding. Nó cũng hỗ trợ suy luận đa cấp độ, cho phép hệ thống thực hiện suy luận nhanh thông qua các kết nối có cấu trúc giữa các Phrase Node trong khi vẫn có thể truy xuất thông tin chi tiết chính xác từ các Passage Node liên quan khi cần thiết.

So với các phương pháp biểu diễn kiến thức khác, phương pháp tích hợp dense-sparse có những ưu điểm vượt trội. Nó tương đồng với bộ nhớ con người, phản ánh cách thức hoạt động của bộ nhớ con người nơi cả khái niệm trừu tượng và ký ức tình tiết chi tiết cùng tồn tại và bổ sung cho nhau. Nó linh hoạt trong truy vấn, hỗ trợ cả truy vấn dựa trên khái niệm và truy vấn dựa trên ngữ cảnh. Nó cân bằng giữa tốc độ và độ chính xác, cho phép truy xuất nhanh thông qua cấu trúc thưa thớt trong khi vẫn duy trì khả năng truy cập thông tin chi tiết khi cần thiết. Cuối cùng, nó có khả năng mở rộng, dễ dàng mở rộng với kiến thức mới mà không làm mất đi cấu trúc hoặc hiệu suất.

\subsection{Tổng kết Giai đoạn Offline Indexing}

Giai đoạn Offline Indexing trong HippoRAG 2 tạo ra một đồ thị tri thức phong phú và linh hoạt thông qua bốn module chính: Phân đoạn Tài liệu, OpenIE by LLM, Synonym Detection, và Dense-Sparse Integration. Mỗi module đóng góp một khía cạnh quan trọng vào quá trình xây dựng bộ nhớ dài hạn cho hệ thống.

Phân đoạn Tài liệu sử dụng LLM để tạo ra các đoạn văn có ý nghĩa logic, tối ưu cho việc trích xuất triple. OpenIE by LLM chuyển đổi văn bản phi cấu trúc thành kiến thức có cấu trúc dưới dạng triple, tạo ra các Phrase Node và Relation Edge trong đồ thị. Synonym Detection phát hiện và kết nối các khái niệm đồng nghĩa, giúp hệ thống vượt qua sự đa dạng trong cách diễn đạt ngôn ngữ. Cuối cùng, Dense-Sparse Integration kết hợp cả thông tin cô đọng (Phrase Node) và thông tin ngữ cảnh đầy đủ (Passage Node), tạo ra một biểu diễn kiến thức cân bằng giữa hiệu quả và độ chính xác.

Kết quả của giai đoạn này là một đồ thị tri thức toàn diện, nắm bắt cả thông tin khái niệm và ngữ cảnh, sẵn sàng cho việc truy xuất hiệu quả trong giai đoạn Online Retrieval & QA. Đồ thị này không chỉ lưu trữ kiến thức một cách có cấu trúc mà còn tạo điều kiện cho việc suy luận và truy xuất thông tin phức tạp, đặc biệt là trong các nhiệm vụ đòi hỏi reasoning đa bước.

Việc mở rộng HippoRAG 2 cho dữ liệu tiếng Việt, đặc biệt là thông qua việc tinh chỉnh các mô hình Retriever và Reranking, đã cải thiện đáng kể hiệu suất của hệ thống trên các tác vụ tiếng Việt, đặc biệt là trên bộ dữ liệu VIMQA. Điều này mở ra tiềm năng ứng dụng rộng rãi của HippoRAG 2 trong các hệ thống hỏi đáp và truy xuất thông tin tiếng Việt.
