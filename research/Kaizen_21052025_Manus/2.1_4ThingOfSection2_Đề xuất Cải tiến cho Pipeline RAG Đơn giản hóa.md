
# Phân tích Pipeline RAG Đơn giản hóa (Dựa trên HippoRAG 2)

Pipeline này là một phiên bản rút gọn của HippoRAG 2, giữ lại một số thành phần cốt lõi trong khi loại bỏ các bước phức tạp liên quan đến tìm kiếm đồ thị.

## 1. Giả định Pha Offline

Mặc dù không được mô tả rõ ràng trong yêu cầu online, pipeline này vẫn ngầm yêu cầu một pha offline tương tự như HippoRAG 2 để chuẩn bị dữ liệu:

*   **Input:** Tập hợp các tài liệu/văn bản (Passages).
*   **Xử lý:**
    1.  **Trích xuất Triples:** Sử dụng các kỹ thuật như OpenIE (có thể dùng LLM) để trích xuất các bộ ba (subject, relation, object) từ passages.
    2.  **Xây dựng Knowledge Graph (KG):** Tạo một đồ thị tri thức từ passages và triples. Đồ thị này có thể bao gồm:
        *   **Phrase Nodes:** Đại diện cho các thực thể/khái niệm (subject/object).
        *   **Passage Nodes:** Đại diện cho các đoạn văn bản gốc.
        *   **Edges:** Các cạnh kết nối các node (ví dụ: Relation Edge, Context Edge, Synonym Edge như trong HippoRAG 2).
*   **Output:** Một Knowledge Graph và một cơ sở dữ liệu chứa các triples đã được trích xuất, cùng với các passages gốc được lập chỉ mục (ví dụ: bằng vector embedding).

## 2. Quy trình Pha Online

Pipeline online xử lý truy vấn của người dùng qua các bước sau:

*   **Input:** Truy vấn (Query) của người dùng.
*   **Bước 1: Truy xuất Kép (Dual Retrieval)**
    *   **Truy xuất Passages:** Sử dụng một mô hình retriever (ví dụ: dựa trên embedding như NV-Embed-v2) để tìm kiếm và xếp hạng các passages trong kho dữ liệu dựa trên độ tương đồng với truy vấn. Kết quả là `Ranked Passages`.
    *   **Truy xuất Triples:** Đồng thời, sử dụng phương pháp "Query to Triple" (như trong HippoRAG 2, dùng embedding để so khớp toàn bộ truy vấn với các triples đã trích xuất) để tìm kiếm và xếp hạng các triples. Kết quả là `Ranked Triples`.
*   **Bước 2: Lọc Triples (Triple Filtering)**
    *   Áp dụng một cơ chế lọc (tương tự Recognition Memory của HippoRAG 2) lên `Ranked Triples`. Mục tiêu là loại bỏ các triples không liên quan hoặc có độ tin cậy thấp, giữ lại những triple phù hợp nhất với truy vấn. Kết quả là `Filtered Triples`.
*   **Bước 3 (Ngầm định): Tổng hợp và Tạo câu trả lời (QA Generation)**
    *   Pipeline theo mô tả dừng lại sau bước lọc triples. Tuy nhiên, để hoàn chỉnh quy trình RAG, bước tiếp theo sẽ là sử dụng `Ranked Passages` và `Filtered Triples` làm ngữ cảnh đầu vào cho một Large Language Model (LLM).
    *   LLM sẽ tổng hợp thông tin từ cả hai nguồn (văn bản và triples) để tạo ra câu trả lời cuối cùng cho truy vấn của người dùng.

## 3. Các Module được giữ lại từ HippoRAG 2

*   Kiến trúc đồ thị cơ bản (ngầm định từ pha offline).
*   Truy xuất kép (Passages và Triples).
*   Phương pháp "Query to Triple" để truy xuất triple.
*   Cơ chế lọc triple (Recognition Memory).

## 4. Các Module bị loại bỏ từ HippoRAG 2

*   Gán trọng số cho Seed Node (Assigning Seed Node Weights).
*   Tìm kiếm đồ thị bằng Personalized PageRank (PPR Graph Search).

## 5. Đặc điểm

*   **Ưu điểm:** Đơn giản hơn đáng kể so với HippoRAG 2, giảm chi phí tính toán và độ phức tạp triển khai do loại bỏ bước PPR. Vẫn tận dụng được kiến thức có cấu trúc (triples) để cải thiện độ chính xác so với RAG truyền thống chỉ dựa trên passage.
*   **Nhược điểm:** Mất khả năng suy luận đa bước qua đồ thị (do loại bỏ PPR). Việc tích hợp thông tin giữa passages và triples cho LLM ở bước cuối cùng trở nên kém rõ ràng hơn (không có cơ chế xếp hạng lại passage dựa trên PPR). Có thể bỏ lỡ thông tin quan trọng nằm ở các node/passage không được truy xuất trực tiếp.


----


# Đề xuất Cải tiến cho Pipeline RAG Đơn giản hóa

Pipeline RAG đơn giản hóa của bạn (chỉ giữ lại Ranked Passages, Ranked Triples, Filtered Triples) là một điểm khởi đầu tốt, tập trung vào việc kết hợp truy xuất văn bản và truy xuất triple cơ bản. Dưới đây là một số đề xuất cải tiến, lấy cảm hứng từ các kỹ thuật trong HippoRAG 2, GraphRAG và các nghiên cứu về KG Retrieval, nhằm nâng cao hiệu quả mà không cần khôi phục hoàn toàn độ phức tạp của PPR:

## 1. Truy xuất Triple Lai (Hybrid Triple Retrieval)

*   **Ý tưởng:** Cải thiện bước tạo `Ranked Triples` ban đầu bằng cách kết hợp cả phương pháp truy xuất thưa (sparse) và dày đặc (dense), tương tự như cách truy xuất passage.
*   **Cơ chế:**
    1.  Tuyến tính hóa *tất cả* triples trong KG thành câu văn bản.
    2.  Sử dụng cả BM25 (sparse) và một mô hình embedding (dense, ví dụ: NV-Embed-v2, DPR) để truy xuất các câu triple liên quan đến truy vấn.
    3.  Kết hợp kết quả từ cả hai retriever (ví dụ: dùng Reciprocal Rank Fusion - RRF) để tạo ra danh sách `Ranked Triples` ban đầu chất lượng hơn.
*   **Lợi ích:** Tận dụng cả sự trùng khớp từ khóa (BM25) và sự tương đồng ngữ nghĩa (embedding), giúp tìm được nhiều triple liên quan hơn, đặc biệt là các triple sử dụng từ ngữ khác với truy vấn nhưng cùng ý nghĩa. Tham khảo [kg_retrieval_1].


## 2. Xếp hạng lại Passage dựa trên Triple (Triple-based Passage Reranking)

*   **Ý tưởng:** Sử dụng thông tin từ các `Filtered Triples` (được coi là các facts đáng tin cậy nhất liên quan đến truy vấn) để đánh giá lại và xếp hạng lại danh sách `Ranked Passages` ban đầu.
*   **Cơ chế:**
    1.  Sau khi có `Ranked Passages` và `Filtered Triples`.
    2.  Đối với mỗi passage trong `Ranked Passages`, kiểm tra xem nó chứa bao nhiêu thực thể (subject/object) hoặc hỗ trợ bao nhiêu mối quan hệ từ các `Filtered Triples`.
    3.  Tính một điểm số mới cho mỗi passage dựa trên mức độ liên quan của nó với các `Filtered Triples` (ví dụ: số lượng thực thể/triple trùng khớp, điểm tương đồng ngữ nghĩa giữa passage và các triple).
    4.  Kết hợp điểm số mới này với điểm số truy xuất ban đầu (từ retriever passage) để tạo ra một bảng xếp hạng passage cuối cùng, ưu tiên các passage được "xác nhận" bởi các triple đáng tin cậy.
*   **Lợi ích:** Giúp ưu tiên các đoạn văn bản không chỉ tương đồng với truy vấn mà còn được hỗ trợ bởi các bằng chứng cấu trúc từ KG, tăng độ tin cậy và chính xác của ngữ cảnh cung cấp cho LLM.

## 3. Mở rộng Đồ thị Cục bộ (Lightweight Graph Expansion - No PPR)

*   **Ý tưởng:** Tận dụng một phần nhỏ cấu trúc đồ thị để tìm thêm thông tin liên quan mà không cần chạy PPR đầy đủ.
*   **Cơ chế:** *(Đã được giải thích chi tiết trong file ví dụ trước)*
    1.  Lấy các thực thể (subject/object) từ `Filtered Triples`.
    2.  Thực hiện tìm kiếm 1-hop trên Knowledge Graph từ các thực thể này.
    3.  Thu thập các triple hoặc các Phrase Node/Passage Node kết nối trực tiếp (1-hop neighbors).
    4.  Bổ sung các thông tin 1-hop này vào ngữ cảnh cho LLM (kết hợp với đề xuất 2).
*   **Lợi ích:** Khôi phục một phần khả năng suy luận đa bước bị mất do loại bỏ PPR, nhưng với chi phí tính toán thấp hơn nhiều. Chỉ tập trung vào thông tin liền kề nhất trong đồ thị.


## 4. Đưa Triple đã lọc vào Ngữ cảnh LLM (Inject Filtered Triples into LLM Context)

*   **Ý tưởng:** Cung cấp trực tiếp các `Filtered Triples` (dưới dạng văn bản tự nhiên) cho LLM cùng với các `Ranked Passages` (đã được rerank hoặc chưa).
*   **Cơ chế:**
    1.  Tuyến tính hóa các `Filtered Triples` thành các câu văn bản tự nhiên (ví dụ: "Metformin có tác dụng phụ là buồn nôn.").
    2.  Xây dựng prompt cho LLM bao gồm: câu truy vấn, các passage được xếp hạng cao nhất (Top-K), và các câu triple đã tuyến tính hóa.
    3.  Yêu cầu LLM trả lời câu hỏi dựa trên *cả* passages và triples được cung cấp.
*   **Lợi ích:** Cung cấp trực tiếp kiến thức cấu trúc, rõ ràng cho LLM, giúp LLM có thêm facts chính xác để suy luận, đặc biệt hữu ích khi thông tin trong passages có thể mơ hồ hoặc không đầy đủ. Đây là cách tiếp cận cốt lõi của nhiều hệ thống KG-RAG [kg_retrieval_3].

