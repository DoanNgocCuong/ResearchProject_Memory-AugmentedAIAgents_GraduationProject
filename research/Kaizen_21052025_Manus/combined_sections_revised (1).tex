\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}
\usepackage{amsmath}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

\begin{document}

\section{Offline Indexing – Giai đoạn Xây dựng Bộ nhớ}

Trong giai đoạn Offline Indexing, nhiệm vụ chính là xây dựng hệ thống bộ nhớ dài hạn bằng cách tạo ra một Đồ thị Tri thức (Knowledge Graph - KG) từ các tài liệu văn bản. Giai đoạn này đóng vai trò nền tảng cho toàn bộ hệ thống được đề xuất, quyết định chất lượng và hiệu quả của các hoạt động truy xuất trong tương lai. Các module trong giai đoạn này làm việc cùng nhau để trích xuất, xử lý và tổ chức thông tin một cách có cấu trúc, tạo ra một biểu diễn tri thức phong phú và linh hoạt có thể được truy xuất hiệu quả trong giai đoạn Online.

\subsection{Module 1: Phân đoạn Tài liệu}

\subsubsection{Diễn giải chi tiết Module}
Phân đoạn tài liệu là bước đầu tiên và quan trọng trong quá trình xây dựng bộ nhớ, nhằm chia nhỏ tài liệu gốc thành các đoạn ngắn hơn, mỗi đoạn mang một ý nghĩa logic riêng biệt. Hệ thống được đề xuất sử dụng các Mô hình Ngôn ngữ Lớn (LLM), cụ thể là Qwen-1.5B-Instruct, để thực hiện nhiệm vụ này với độ chính xác cao. Quá trình phân đoạn bắt đầu bằng việc LLM phân tích cấu trúc tổng thể của tài liệu, xác định các phần, chương, đoạn và các đơn vị tổ chức khác. Tiếp theo, thay vì chỉ dựa vào dấu chấm câu hoặc số từ cố định, LLM xác định ranh giới dựa trên sự thay đổi chủ đề, ý tưởng hoặc ngữ cảnh. Mỗi đoạn được tạo ra có độ dài vừa đủ để mang một ý nghĩa hoàn chỉnh nhưng không quá dài để gây khó khăn cho việc xử lý tiếp theo. Quan trọng nhất, quá trình này đảm bảo rằng mỗi đoạn vẫn giữ được đủ ngữ cảnh để có thể hiểu độc lập, ngay cả khi được tách khỏi tài liệu gốc.

Phân đoạn tài liệu đóng vai trò quan trọng vì nhiều lý do. Các đoạn có kích thước phù hợp và mạch lạc về mặt ngữ nghĩa giúp quá trình trích xuất triple trong bước tiếp theo hiệu quả hơn. Nó đảm bảo rằng thông tin ngữ cảnh quan trọng không bị mất khi chia nhỏ tài liệu. Các đoạn được phân chia tốt sẽ dễ dàng được truy xuất chính xác hơn khi cần thiết. Việc phân đoạn cũng giúp loại bỏ thông tin thừa hoặc không liên quan, tập trung vào nội dung quan trọng. So với các phương pháp phân đoạn truyền thống dựa trên quy tắc cố định, phương pháp sử dụng LLM của hệ thống được đề xuất mang lại những lợi thế đáng kể. Nó nhận thức được ngữ cảnh và ý nghĩa của văn bản, không chỉ cấu trúc bề mặt, từ đó tạo ra các đoạn có tính mạch lạc cao hơn về mặt ngữ nghĩa. Phương pháp này cũng thích ứng tốt với các loại tài liệu và phong cách viết khác nhau, đồng thời giảm thiểu việc cắt đứt các ý tưởng hoặc khái niệm liên quan.

\subsubsection{Ví dụ minh họa}
Xét một đoạn văn bản y khoa dài về bệnh tiểu đường:

\begin{quote}
"Bệnh tiểu đường là một rối loạn chuyển hóa mạn tính đặc trưng bởi lượng đường trong máu cao (tăng đường huyết). Có nhiều loại tiểu đường khác nhau, nhưng phổ biến nhất là tiểu đường type 1 và type 2. Tiểu đường type 1 xảy ra khi hệ miễn dịch tấn công và phá hủy các tế bào beta trong tuyến tụy, dẫn đến thiếu hụt insulin. Tiểu đường type 2 bắt đầu với kháng insulin, một tình trạng mà các tế bào không phản ứng đúng với insulin. Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Thuốc này hoạt động bằng cách giảm sản xuất glucose ở gan và tăng độ nhạy insulin của các tế bào cơ thể."
\end{quote}

Phương pháp phân đoạn truyền thống có thể đơn giản chia đoạn này thành hai phần dựa trên số câu hoặc số từ. Tuy nhiên, hệ thống được đề xuất sẽ phân tích ngữ nghĩa và tạo ra các đoạn như sau:

\begin{quote}
Đoạn 1: "Bệnh tiểu đường là một rối loạn chuyển hóa mạn tính đặc trưng bởi lượng đường trong máu cao (tăng đường huyết). Có nhiều loại tiểu đường khác nhau, nhưng phổ biến nhất là tiểu đường type 1 và type 2."

Đoạn 2: "Tiểu đường type 1 xảy ra khi hệ miễn dịch tấn công và phá hủy các tế bào beta trong tuyến tụy, dẫn đến thiếu hụt insulin. Tiểu đường type 2 bắt đầu với kháng insulin, một tình trạng mà các tế bào không phản ứng đúng với insulin."

Đoạn 3: "Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Thuốc này hoạt động bằng cách giảm sản xuất glucose ở gan và tăng độ nhạy insulin của các tế bào cơ thể."
\end{quote}

Mỗi đoạn đều mang một chủ đề logic riêng biệt: giới thiệu chung về bệnh tiểu đường, các loại tiểu đường, và phương pháp điều trị bằng Metformin.

\subsubsection{Tinh chỉnh Mô hình Retriever và Reranking}

\paragraph{Diễn giải chi tiết}
Trong phần mở rộng hệ thống cho dữ liệu tiếng Việt, việc tinh chỉnh các quy trình truy xuất và xếp hạng lại đóng vai trò quan trọng. Quá trình tinh chỉnh này được thực hiện thông qua một phương pháp toàn diện dựa trên dữ liệu. Đối với tinh chỉnh retriever, quá trình bao gồm nhiều bước. Đầu tiên là xây dựng dữ liệu huấn luyện bằng cách tạo bộ dữ liệu gồm các cặp truy vấn-đoạn văn liên quan (dương tính) và không liên quan (âm tính). Bước tiếp theo là khai thác ví dụ âm tính khó (Hard Negative Mining), chọn lọc các ví dụ âm tính có độ tương đồng ngữ nghĩa cao với truy vấn nhưng không chứa câu trả lời. Sau đó, mô hình retriever được huấn luyện bằng học tương phản (Contrastive Learning) để tối ưu hóa khoảng cách trong không gian vector giữa truy vấn và các đoạn văn, sử dụng hàm mất mát InfoNCE: $\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(s(q, d^+)/\tau)}{\exp(s(q, d^+)/\tau) + \sum_{d^- \in \mathcal{N}} \exp(s(q, d^-)/\tau)}$. Cuối cùng, dữ liệu huấn luyện được tăng cường bằng kỹ thuật tạo truy vấn (query generation).

Đối với tinh chỉnh reranker, quá trình cũng gồm nhiều bước. Đầu tiên là xây dựng dữ liệu có nhãn mức độ liên quan, gán nhãn cho các cặp truy vấn-đoạn văn theo thang điểm liên quan. Tiếp theo, mô hình được huấn luyện với các mục tiêu học khác nhau như học theo điểm (Pointwise), học theo cặp (Pairwise) sử dụng hàm mất mát như $\mathcal{L}_{\text{pairwise}} = \max(0, \epsilon - s(q, d_i) + s(q, d_j))$, hoặc học theo danh sách (Listwise) tối ưu hóa metric như NDCG. Kỹ thuật chưng cất kiến thức (Knowledge Distillation) cũng có thể được áp dụng. Đối với dữ liệu tiếng Việt, quá trình thích ứng miền được thực hiện thông qua học theo chương trình (Curriculum Learning), điều chỉnh tham số ngôn ngữ, và tăng cường dữ liệu đặc thù. Quá trình tinh chỉnh này đã cải thiện đáng kể hiệu suất của cả retriever và reranker trên dữ liệu tiếng Việt, đặc biệt là trên bộ dữ liệu VIMQA.

\paragraph{Ví dụ minh họa}
Ví dụ về xây dựng dữ liệu huấn luyện retriever: Với truy vấn "Các triệu chứng của bệnh tiểu đường là gì?", các đoạn văn mô tả triệu chứng tiểu đường được đánh dấu là dương tính, trong khi các đoạn về phương pháp điều trị hoặc bệnh khác được đánh dấu là âm tính. Ví dụ về khai thác ví dụ âm tính khó: Với truy vấn về triệu chứng tiểu đường, một đoạn văn về các yếu tố nguy cơ của bệnh tiểu đường có thể được chọn làm ví dụ âm tính khó. Ví dụ về tăng cường dữ liệu: Từ một đoạn văn về "Biến chứng thận do tiểu đường", LLM có thể tạo ra các truy vấn như "Tiểu đường ảnh hưởng đến thận như thế nào?".

Ví dụ về xây dựng dữ liệu reranker: Với truy vấn "Metformin có tác dụng phụ gì?", các đoạn văn sẽ được gán điểm từ 0 đến 4 dựa trên mức độ chi tiết và liên quan đến tác dụng phụ của Metformin. Ví dụ về chưng cất kiến thức: Sử dụng một cross-encoder lớn như BERT-large để tạo nhãn cho một cross-encoder nhỏ hơn như BERT-base. Ví dụ về thích ứng miền: Bắt đầu huấn luyện với dữ liệu tiếng Việt tổng quát, sau đó chuyển sang dữ liệu y khoa tiếng Việt, và cuối cùng là dữ liệu về bệnh tiểu đường bằng tiếng Việt.

Kết quả tinh chỉnh trên VIMQA: Retriever cải thiện Recall@5 từ 67.3\% lên 79.8\%, reranker cải thiện NDCG@10 từ 0.72 lên 0.85.

\subsection{Module 2: OpenIE by LLM (Trích xuất Triple)}

\subsubsection{Diễn giải chi tiết Module}
Module OpenIE by LLM trong hệ thống được đề xuất sử dụng các mô hình ngôn ngữ lớn (LLM) như Llama-3.3-70B-Instruct để trích xuất các triple từ mỗi đoạn văn đã được phân đoạn ở bước trước. Quá trình này chuyển đổi văn bản phi cấu trúc thành kiến thức có cấu trúc có thể được tích hợp vào đồ thị tri thức. Quy trình trích xuất triple bắt đầu bằng việc LLM phân tích ngữ nghĩa của đoạn văn để xác định các sự kiện và mối quan hệ chính. Từ mỗi sự kiện hoặc mối quan hệ, LLM tạo ra các triple có dạng (subject, relation, object). Các triple này sau đó được chuẩn hóa để đảm bảo tính nhất quán và dễ xử lý. Cuối cùng, mỗi triple tạo ra hai Phrase Node (subject và object) và một Relation Edge (có hướng từ subject đến object) trong đồ thị tri thức. Hệ thống sử dụng phương pháp "schema-less open KG", cho phép trích xuất bất kỳ loại quan hệ nào mà không bị giới hạn bởi một schema cố định, khác biệt so với các hệ thống KG truyền thống.

Việc sử dụng LLM để trích xuất triple mang lại nhiều lợi thế. LLM có khả năng hiểu ngữ cảnh và trích xuất các mối quan hệ phức tạp. Phương pháp "schema-less" cho phép biểu diễn đa dạng thông tin và làm cho KG linh hoạt, dễ mở rộng. LLM cũng có thể hiểu và trích xuất các mối quan hệ tinh tế và ngữ cảnh phụ thuộc. So với các phương pháp truyền thống, phương pháp này có độ chính xác cao hơn, khả năng xử lý văn bản phức tạp tốt hơn, không cần quy tắc thủ công và có khả năng thích ứng cao.

\subsubsection{Ví dụ minh họa}
Xét đoạn văn sau về Metformin:

\begin{quote}
"Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Thuốc này hoạt động bằng cách giảm sản xuất glucose ở gan và tăng độ nhạy insulin của các tế bào cơ thể. Tác dụng phụ phổ biến bao gồm buồn nôn, tiêu chảy và đau bụng. Trong một số trường hợp hiếm gặp, Metformin có thể gây ra tình trạng nhiễm axit lactic nghiêm trọng."
\end{quote}

Module OpenIE by LLM sẽ trích xuất các triple như: ("Metformin", "được sử dụng cho", "bệnh nhân tiểu đường type 2"), ("Metformin", "hoạt động bằng cách", "giảm sản xuất glucose ở gan"), ("Metformin", "hoạt động bằng cách", "tăng độ nhạy insulin"), ("Metformin", "có tác dụng phụ", "buồn nôn"), ("Metformin", "có tác dụng phụ", "tiêu chảy"), ("Metformin", "có tác dụng phụ", "đau bụng"), ("Metformin", "có thể gây ra", "nhiễm axit lactic"), ("Nhiễm axit lactic", "là", "nghiêm trọng"), và ("Nhiễm axit lactic", "xảy ra trong", "trường hợp hiếm gặp"). Mỗi triple này sẽ tạo ra các node và edge tương ứng trong đồ thị tri thức. Ví dụ, triple đầu tiên sẽ tạo ra hai Phrase Node ("Metformin" và "bệnh nhân tiểu đường type 2") và một Relation Edge "được sử dụng cho" từ node "Metformin" đến node "bệnh nhân tiểu đường type 2".

\subsection{Module 3: Synonym Detection by Embedding}

\subsubsection{Diễn giải chi tiết Module}
Sau khi trích xuất triple, module Synonym Detection sử dụng các kỹ thuật embedding để phát hiện các từ và cụm từ đồng nghĩa trong đồ thị tri thức, giải quyết thách thức về sự đa dạng trong cách diễn đạt cùng một khái niệm. Quy trình bắt đầu bằng việc tạo embedding cho mỗi Phrase Node, sử dụng các mô hình như Word2Vec, GloVe, hoặc BERT. Sau đó, độ tương đồng cosine giữa các embedding của các Phrase Node khác nhau được tính toán: $\text{similarity}(A, B) = \frac{A \cdot B}{||A|| \cdot ||B||}$. Khi độ tương đồng giữa hai node vượt quá ngưỡng được định nghĩa trước (thường là 0.85-0.95), một Synonym Edge không có hướng được tạo ra để kết nối chúng.

Module này mang lại nhiều lợi ích. Nó khắc phục sự đa dạng ngôn ngữ, giúp hệ thống nhận diện các cách diễn đạt khác nhau của cùng một khái niệm. Nó kết nối thông tin phân tán bằng cách tạo liên kết giữa thông tin tương tự nhau. Điều này cải thiện khả năng truy xuất, tăng độ bao phủ của kết quả. Nó còn có thể hỗ trợ đa ngôn ngữ. So với từ điển đồng nghĩa cố định, phương pháp dựa trên embedding phát hiện mối quan hệ ngữ nghĩa thực tế, có khả năng thích ứng với từ mới, xử lý ngữ cảnh tốt hơn và cho phép điều chỉnh độ chính xác.

\subsubsection{Ví dụ minh họa}
Xét các Phrase Node sau: "Metformin", "Glucophage" (tên thương mại), "tiểu đường type 2", "đái tháo đường type 2", "bệnh tiểu đường loại 2", và "T2DM". Module Synonym Detection tính toán độ tương đồng. Giả sử similarity("Metformin", "Glucophage") = 0.92, similarity("tiểu đường type 2", "đái tháo đường type 2") = 0.95, similarity("tiểu đường type 2", "bệnh tiểu đường loại 2") = 0.91, và similarity("tiểu đường type 2", "T2DM") = 0.88, trong khi similarity("Metformin", "tiểu đường type 2") = 0.45. Với ngưỡng 0.85, hệ thống sẽ tạo Synonym Edge kết nối "Metformin" với "Glucophage", và kết nối "tiểu đường type 2" với "đái tháo đường type 2", "bệnh tiểu đường loại 2", và "T2DM".

\subsection{Module 4: Dense-Sparse Integration}

\subsubsection{Diễn giải chi tiết Module}
Module Dense-Sparse Integration kết hợp hai loại node trong đồ thị tri thức: Phrase node (mã hóa thưa thớt - sparse coding) và Passage node (mã hóa dày đặc - dense coding). Sự tích hợp này giải quyết sự đánh đổi giữa độ chính xác khái niệm và sự phong phú về ngữ cảnh. Quy trình tích hợp bắt đầu bằng việc tạo Phrase Node cho mỗi subject và object từ các triple, biểu diễn thông tin ở định dạng thưa thớt. Đồng thời, mỗi đoạn văn gốc trở thành một Passage Node, lưu trữ toàn bộ ngữ cảnh. Sau đó, các Context Edge có nhãn "contains" được tạo ra, có hướng từ Passage Node đến Phrase Node. Cuối cùng, cả hai loại node và các cạnh kết nối được tích hợp vào cùng một đồ thị tri thức.

Thiết kế này cân bằng giữa hiệu quả và độ chính xác: mã hóa thưa thớt hiệu quả về lưu trữ và suy luận nhanh, trong khi mã hóa dày đặc bảo toàn ngữ cảnh đầy đủ. Nó khắc phục hạn chế của các phương pháp trước đây vốn tập trung vào thực thể và bỏ qua tín hiệu ngữ cảnh. Sự kết hợp này cải thiện khả năng truy xuất và hỗ trợ suy luận đa cấp độ. So với các phương pháp khác, nó tương đồng với bộ nhớ con người, linh hoạt trong truy vấn, cân bằng tốc độ và độ chính xác, và có khả năng mở rộng.

\subsubsection{Ví dụ minh họa}
Xét đoạn văn: "Metformin thường được sử dụng như liệu pháp đầu tay cho bệnh nhân tiểu đường type 2. Tác dụng phụ phổ biến bao gồm buồn nôn và đau bụng." Từ các triple đã trích xuất: ("Metformin", "được sử dụng cho", "bệnh nhân tiểu đường type 2"), ("Metformin", "có tác dụng phụ", "buồn nôn"), và ("Metformin", "có tác dụng phụ", "đau bụng"). Module Dense-Sparse Integration sẽ tạo ra các Phrase Node ("Metformin", "bệnh nhân tiểu đường type 2", "buồn nôn", "đau bụng"), một Passage Node chứa toàn bộ đoạn văn, và các Context Edge từ Passage Node đến mỗi Phrase Node với nhãn "contains".

\subsection{Tổng kết Giai đoạn Offline Indexing}

Giai đoạn Offline Indexing trong hệ thống được đề xuất tạo ra một đồ thị tri thức phong phú và linh hoạt thông qua bốn module chính: Phân đoạn Tài liệu, OpenIE by LLM, Synonym Detection, và Dense-Sparse Integration. Phân đoạn Tài liệu tạo ra các đoạn văn có ý nghĩa logic. OpenIE by LLM chuyển đổi văn bản thành kiến thức có cấu trúc dưới dạng triple. Synonym Detection kết nối các khái niệm đồng nghĩa. Dense-Sparse Integration kết hợp thông tin cô đọng và thông tin ngữ cảnh đầy đủ. Kết quả là một đồ thị tri thức toàn diện, sẵn sàng cho việc truy xuất hiệu quả trong giai đoạn Online, hỗ trợ suy luận và truy xuất thông tin phức tạp. Việc mở rộng và tinh chỉnh cho dữ liệu tiếng Việt đã cải thiện đáng kể hiệu suất hệ thống.

\section{Online Retrieval \& QA – Giai đoạn Truy hồi và Phản hồi}

Giai đoạn này mô tả chi tiết quy trình xử lý truy vấn và tạo phản hồi trong pipeline RAG được đề xuất, dựa trên kiến thức đã được cấu trúc hóa ở giai đoạn Offline. Pipeline này được thiết kế để cân bằng giữa hiệu quả tính toán và chất lượng thông tin, kết hợp truy xuất văn bản và truy xuất tri thức cấu trúc, đồng thời tích hợp các kỹ thuật nâng cao để tối ưu hóa ngữ cảnh đầu vào cho Mô hình Ngôn ngữ Lớn (LLM).

\subsection{Module 1: Truy xuất Kép và Lai (Passages \& Hybrid Triples)}

\subsubsection{Diễn giải chi tiết Module}
Khi nhận được một truy vấn từ người dùng, module đầu tiên thực hiện truy xuất song song từ hai nguồn dữ liệu: kho văn bản (để lấy passages) và Đồ thị Tri thức (KG - để lấy triples). Mục tiêu là thu thập một tập hợp thông tin ban đầu đa dạng, bao gồm cả ngữ cảnh rộng và các facts cụ thể.

Quá trình truy xuất passage nhằm xác định các đoạn văn bản trong kho dữ liệu có khả năng chứa thông tin liên quan đến truy vấn. Một mô hình retriever hiệu quả (dense retriever hoặc hybrid BM25/dense) được sử dụng để tính toán điểm tương đồng giữa truy vấn và từng đoạn văn bản, tạo ra danh sách `Ranked Passages`.

Đồng thời, hệ thống thực hiện truy xuất triple từ KG bằng phương pháp lai. Quá trình này bắt đầu bằng việc tuyến tính hóa mỗi triple thành câu tự nhiên. Sau đó, truy xuất Sparse (BM25) và truy xuất Dense (Embedding, ví dụ NV-Embed-v2) được áp dụng song song trên các câu triple đã tuyến tính hóa. Kết quả từ hai phương pháp truy xuất này được kết hợp bằng Reciprocal Rank Fusion (RRF) để tạo ra danh sách `Ranked Triples` chất lượng cao, xem xét cả sự trùng khớp từ khóa và sự tương đồng ngữ nghĩa.

\subsubsection{Ví dụ minh họa}
Ví dụ truy xuất Passage: Với truy vấn "Tác dụng phụ phổ biến của Metformin là gì?", mô hình retriever có thể trả về Passage A (Điểm: 0.85) mô tả "Metformin là thuốc điều trị tiểu đường type 2. Một số tác dụng phụ thường gặp bao gồm buồn nôn, tiêu chảy và đau bụng...", tiếp theo là Passage B (Điểm: 0.78) và Passage C (Điểm: 0.72).

Ví dụ truy xuất Triple Lai: Triple `(Metformin, hasSideEffect, Nausea)` được tuyến tính hóa thành "Metformin has side effect Nausea.". BM25 có thể trả về [("Metformin has side effect Nausea.", Score: 15.2), ...]. Dense retriever có thể trả về [("Metformin has side effect Nausea.", Score: 0.91), ...]. RRF kết hợp kết quả, ví dụ: [(`(Metformin, hasSideEffect, Nausea)`, Score: 0.082), (`(Metformin, causesSideEffect, Diarrhea)`, Score: 0.048), ...].

\subsection{Module 2: Lọc Triple (Triple Filtering)}

\subsubsection{Diễn giải chi tiết Module}
Danh sách `Ranked Triples` từ Module 1 có thể vẫn chứa thông tin không liên quan. Module này thực hiện lọc để giữ lại những facts cốt lõi và đáng tin cậy nhất. Một phương pháp ví dụ là lọc dựa trên LLM đơn giản hóa. Đầu tiên, chọn Top-N triple có điểm RRF cao nhất. Tiếp theo, đối với mỗi triple trong Top-N, sử dụng một LLM nhỏ hơn với một prompt được thiết kế để đánh giá mức độ liên quan trực tiếp của triple đó với truy vấn gốc. Cuối cùng, chỉ giữ lại những triple được LLM đánh giá là có liên quan trực tiếp, tạo thành tập `Filtered Triples`.

\subsubsection{Ví dụ minh họa}
Áp dụng lọc LLM cho các `Ranked Triples` ở trên với truy vấn "Tác dụng phụ phổ biến của Metformin là gì?":
*   `(Metformin, hasSideEffect, Nausea)` -> LLM đánh giá: Có
*   `(Metformin, causesSideEffect, Diarrhea)` -> LLM đánh giá: Có
*   `(Metformin, mayCause, AbdominalPain)` -> LLM đánh giá: Có
*   `(Metformin, treats, DiabetesType2)` -> LLM đánh giá: Không (không phải tác dụng phụ)
Kết quả là tập `Filtered Triples`: {`(Metformin, hasSideEffect, Nausea)`, `(Metformin, causesSideEffect, Diarrhea)`, `(Metformin, mayCause, AbdominalPain)`}.

\subsection{Module 3: Xếp hạng lại Passage và Mở rộng Ngữ cảnh (Passage Reranking \& Context Expansion)}

\subsubsection{Diễn giải chi tiết Module}
Module này tinh chỉnh và làm giàu ngữ cảnh sẽ được cung cấp cho LLM bằng cách tận dụng các `Filtered Triples` và cấu trúc cục bộ của KG.

Bước xếp hạng lại passage dựa trên triple (Triple-based Passage Reranking) nhằm ưu tiên các passage không chỉ tương tự truy vấn mà còn được hỗ trợ bởi các facts đáng tin cậy trong `Filtered Triples`. Quá trình bao gồm kiểm tra sự hỗ trợ (passage có chứa thực thể từ triple không), tính điểm rerank (ví dụ: đếm số triple được hỗ trợ), kết hợp điểm retriever ban đầu và điểm rerank, và cuối cùng là sắp xếp lại các passage dựa trên điểm cuối cùng (`Reranked Passages`).

Bước mở rộng đồ thị cục bộ (Lightweight Graph Expansion) tìm kiếm thêm thông tin liên quan trực tiếp đến các facts cốt lõi đã xác định. Quá trình bao gồm xác định thực thể cốt lõi từ `Filtered Triples`, thực hiện tìm kiếm 1-hop trên KG đối với mỗi thực thể cốt lõi (tìm các triple mà thực thể tham gia), và thu thập các triple 1-hop mới tìm được này thành `Expanded Context`.

\subsubsection{Ví dụ minh họa}
Ví dụ Xếp hạng lại Passage: Giả sử `Filtered Triples` = {`(M, SE, N)`, `(M, SE, D)`, `(M, SE, AP)`}. Passage A (Score: 0.85) chứa "Metformin", "buồn nôn", "tiêu chảy", "đau bụng" (hỗ trợ 3 triples). Passage B (Score: 0.78) chỉ chứa "Metformin" (hỗ trợ 0 triples). Sau khi kết hợp điểm, Passage A có $Score_{final}$ cao hơn và được đẩy lên hạng cao hơn trong `Reranked Passages`.

Ví dụ Mở rộng Đồ thị Cục bộ: Thực thể cốt lõi là {Metformin, Nausea, Diarrhea, AbdominalPain}. Tìm kiếm 1-hop có thể trả về: `(Nausea, isSymptomOf, Gastritis)`, `(Metformin, interactsWith, Alcohol)`, `(Metformin, hasMechanism, ReduceGlucoseProduction)`. Các triple này tạo thành `Expanded Context`.

\subsection{Module 4: Chuẩn bị Ngữ cảnh và Tạo Câu trả lời (Context Preparation \& Answer Generation)}

\subsubsection{Diễn giải chi tiết Module}
Module cuối cùng tổng hợp tất cả thông tin đã được truy xuất, lọc và mở rộng để tạo prompt cho LLM và nhận câu trả lời cuối cùng. Một prompt hiệu quả cần cung cấp đầy đủ thông tin một cách có cấu trúc, bao gồm truy vấn gốc, các đoạn văn bản liên quan đã được xếp hạng lại (Top-K Reranked Passages), các sự thật cốt lõi đã xác minh (Filtered Triples, diễn đạt tự nhiên), và tùy chọn thông tin liên quan bổ sung (Expanded Context, diễn đạt tự nhiên). LLM nhận prompt này và sử dụng toàn bộ ngữ cảnh để tổng hợp và tạo ra câu trả lời cuối cùng, đảm bảo tính chính xác, đầy đủ và đáng tin cậy.

\subsubsection{Ví dụ minh họa}
Ví dụ cấu trúc Prompt:

\begin{verbatim}
**Truy vấn:** Tác dụng phụ phổ biến của Metformin là gì?

**Các đoạn văn bản liên quan (Top-K Reranked Passages):**
*   Passage A: Metformin là thuốc điều trị tiểu đường type 2. Một số tác dụng phụ thường gặp bao gồm buồn nôn, tiêu chảy và đau bụng...
*   Passage B: Liều lượng Metformin cần được điều chỉnh bởi bác sĩ...
*   ...

**Các sự thật cốt lõi đã xác minh (Filtered Triples):**
*   Metformin có tác dụng phụ là Buồn nôn.
*   Metformin gây ra tác dụng phụ là Tiêu chảy.
*   Metformin có thể gây ra Đau bụng.

**Thông tin liên quan bổ sung (Expanded Context - tùy chọn):**
*   Buồn nôn là triệu chứng của Viêm dạ dày.
*   Metformin tương tác với Rượu.
*   Metformin có cơ chế làm giảm sản xuất Glucose.

**Câu hỏi:** Dựa trên thông tin trên, hãy trả lời câu truy vấn ban đầu.
\end{verbatim}

Ví dụ Câu trả lời của LLM: "Các tác dụng phụ phổ biến của Metformin bao gồm buồn nôn, tiêu chảy và đau bụng. Đây là những thông tin được xác nhận và thường gặp khi sử dụng thuốc này để điều trị tiểu đường type 2."

\end{document}

