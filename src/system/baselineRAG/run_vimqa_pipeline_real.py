"""
Run RAG Pipeline cho VIMQA_dev collection
Äá»c questions tá»« Excel, cháº¡y qua RAG pipeline, vÃ  ghi káº¿t quáº£ ra file má»›i
"""

import pandas as pd
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

# Setup paths
current_file = Path(__file__)
sys.path.append(str(current_file.parent))

# Create outputs directory if it doesn't exist
outputs_dir = current_file.parent / "outputs"
outputs_dir.mkdir(exist_ok=True)

# Import RAG Pipeline
from pipelineRAG import RAGPipeline

class VIMQARunner:
    """
    Class Ä‘á»ƒ cháº¡y RAG Pipeline trÃªn VIMQA dataset
    """
    
    def __init__(
        self,
        collection_name: str = "VIMQA_dev",
        retriever_type: str = "vector",  # vector hoáº·c hybrid
        k: int = 5,
        generator_model: str = "gpt-4o-mini",
        temperature: float = 0.1
    ):
        """
        Khá»Ÿi táº¡o VIMQA Runner
        
        Args:
            collection_name: TÃªn collection trong Qdrant
            retriever_type: Loáº¡i retriever (vector, bm25, hybrid)
            k: Sá»‘ documents retrieve
            generator_model: Model OpenAI
            temperature: Temperature cho generation
        """
        self.collection_name = collection_name
        self.retriever_type = retriever_type
        self.k = k
        self.generator_model = generator_model
        self.temperature = temperature
        
        # Initialize RAG Pipeline
        print(f"ğŸš€ Initializing VIMQA Pipeline...")
        print(f"   Collection: {collection_name}")
        print(f"   Retriever: {retriever_type}")
        print(f"   K documents: {k}")
        print(f"   Model: {generator_model}")
        
        self.rag_pipeline = RAGPipeline(
            retriever_type=retriever_type,
            vector_store_type="qdrant",
            documents=None,  # Sá»­ dá»¥ng existing collection
            collection_name=collection_name,
            k=k,
            generator_model=generator_model,
            temperature=temperature
        )
        
        print(f"âœ… Pipeline initialized successfully!")
    
    def load_questions_from_excel(self, file_path: str, question_column: str = "question", nrows: Optional[int] = None) -> pd.DataFrame:
        """
        Load questions tá»« file Excel
        
        Args:
            file_path: ÄÆ°á»ng dáº«n file Excel
            question_column: TÃªn cá»™t chá»©a cÃ¢u há»i
            nrows: Sá»‘ rows muá»‘n Ä‘á»c (None = Ä‘á»c táº¥t cáº£)
            
        Returns:
            DataFrame chá»©a questions
        """
        try:
            print(f"ğŸ“– Loading questions from: {file_path}")
            
            # Äá»c file Excel
            if file_path.endswith('.xlsx') or file_path.endswith('.xls'):
                df = pd.read_excel(file_path, nrows=nrows)
            elif file_path.endswith('.csv'):
                df = pd.read_csv(file_path, nrows=nrows)
            else:
                raise ValueError("Unsupported file format. Use .xlsx, .xls, or .csv")
            
            print(f"âœ… Loaded {len(df)} rows")
            print(f"ğŸ“‹ Columns: {list(df.columns)}")
            
            # Kiá»ƒm tra column question cÃ³ tá»“n táº¡i khÃ´ng
            if question_column not in df.columns:
                print(f"âš ï¸  Column '{question_column}' not found. Available columns: {list(df.columns)}")
                # Tá»± Ä‘á»™ng detect question column
                possible_cols = [col for col in df.columns if 'question' in col.lower() or 'cÃ¢u há»i' in col.lower() or 'query' in col.lower()]
                if possible_cols:
                    question_column = possible_cols[0]
                    print(f"âœ… Auto-detected question column: '{question_column}'")
                else:
                    raise ValueError(f"Cannot find question column. Available: {list(df.columns)}")
            
            # Filter out empty questions
            original_len = len(df)
            df = df[df[question_column].notna() & (df[question_column] != "")]
            print(f"ğŸ“ Valid questions: {len(df)}/{original_len}")
            
            return df
            
        except Exception as e:
            print(f"âŒ Error loading Excel file: {e}")
            raise
    
    def process_questions(
        self, 
        df: pd.DataFrame, 
        question_column: str = "question",
        batch_size: int = 10,
        save_intermediate: bool = True
    ) -> pd.DataFrame:
        """
        Xá»­ lÃ½ táº¥t cáº£ questions qua RAG pipeline
        
        Args:
            df: DataFrame chá»©a questions
            question_column: TÃªn cá»™t question
            batch_size: Sá»‘ questions xá»­ lÃ½ cÃ¹ng lÃºc
            save_intermediate: CÃ³ save káº¿t quáº£ trung gian khÃ´ng
            
        Returns:
            DataFrame vá»›i káº¿t quáº£
        """
        results = []
        total_questions = len(df)
        
        print(f"\nğŸ¤– Processing {total_questions} questions...")
        print(f"ğŸ“¦ Batch size: {batch_size}")
        
        for i in range(0, total_questions, batch_size):
            batch_end = min(i + batch_size, total_questions)
            batch_df = df.iloc[i:batch_end].copy()
            
            print(f"\nğŸ“¦ Processing batch {i//batch_size + 1}/{(total_questions-1)//batch_size + 1}")
            print(f"   Questions {i+1}-{batch_end}/{total_questions}")
            
            batch_results = []
            
            for idx, row in batch_df.iterrows():
                question = row[question_column]
                
                try:
                    print(f"   ğŸ” Q{idx+1}: {question[:50]}...")
                    
                    # Query through RAG pipeline
                    result = self.rag_pipeline.query(
                        question=question,
                        return_sources=True,
                        return_documents=False
                    )
                    
                    # Prepare result row
                    result_row = row.copy()
                    result_row['ai_answer'] = result.get('answer', 'Error: No answer generated')
                    result_row['sources'] = str(result.get('sources', []))
                    result_row['num_documents_used'] = result.get('num_documents_used', 0)
                    result_row['has_error'] = 'error' in result
                    result_row['error_message'] = result.get('error', '')
                    
                    batch_results.append(result_row)
                    print(f"   âœ… Completed")
                    
                except Exception as e:
                    print(f"   âŒ Error: {e}")
                    result_row = row.copy()
                    result_row['ai_answer'] = f"Error: {str(e)}"
                    result_row['sources'] = '[]'
                    result_row['num_documents_used'] = 0
                    result_row['has_error'] = True
                    result_row['error_message'] = str(e)
                    batch_results.append(result_row)
            
            results.extend(batch_results)
            
            # Save intermediate results
            if save_intermediate and len(results) > 0:
                temp_df = pd.DataFrame(results)
                temp_file = outputs_dir / f"temp_results_batch_{i//batch_size + 1}.xlsx"
                temp_df.to_excel(temp_file, index=False)
                print(f"ğŸ’¾ Saved intermediate results to: {temp_file}")
        
        return pd.DataFrame(results)
    
    def save_results(
        self, 
        results_df: pd.DataFrame, 
        output_file: str = None,
        include_metadata: bool = True
    ) -> str:
        """
        LÆ°u káº¿t quáº£ ra file Excel
        
        Args:
            results_df: DataFrame chá»©a káº¿t quáº£
            output_file: TÃªn file output
            include_metadata: CÃ³ bao gá»“m metadata khÃ´ng
            
        Returns:
            ÄÆ°á»ng dáº«n file Ä‘Ã£ lÆ°u
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"vimqa_results_{timestamp}.xlsx"
        
        # Ensure output file is in outputs directory
        output_path = outputs_dir / output_file
        
        try:
            print(f"\nğŸ’¾ Saving results to: {output_path}")
            
            if include_metadata:
                # Add metadata sheet
                with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                    # Main results
                    results_df.to_excel(writer, sheet_name='Results', index=False)
                    
                    # Metadata
                    metadata = {
                        'run_timestamp': [datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
                        'collection_name': [self.collection_name],
                        'retriever_type': [self.retriever_type],
                        'k_documents': [self.k],
                        'generator_model': [self.generator_model],
                        'temperature': [self.temperature],
                        'total_questions': [len(results_df)],
                        'successful_answers': [len(results_df[~results_df['has_error']])],
                        'failed_answers': [len(results_df[results_df['has_error']])]
                    }
                    metadata_df = pd.DataFrame(metadata)
                    metadata_df.to_excel(writer, sheet_name='Metadata', index=False)
                    
                    print(f"âœ… Saved with metadata")
            else:
                results_df.to_excel(output_path, index=False)
                print(f"âœ… Saved results only")
            
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ Error saving results: {e}")
            raise
    
    def run_full_pipeline(
        self,
        input_file: str,
        output_file: str = None,
        question_column: str = "question",
        batch_size: int = 10,
        nrows: Optional[int] = None
    ) -> str:
        """
        Cháº¡y full pipeline: load â†’ process â†’ save
        
        Args:
            input_file: File Excel input
            output_file: File Excel output
            question_column: Cá»™t chá»©a questions
            batch_size: Batch size
            nrows: Sá»‘ rows muá»‘n Ä‘á»c (None = Ä‘á»c táº¥t cáº£)
            
        Returns:
            ÄÆ°á»ng dáº«n file káº¿t quáº£
        """
        print(f"\nğŸš€ Starting VIMQA Full Pipeline")
        print(f"{'='*50}")
        
        # Step 1: Load questions
        df = self.load_questions_from_excel(input_file, question_column, nrows=nrows)
        
        # Step 2: Process questions
        results_df = self.process_questions(
            df, 
            question_column=question_column,
            batch_size=batch_size
        )
        
        # Step 3: Save results
        output_path = self.save_results(results_df, output_file)
        
        # Step 4: Summary
        total = len(results_df)
        successful = len(results_df[~results_df['has_error']])
        failed = len(results_df[results_df['has_error']])
        
        print(f"\nğŸ¯ Pipeline Summary:")
        print(f"   Total questions: {total}")
        print(f"   Successful: {successful} ({successful/total*100:.1f}%)")
        print(f"   Failed: {failed} ({failed/total*100:.1f}%)")
        print(f"   Output file: {output_path}")
        
        return output_path

def main():
    """
    Main function Ä‘á»ƒ cháº¡y VIMQA pipeline
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Run VIMQA RAG Pipeline")
    parser.add_argument("--input", "-i", required=True, help="Input Excel file path")
    parser.add_argument("--output", "-o", help="Output Excel file path")
    parser.add_argument("--question_column", "-q", default="question", help="Question column name")
    parser.add_argument("--collection", "-c", default="VIMQA_dev", help="Qdrant collection name")
    parser.add_argument("--retriever", "-r", default="vector", choices=["vector", "bm25", "hybrid"], help="Retriever type")
    parser.add_argument("--k", type=int, default=5, help="Number of documents to retrieve")
    parser.add_argument("--batch_size", "-b", type=int, default=10, help="Batch size for processing")
    parser.add_argument("--model", "-m", default="gpt-4o-mini", help="OpenAI model")
    parser.add_argument("--temperature", "-t", type=float, default=0.1, help="Generation temperature")
    parser.add_argument("--nrows", "-n", type=int, help="Number of rows to process (default: all)")
    
    args = parser.parse_args()
    
    try:
        # Initialize runner
        runner = VIMQARunner(
            collection_name=args.collection,
            retriever_type=args.retriever,
            k=args.k,
            generator_model=args.model,
            temperature=args.temperature
        )
        
        # Run pipeline
        output_file = runner.run_full_pipeline(
            input_file=args.input,
            output_file=args.output,
            question_column=args.question_column,
            batch_size=args.batch_size,
            nrows=args.nrows
        )
        
        print(f"\nğŸ‰ Pipeline completed successfully!")
        print(f"ğŸ“„ Results saved to: {output_file}")
        
    except Exception as e:
        print(f"\nğŸ’¥ Pipeline failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # Example usage when run directly
    if len(sys.argv) == 1:
        print("ğŸš€ VIMQA RAG Pipeline Runner")
        print("="*40)
        print("\nExample usage:")
        print("python run_vimqa_pipeline.py --input questions.xlsx --output results.xlsx")
        print("\nArguments:")
        print("  --input, -i      : Input Excel file with questions")
        print("  --output, -o     : Output Excel file (optional)")
        print("  --question_column: Column name containing questions (default: 'question')")
        print("  --collection, -c : Qdrant collection name (default: 'VIMQA_dev')")
        print("  --retriever, -r  : Retriever type (vector/bm25/hybrid, default: vector)")
        print("  --k              : Number of documents to retrieve (default: 5)")
        print("  --batch_size, -b : Batch size (default: 10)")
        print("  --model, -m      : OpenAI model (default: gpt-4o-mini)")
        print("  --temperature, -t: Generation temperature (default: 0.1)")
        print("  --nrows, -n      : Number of rows to process (default: all)")
        
        # Quick test vá»›i VIMQA dataset
        print("\nğŸ§ª Running test with VIMQA dataset...")
        
        # ÄÆ°á»ng dáº«n Ä‘áº¿n file input
        input_file = current_file.parent.parent.parent / "datasets" / "dataset_full" / "vimqa_processed" / "qa_pairs_vimqa_dev_300.xlsx"
        
        if not input_file.exists():
            print(f"âŒ Input file not found: {input_file}")
            sys.exit(1)
            
        print(f"ğŸ“– Reading from: {input_file}")
        
        try:
            # Khá»Ÿi táº¡o runner
            runner = VIMQARunner(
                collection_name="VIMQA_dev",
                retriever_type="vector",
                k=3,
                generator_model="gpt-4o-mini",
                temperature=0.1
            )
            
            # Cháº¡y pipeline vá»›i 5 rows Ä‘áº§u
            output_file = runner.run_full_pipeline(
                input_file=str(input_file),
                question_column="question",
                batch_size=5,  # Process all 5 rows in one batch
                nrows=5  # Only read first 5 rows
            )
            
            print(f"âœ… Test completed! Check: {output_file}")
            
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
            
    else:
        main()
